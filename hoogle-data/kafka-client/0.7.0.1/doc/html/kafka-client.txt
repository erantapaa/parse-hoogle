-- Hoogle documentation, generated by Haddock
-- See Hoogle, http://www.haskell.org/hoogle/


-- | Low-level Haskell client library for Apache Kafka 0.7.
--   
@package kafka-client
@version 0.7.0.1

module Kafka.Internal.Types

-- | Different errors returned by Kafka.
data Error

-- | Unknown error
UnknownError :: Error

-- | Offset requested is invalid or no longer available on the server.
OffsetOutOfRangeError :: Error

-- | A message failed to match its checksum.
InvalidMessageError :: Error

-- | The requested partition doesn't exist.
WrongPartitionError :: Error

-- | The maximum size requested for fetching is smaller than the message
--   being fetched.
InvalidFetchSizeError :: Error

-- | Methods of compression supported by Kafka.
data Compression

-- | The message is uncompressed.
NoCompression :: Compression

-- | The message is compressed using <tt>gzip</tt> compression and may
--   contain other messages in it.
GzipCompression :: Compression

-- | The message is compressed using <tt>snappy</tt> compression and may
--   contain other messages in it.
SnappyCompression :: Compression

-- | Different times for which offsets may be retrieved using
--   <a>offsets</a>.
data OffsetsTime

-- | Retrieve the latest offsets
OffsetsLatest :: OffsetsTime

-- | Retrieve the earliest offsets.
OffsetsEarliest :: OffsetsTime

-- | Retrieve offsets before the given time.
--   
--   Keep in mind that the response will not contain the precise offset
--   that occurred around this time. It will return up to the specified
--   count of offsets in descending, each being the first offset of every
--   segment file for the specified partition with a modified time less
--   than this time, and possibly a "high water mark" for the last segment
--   of the partition (if it was modified before this time) which specifies
--   the offset at which the next message to that partition will be
--   written.
OffsetsBefore :: !UTCTime -> OffsetsTime

-- | The different request types supported by Kafka.
data RequestType
ProduceRequestType :: RequestType
FetchRequestType :: RequestType
MultiFetchRequestType :: RequestType
MultiProduceRequestType :: RequestType
OffsetsRequestType :: RequestType

-- | Represents a Kafka topic.
--   
--   This is an instance of <a>IsString</a> so a literal string may be used
--   to create a Topic with the <tt>OverloadedStrings</tt> extension.
newtype Topic
Topic :: ByteString -> Topic

-- | Represents an Offset in Kafka.
--   
--   This is an instance of <a>Num</a> so a literal number may be used to
--   create an Offset.
newtype Offset
Offset :: Word64 -> Offset

-- | Represents a Kafka topic partition.
--   
--   This is an instance of <a>Num</a> so a literal number may be used to
--   create a Partition.
newtype Partition
Partition :: Word32 -> Partition

-- | Represents a size.
--   
--   This is an instance of <a>Num</a> so a literal number may be used to
--   create a Size.
newtype Size
Size :: Word32 -> Size

-- | Represents a Count.
--   
--   This is an instance of <a>Num</a> so a literal number may be used to
--   create a Size.
newtype Count
Count :: Word32 -> Count

-- | Represents a Message being sent through Kafka.
data Message
Message :: !Compression -> !ByteString -> Message

-- | Compression used for the message.
--   
--   If this is anything but <a>NoCompression</a>, this message contains
--   other messages in it.
messageCompression :: Message -> !Compression

-- | Message payload.
--   
--   If the message is using any compression scheme, the payload contains
--   other messages in the same format.
messagePayload :: Message -> !ByteString

-- | Represents a collection of message payloads.
--   
--   These are compressed into a single message using Snappy compression
--   when being sent.
newtype MessageSet
MessageSet :: [ByteString] -> MessageSet
fromMessageSet :: MessageSet -> [ByteString]
instance [overlap ok] Show Error
instance [overlap ok] Read Error
instance [overlap ok] Eq Error
instance [overlap ok] Ord Error
instance [overlap ok] Show Compression
instance [overlap ok] Read Compression
instance [overlap ok] Eq Compression
instance [overlap ok] Ord Compression
instance [overlap ok] Show OffsetsTime
instance [overlap ok] Read OffsetsTime
instance [overlap ok] Eq OffsetsTime
instance [overlap ok] Ord OffsetsTime
instance [overlap ok] Show RequestType
instance [overlap ok] Read RequestType
instance [overlap ok] Eq RequestType
instance [overlap ok] Ord RequestType
instance [overlap ok] Show Topic
instance [overlap ok] Read Topic
instance [overlap ok] Eq Topic
instance [overlap ok] Ord Topic
instance [overlap ok] IsString Topic
instance [overlap ok] Show Offset
instance [overlap ok] Read Offset
instance [overlap ok] Eq Offset
instance [overlap ok] Ord Offset
instance [overlap ok] Num Offset
instance [overlap ok] Show Partition
instance [overlap ok] Read Partition
instance [overlap ok] Eq Partition
instance [overlap ok] Ord Partition
instance [overlap ok] Num Partition
instance [overlap ok] Show Size
instance [overlap ok] Read Size
instance [overlap ok] Eq Size
instance [overlap ok] Ord Size
instance [overlap ok] Num Size
instance [overlap ok] Show Count
instance [overlap ok] Read Count
instance [overlap ok] Eq Count
instance [overlap ok] Ord Count
instance [overlap ok] Num Count
instance [overlap ok] Show Message
instance [overlap ok] Read Message
instance [overlap ok] Eq Message
instance [overlap ok] Ord Message
instance [overlap ok] Show MessageSet
instance [overlap ok] Read MessageSet
instance [overlap ok] Eq MessageSet
instance [overlap ok] Monoid MessageSet
instance [overlap ok] Serialize MessageSet
instance [overlap ok] Serialize Message
instance [overlap ok] Serialize Count
instance [overlap ok] Serialize Size
instance [overlap ok] Serialize Partition
instance [overlap ok] Serialize Offset
instance [overlap ok] Serialize Topic
instance [overlap ok] Serialize RequestType
instance [overlap ok] Serialize OffsetsTime
instance [overlap ok] Serialize Compression
instance [overlap ok] Serialize (Maybe Error)

module Kafka.Internal.Transport

-- | Types that provide a means to send and receive bytes.
class Transport t
send :: Transport t => t -> ByteString -> IO ()
recv :: Transport t => t -> Int -> IO ByteString

-- | Keep reading from the given transport until the given number of bytes
--   are read or the end of the stream is reached -- whichever comes first.
recvExactly :: Transport t => t -> Int -> IO ByteString

-- | Represents a socket. The fields are, respectively:
--   
--   <ul>
--   <li>File descriptor</li>
--   <li>Socket family</li>
--   <li>Socket type</li>
--   <li>Protocol number</li>
--   <li>Status flag</li>
--   </ul>
--   
--   If you are calling the <a>MkSocket</a> constructor directly you should
--   ensure you have called <a>withSocketsDo</a>.
data Socket :: *

-- | Open a connection, execute the given operation on it, and ensure it is
--   closed afterwards even if an exception was thrown.
--   
--   <pre>
--   withConnection "localhost" 9092 $ \conn -&gt;
--      doStuff conn
--      fail "something went wrong"
--   </pre>
--   
--   Throws an <tt>IOException</tt> if we were unable to open the
--   connection.
withConnection :: ByteString -> Int -> (Socket -> IO a) -> IO a

-- | Create a new connection.
--   
--   Connects to the given hostname and port. Throws an <a>IOException</a>
--   in case of failure.
connect :: ByteString -> Int -> IO Socket

-- | Close the socket. All future operations on the socket object will
--   fail. The remote end will receive no more data (after queued data is
--   flushed).
close :: Socket -> IO ()
instance Transport Socket

module Kafka.Internal.Request

-- | A request to send messages down a Kafka topic-partition pair.
--   
--   Produce requests do not have a corresponding response. There is no way
--   of knowing in Kafka 0.7 if a message was successfully
--   <tt>Produce</tt>d.
data Produce
Produce :: {-# UNPACK #-} !Topic -> {-# UNPACK #-} !Partition -> [ByteString] -> Produce

-- | Kafka topic to which the messages will be sent.
produceTopic :: Produce -> {-# UNPACK #-} !Topic

-- | Partition of the topic.
producePartition :: Produce -> {-# UNPACK #-} !Partition

-- | List of message payloads.
--   
--   For those concerned with low-leveld details: These messages will be
--   compressed using <a>Snappy</a> compression.
produceMessages :: Produce -> [ByteString]

-- | <tt>Put</tt>s the given single <tt>Produce</tt> request.
putProduceRequest :: Produce -> Put

-- | <tt>Put</tt>s the given <tt>MultiProduce</tt> request.
putMultiProduceRequest :: [Produce] -> Put

-- | A request to fetch messages from a particular Kafka topic-partition
--   pair.
--   
--   <a>FetchResponse</a> contains responses for this kind of request.
data Fetch
Fetch :: {-# UNPACK #-} !Topic -> {-# UNPACK #-} !Partition -> {-# UNPACK #-} !Offset -> {-# UNPACK #-} !Size -> Fetch

-- | Kafka topic from which messages will be fetched.
fetchTopic :: Fetch -> {-# UNPACK #-} !Topic

-- | Partition of the topic.
fetchPartition :: Fetch -> {-# UNPACK #-} !Partition

-- | Offset at which the fetch will start.
--   
--   Kafka offloads the responsiblity of knowing this to the client. That
--   means that if an offset is specified here that is not a real message
--   start, Kafka will spit out garbage.
--   
--   Use <a>offsets</a> to find valid offsets.
fetchOffset :: Fetch -> {-# UNPACK #-} !Offset

-- | Maximum size of the returned messages.
--   
--   Note, this is <i>not</i> the number of messages. This is the maximum
--   combined size of the returned <i>compressed</i> messages.
fetchSize :: Fetch -> {-# UNPACK #-} !Size

-- | <tt>Put</tt>s the given single <tt>Fetch</tt> request.
putFetchRequest :: Fetch -> Put

-- | <tt>Put</tt>s the given <tt>MultiFetch</tt> request.
putMultiFetchRequest :: [Fetch] -> Put

-- | A request to retrieve offset information from Kafka.
--   
--   The response for this kind of request is a list of <a>Offset</a>s.
data Offsets
Offsets :: {-# UNPACK #-} !Topic -> {-# UNPACK #-} !Partition -> !OffsetsTime -> {-# UNPACK #-} !Count -> Offsets

-- | Kafka topic from which offsets will be retrieved.
offsetsTopic :: Offsets -> {-# UNPACK #-} !Topic

-- | Partition of the topic.
offsetsPartition :: Offsets -> {-# UNPACK #-} !Partition

-- | Time around which offsets will be retrieved.
--   
--   If you provide a time for this, keep in mind that the response will
--   not contain the precise offset that occurred around that time. It will
--   return up to <tt>offsetsCount</tt> offsets in descending, each being
--   the first offset of every segment file for the specified partition
--   with a modified time less than the specified time, and possibly a
--   "high water mark" for the last segment of the partition (if it was
--   modified before the specified time) which specifies the offset at
--   which the next message to that partition will be written.
offsetsTime :: Offsets -> !OffsetsTime

-- | Maximum number of offsets that will be retrieved.
offsetsCount :: Offsets -> {-# UNPACK #-} !Count

-- | <tt>Put</tt>s the given <tt>Offsets</tt> request.
putOffsetsRequest :: Offsets -> Put
instance Show Produce
instance Read Produce
instance Eq Produce
instance Show Fetch
instance Read Fetch
instance Eq Fetch
instance Show Offsets
instance Read Offsets
instance Eq Offsets

module Kafka.Internal.Response

-- | A response from Kafka can either be a failure or the value that was
--   expected.
type Response a = Either Error a

-- | Result of a single Kafka <a>Fetch</a>.
data FetchResponse
FetchResponse :: [ByteString] -> {-# UNPACK #-} !Offset -> FetchResponse

-- | List of messages returned in the response for the <a>Fetch</a>
--   request.
fetchMessages :: FetchResponse -> [ByteString]

-- | New offset at which the next <a>Fetch</a> request should start reading
--   in the same topic and partition to access the messages that follow the
--   messages returned in this response.
fetchNewOffset :: FetchResponse -> {-# UNPACK #-} !Offset

-- | Parses a single <tt>FetchResponse</tt> for the given <tt>Fetch</tt>
--   request.
getFetchResponse :: Fetch -> Get FetchResponse

-- | Parses <tt>FetchResponse</tt>s for each of the given <tt>Fetch</tt>
--   requests.
getMultiFetchResponse :: [Fetch] -> Get [FetchResponse]

-- | Parses the response for an <tt>Offsets</tt> request.
getOffsetsResponse :: Get [Offset]
instance Show FetchResponse
instance Read FetchResponse
instance Eq FetchResponse

module Kafka.Internal


-- | A library to interact with Apache Kafka 0.7.
module Kafka

-- | Open a connection, execute the given operation on it, and ensure it is
--   closed afterwards even if an exception was thrown.
--   
--   <pre>
--   withConnection "localhost" 9092 $ \conn -&gt;
--      doStuff conn
--      fail "something went wrong"
--   </pre>
--   
--   Throws an <tt>IOException</tt> if we were unable to open the
--   connection.
withConnection :: ByteString -> Int -> (Socket -> IO a) -> IO a

-- | Sends the given <a>Produce</a> requests to Kafka.
--   
--   If multiple requests are supplied, a <tt>MultiProduce</tt> request is
--   made.
--   
--   <pre>
--   <a>withConnection</a> "localhost" 9092 $ \conn -&gt;
--     produce conn [
--        <a>Produce</a> (<a>Topic</a> "my-topic") (<a>Partition</a> 0) ["foo"]
--      , Produce "another-topic" 0
--                  ["multiple", "messages"]
--      ]
--   </pre>
--   
--   Note that string literals may be used in place of <a>Topic</a> (with
--   the <tt>OverloadedStrings</tt> GHC extension), and integer literals
--   may be used in place of <a>Partition</a>.
produce :: Transport t => t -> [Produce] -> IO ()

-- | <a>Fetch</a>es messages from Kafka.
--   
--   If multiple Fetch requests are supplied, a <tt>MultiFetch</tt> request
--   is made.
--   
--   <pre>
--   <a>withConnection</a> "localhost" 9092 $ \conn -&gt; do
--     Right [<a>FetchResponse</a> messages newOffset] &lt;- fetch conn [
--         <a>Fetch</a> (<a>Topic</a> "test-topic") (<a>Partition</a> 0) (Offset 42) 1024
--       ]
--     {- Consume the messages here -}
--     response &lt;- fetch conn [<a>Fetch</a> "test-topic" 0 newOffset 1024]
--     {- ... -}
--   </pre>
--   
--   Returns a list of <a>FetchResponse</a>s in the same order as the
--   <a>Fetch</a> requests. Each response contains the messages returned
--   for the corresponding request and the new offset at which the next
--   request should be made for that request to get the messages that
--   follow.
--   
--   If a response for a request contains no messages, the specified
--   topic-partition pair has been exhausted.
--   
--   Note that string literals may be used in place of <a>Topic</a> (with
--   the <tt>OverloadedStrings</tt> GHC extension), and integer literals
--   may be used in place of <a>Offset</a>.
fetch :: Transport t => t -> [Fetch] -> IO (Response [FetchResponse])

-- | Retrieve message offsets from Kafka.
--   
--   <pre>
--   <a>withConnection</a> "localhost" 9092 $ \conn -&gt; do
--     Right [os] &lt;- offsets conn (Offsets "topic" 0 OffsetsEarliest 1)
--     fetch conn [<a>Fetch</a> "topic" (Partition 0) os 10] &gt;&gt;= doSomething
--   </pre>
--   
--   Note that string literals may be used in place of <a>Topic</a> (with
--   the <tt>OverloadedStrings</tt> GHC extension), and integer literals
--   may be used in place of <a>Count</a>.
offsets :: Transport t => t -> Offsets -> IO (Response [Offset])

-- | A request to send messages down a Kafka topic-partition pair.
--   
--   Produce requests do not have a corresponding response. There is no way
--   of knowing in Kafka 0.7 if a message was successfully
--   <tt>Produce</tt>d.
data Produce
Produce :: {-# UNPACK #-} !Topic -> {-# UNPACK #-} !Partition -> [ByteString] -> Produce

-- | Kafka topic to which the messages will be sent.
produceTopic :: Produce -> {-# UNPACK #-} !Topic

-- | Partition of the topic.
producePartition :: Produce -> {-# UNPACK #-} !Partition

-- | List of message payloads.
--   
--   For those concerned with low-leveld details: These messages will be
--   compressed using <a>Snappy</a> compression.
produceMessages :: Produce -> [ByteString]

-- | A request to fetch messages from a particular Kafka topic-partition
--   pair.
--   
--   <a>FetchResponse</a> contains responses for this kind of request.
data Fetch
Fetch :: {-# UNPACK #-} !Topic -> {-# UNPACK #-} !Partition -> {-# UNPACK #-} !Offset -> {-# UNPACK #-} !Size -> Fetch

-- | Kafka topic from which messages will be fetched.
fetchTopic :: Fetch -> {-# UNPACK #-} !Topic

-- | Partition of the topic.
fetchPartition :: Fetch -> {-# UNPACK #-} !Partition

-- | Offset at which the fetch will start.
--   
--   Kafka offloads the responsiblity of knowing this to the client. That
--   means that if an offset is specified here that is not a real message
--   start, Kafka will spit out garbage.
--   
--   Use <a>offsets</a> to find valid offsets.
fetchOffset :: Fetch -> {-# UNPACK #-} !Offset

-- | Maximum size of the returned messages.
--   
--   Note, this is <i>not</i> the number of messages. This is the maximum
--   combined size of the returned <i>compressed</i> messages.
fetchSize :: Fetch -> {-# UNPACK #-} !Size

-- | Result of a single Kafka <a>Fetch</a>.
data FetchResponse
FetchResponse :: [ByteString] -> {-# UNPACK #-} !Offset -> FetchResponse

-- | List of messages returned in the response for the <a>Fetch</a>
--   request.
fetchMessages :: FetchResponse -> [ByteString]

-- | New offset at which the next <a>Fetch</a> request should start reading
--   in the same topic and partition to access the messages that follow the
--   messages returned in this response.
fetchNewOffset :: FetchResponse -> {-# UNPACK #-} !Offset

-- | A request to retrieve offset information from Kafka.
--   
--   The response for this kind of request is a list of <a>Offset</a>s.
data Offsets
Offsets :: {-# UNPACK #-} !Topic -> {-# UNPACK #-} !Partition -> !OffsetsTime -> {-# UNPACK #-} !Count -> Offsets

-- | Kafka topic from which offsets will be retrieved.
offsetsTopic :: Offsets -> {-# UNPACK #-} !Topic

-- | Partition of the topic.
offsetsPartition :: Offsets -> {-# UNPACK #-} !Partition

-- | Time around which offsets will be retrieved.
--   
--   If you provide a time for this, keep in mind that the response will
--   not contain the precise offset that occurred around that time. It will
--   return up to <tt>offsetsCount</tt> offsets in descending, each being
--   the first offset of every segment file for the specified partition
--   with a modified time less than the specified time, and possibly a
--   "high water mark" for the last segment of the partition (if it was
--   modified before the specified time) which specifies the offset at
--   which the next message to that partition will be written.
offsetsTime :: Offsets -> !OffsetsTime

-- | Maximum number of offsets that will be retrieved.
offsetsCount :: Offsets -> {-# UNPACK #-} !Count

-- | Different times for which offsets may be retrieved using
--   <a>offsets</a>.
data OffsetsTime

-- | Retrieve the latest offsets
OffsetsLatest :: OffsetsTime

-- | Retrieve the earliest offsets.
OffsetsEarliest :: OffsetsTime

-- | Retrieve offsets before the given time.
--   
--   Keep in mind that the response will not contain the precise offset
--   that occurred around this time. It will return up to the specified
--   count of offsets in descending, each being the first offset of every
--   segment file for the specified partition with a modified time less
--   than this time, and possibly a "high water mark" for the last segment
--   of the partition (if it was modified before this time) which specifies
--   the offset at which the next message to that partition will be
--   written.
OffsetsBefore :: !UTCTime -> OffsetsTime

-- | Represents a Kafka topic.
--   
--   This is an instance of <a>IsString</a> so a literal string may be used
--   to create a Topic with the <tt>OverloadedStrings</tt> extension.
newtype Topic
Topic :: ByteString -> Topic

-- | Represents an Offset in Kafka.
--   
--   This is an instance of <a>Num</a> so a literal number may be used to
--   create an Offset.
newtype Offset
Offset :: Word64 -> Offset

-- | Represents a Kafka topic partition.
--   
--   This is an instance of <a>Num</a> so a literal number may be used to
--   create a Partition.
newtype Partition
Partition :: Word32 -> Partition

-- | Represents a size.
--   
--   This is an instance of <a>Num</a> so a literal number may be used to
--   create a Size.
newtype Size
Size :: Word32 -> Size

-- | Represents a Count.
--   
--   This is an instance of <a>Num</a> so a literal number may be used to
--   create a Size.
newtype Count
Count :: Word32 -> Count

-- | Different errors returned by Kafka.
data Error

-- | Unknown error
UnknownError :: Error

-- | Offset requested is invalid or no longer available on the server.
OffsetOutOfRangeError :: Error

-- | A message failed to match its checksum.
InvalidMessageError :: Error

-- | The requested partition doesn't exist.
WrongPartitionError :: Error

-- | The maximum size requested for fetching is smaller than the message
--   being fetched.
InvalidFetchSizeError :: Error

-- | A response from Kafka can either be a failure or the value that was
--   expected.
type Response a = Either Error a

-- | Represents a socket. The fields are, respectively:
--   
--   <ul>
--   <li>File descriptor</li>
--   <li>Socket family</li>
--   <li>Socket type</li>
--   <li>Protocol number</li>
--   <li>Status flag</li>
--   </ul>
--   
--   If you are calling the <a>MkSocket</a> constructor directly you should
--   ensure you have called <a>withSocketsDo</a>.
data Socket :: *

-- | Types that provide a means to send and receive bytes.
class Transport t
send :: Transport t => t -> ByteString -> IO ()
recv :: Transport t => t -> Int -> IO ByteString
