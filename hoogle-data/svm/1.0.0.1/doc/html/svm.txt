-- Hoogle documentation, generated by Haddock
-- See Hoogle, http://www.haskell.org/hoogle/


-- | A support vector machine written in Haskell
--   
--   svm is a library which implements least squares support vector
--   regression. It includes several common kernel functions.
@package svm
@version 1.0.0.1


-- | This module performs support vector regression on a set of training
--   points in order to determine the generating function. Currently least
--   squares support vector regression is implemented. The optimal solution
--   to the Langrangian is found by a conjugate gradient algorithm (CGA).
module SVM

-- | Each data set is a list of vectors and values which are training
--   points of the form f(x) = y forall {x,y}.
data DataSet
DataSet :: (Array Int [Double]) -> DoubleArray -> DataSet
points :: DataSet -> (Array Int [Double])
values :: DataSet -> DoubleArray

-- | The solution contains the dual weights, the support vectors and the
--   bias.
data SVMSolution
SVMSolution :: DoubleArray -> (Array Int [Double]) -> Double -> SVMSolution
alpha :: SVMSolution -> DoubleArray
sv :: SVMSolution -> (Array Int [Double])
bias :: SVMSolution -> Double

-- | Every kernel function represents an inner product in feature space.
--   The parameters are:
--   
--   <ul>
--   <li>A list of kernel parameters that can be interpreted differently by
--   each kernel function.</li>
--   <li>The first point in the inner product.</li>
--   <li>The second point in the inner product.</li>
--   </ul>
newtype KernelFunction
KernelFunction :: ([Double] -> [Double] -> [Double] -> Double) -> KernelFunction

-- | A support vector machine (SVM) can estimate a function based upon some
--   training data. Instances of this class need only implement the dual
--   cost and the kernel function. Default implementations are given for
--   finding the SVM solution, for simulating a function and for creating a
--   kernel matrix from a set of training points. All SVMs should return a
--   solution which contains a list of the support vectors and their dual
--   weigths. dcost represents the coefficient of the dual cost function.
--   This term gets added to the diagonal elements of the kernel matrix and
--   may be different for each type of SVM.
class SVM a
createKernelMatrix :: SVM a => a -> (Array Int [Double]) -> KernelMatrix
dcost :: SVM a => a -> Double
evalKernel :: SVM a => a -> [Double] -> [Double] -> Double
simulate :: SVM a => a -> SVMSolution -> (Array Int [Double]) -> [Double]
solve :: SVM a => a -> DataSet -> Double -> Int -> SVMSolution

-- | A least squares support vector machine. The cost represents the
--   relative expense of missing a training versus a more complicated
--   generating function. The higher this number the better the fit of the
--   training set, but at a cost of poorer generalization. The LSSVM uses
--   every training point in the solution and performs least squares
--   regression on the dual of the problem.
data LSSVM
LSSVM :: KernelFunction -> Double -> [Double] -> LSSVM

-- | The kernel function defines the feature space.
kf :: LSSVM -> KernelFunction

-- | The cost coefficient in the Lagrangian.
cost :: LSSVM -> Double

-- | Any parameters needed by the <a>KernelFunction</a>.
params :: LSSVM -> [Double]

-- | The kernel matrix has been implemented as an unboxed array for
--   performance reasons.
newtype KernelMatrix
KernelMatrix :: DoubleArray -> KernelMatrix

-- | The reciprocal kernel is the result of exponential basis functions,
--   exp(-k*(x+a)). The inner product is an integral over all k &gt;= 0.
reciprocalKernelFunction :: [Double] -> [Double] -> [Double] -> Double

-- | This is the kernel when radial basis functions are used.
radialKernelFunction :: [Double] -> [Double] -> [Double] -> Double

-- | This is a simple dot product between the two data points,
--   corresponding to a featureless space.
linearKernelFunction :: [Double] -> [Double] -> [Double] -> Double
splineKernelFunction :: [Double] -> [Double] -> [Double] -> Double
polyKernelFunction :: [Double] -> [Double] -> [Double] -> Double

-- | Provides a solution similar to neural net.
mlpKernelFunction :: [Double] -> [Double] -> [Double] -> Double
instance SVM LSSVM
