-- Hoogle documentation, generated by Haddock
-- See Hoogle, http://www.haskell.org/hoogle/


-- | Semi-explicit parallel programming skeleton library
--   
@package edenskel
@version 2.1.0.0


-- | This Haskell module defines auxiliary functions for programming with
--   the parallel functional language Eden.
--   
--   Depends on GHC. Using standard GHC, you will get a threaded simulation
--   of Eden. Use the forked GHC-Eden compiler from
--   http://www.mathematik.uni-marburg.de/~eden for a parallel build.
--   
--   Eden Group ( http://www.mathematik.uni-marburg.de/~eden )
module Control.Parallel.Eden.Auxiliary

-- | Round robin distribution - inverse to shuffle
unshuffle :: Int -> [a] -> [[a]]

-- | Simple shuffling - inverse to round robin distribution
shuffle :: [[a]] -> [a]

-- | Block distribution, <tt> splitIntoN </tt> distributes one list on n
--   lists with equal distribution ((+-1) without precondition on length).
splitIntoN :: Int -> [a] -> [[a]]

-- | Inverse function to <tt> splitIntoN </tt> - alias for concat.
unSplit :: [[a]] -> [a]

-- | Creates a list of chunks of length <tt> d</tt> .
--   
--   Result: list of chunks (blocks)
chunk :: Int -> [a] -> [[a]]

-- | Inverse function to <tt> chunk </tt> - alias for concat.
unchunk :: [[a]] -> [a]

-- | Task distribution according to worker requests.
distribute :: Int -> [Int] -> [t] -> [[t]]

-- | A lazy list is an infinite stream
lazy :: [a] -> [a]

-- | lazy in first argument
lazy1ZipWith :: (a -> b -> c) -> [a] -> [b] -> [c]

-- | lazy in second argument
lazy2ZipWith :: (a -> b -> c) -> [a] -> [b] -> [c]

-- | lazy in first argument
lazy1Zip :: [a] -> [b] -> [(a, b)]

-- | lazy in second argument
lazy2Zip :: [a] -> [b] -> [(a, b)]

-- | lazy in tail lists
lazyTranspose :: [[a]] -> [[a]]
takeEach :: Int -> [a] -> [a]

-- | transpose for matrices of rectangular shape (rows of equal length).
--   Top level list of the resulting matrix is defined as soon as the first
--   row of the original matrix is closed.
transposeRt :: [[a]] -> [[a]]
unLiftRD :: (Trans a, Trans b) => (RD a -> RD b) -> a -> b

-- | see <tt>liftRD</tt>
unLiftRD2 :: (Trans a, Trans b, Trans c) => (RD a -> RD b -> RD c) -> a -> b -> c

-- | see <tt>liftRD</tt>
unLiftRD3 :: (Trans a, Trans b, Trans c, Trans d) => (RD a -> RD b -> RD c -> RD d) -> a -> b -> c -> d

-- | see <tt>liftRD</tt>
unLiftRD4 :: (Trans a, Trans b, Trans c, Trans d, Trans e) => (RD a -> RD b -> RD c -> RD d -> RD e) -> a -> b -> c -> d -> e

-- | Spawn a matrix of processes
spawnPss :: (Trans a, Trans b) => [[Process a b]] -> [[a]] -> [[b]]

-- | Fetch two Remote Data values
fetch2 :: (Trans a, Trans b) => RD a -> RD b -> (a, b)

-- | Fetch a matrix of Remote Data
fetchRDss :: Trans a => [[RD a]] -> [[a]]

-- | A variant of non-deterministic list merging, which applies a strategy
--   to list elements prior to merging them and stops the additional merge
--   thread (the suckIO_S thread) when only one input stream is left.
mergeS :: [[a]] -> Strategy a -> [a]


-- | This Haskell module defines map-like skeletons for the parallel
--   functional language Eden.
--   
--   Depends on GHC. Using standard GHC, you will get a threaded simulation
--   of Eden. Use the forked GHC-Eden compiler from
--   http://www.mathematik.uni-marburg.de/~eden for a parallel build.
--   
--   Eden Group ( http://www.mathematik.uni-marburg.de/~eden )
module Control.Parallel.Eden.Map

-- | Basic parMap Skeleton - one process for each list element
parMap :: (Trans a, Trans b) => (a -> b) -> [a] -> [b]

-- | A process ranch is a generalized (or super-) farm. Arbitrary input is
--   transformed into a list of inputs for the worker processes (one worker
--   for each transformed value). The worker inputs are processed by the
--   worker function. The results of the worker processes are then reduced
--   using the reduction function.
ranch :: (Trans b, Trans c) => (a -> [b]) -> ([c] -> d) -> (b -> c) -> a -> d

-- | A farm distributes its input to a number of worker processes. The
--   distribution function divides the input list into sublists - each
--   sublist is input to one worker process, the number of worker processes
--   is determined by the number of sublists. The results of the worker
--   processes are then combined using the combination function.
--   
--   Use <a>mapFarmS</a> or <a>mapFarmB</a> if you want a simpler
--   interface.
farm :: (Trans a, Trans b) => ([a] -> [[a]]) -> ([[b]] -> [b]) -> (a -> b) -> [a] -> [b]

-- | Like the <a>farm</a>, but uses a fixed round-robin distribution of
--   tasks.
farmS :: (Trans a, Trans b) => Int -> (a -> b) -> [a] -> [b]

-- | Like the <a>farm</a>, but uses a fixed block distribution of tasks.
farmB :: (Trans a, Trans b) => Int -> (a -> b) -> [a] -> [b]

-- | Offline farm (alias direct mapping): Like the farm, but tasks are
--   evaluated inside the workers (less communication overhead). Tasks are
--   mapped inside each generated process abstraction avoiding evaluating
--   and sending them. This often reduces the communication overhead
--   because unevaluated data is usually much smaller than evaluated data.
--   
--   Use <a>map_offlineFarm</a> if you want a simpler interface.
--   
--   Notice: The offline farm receives the number of processes to be
--   created as its first parameter. The task lists structure has to be
--   completely defined before process instantiation takes place.
offlineFarm :: Trans b => Int -> ([a] -> [[a]]) -> ([[b]] -> [b]) -> (a -> b) -> [a] -> [b]

-- | Like the <a>offlineFarm</a>, but with fixed round-robin distribution
--   of tasks.
offlineFarmS :: (Trans a, Trans b) => Int -> (a -> b) -> [a] -> [b]

-- | Like the <a>offlineFarm</a>, but with fixed block distribution of
--   tasks.
offlineFarmB :: (Trans a, Trans b) => Int -> (a -> b) -> [a] -> [b]

-- | Basic parMap Skeleton - one process for each list element. This
--   version takes places for instantiation on particular PEs.
parMapAt :: (Trans a, Trans b) => Places -> (a -> b) -> [a] -> [b]

-- | A process ranch is a generalized (or super-) farm. This version takes
--   places for instantiation. Arbitrary input is transformed into a list
--   of inputs for the worker processes (one worker for each transformed
--   value). The worker inputs are processed by the worker function. The
--   results of the worker processes are then reduced using the reduction
--   function.
ranchAt :: (Trans b, Trans c) => Places -> (a -> [b]) -> ([c] -> d) -> (b -> c) -> a -> d

-- | A farm distributes its input to a number of worker processes. This
--   version takes places for instantiation. The distribution function
--   divides the input list into sublists - each sublist is input to one
--   worker process, the number of worker processes is determined by the
--   number of sublists. The results of the worker processes are then
--   combined using the combination function.
--   
--   Use <a>map_farm</a> if you want a simpler interface.
farmAt :: (Trans a, Trans b) => Places -> ([a] -> [[a]]) -> ([[b]] -> [b]) -> (a -> b) -> [a] -> [b]

-- | Offline farm with explicit placement (alias self-service farm or
--   direct mapping): Like the farm, but tasks are evaluated inside the
--   workers (less communication overhead). Tasks are mapped inside each
--   generated process abstraction, avoiding evaluating and sending them.
--   This often reduces the communication overhead because unevaluated data
--   is usually much smaller than evaluated data.
--   
--   Use <a>map_offlineFarm</a> if you want a simpler interface.
--   
--   Notice: The task lists structure has to be completely defined before
--   process instantiation takes place.
offlineFarmAt :: Trans b => Places -> Int -> ([a] -> [[a]]) -> ([[b]] -> [b]) -> (a -> b) -> [a] -> [b]

-- | Parallel map variant with map interface using (max (noPe-1) 1) worker
--   processes. Skeletons ending on <tt>S</tt> use round-robin
--   distribution, skeletons ending on <tt>B</tt> use block distribution of
--   tasks.
mapFarmB :: (Trans a, Trans b) => (a -> b) -> [a] -> [b]

-- | Parallel map variant with map interface using (max (noPe-1) 1) worker
--   processes. Skeletons ending on <tt>S</tt> use round-robin
--   distribution, skeletons ending on <tt>B</tt> use block distribution of
--   tasks.
mapFarmS :: (Trans a, Trans b) => (a -> b) -> [a] -> [b]

-- | Parallel map variant with map interface using (max (noPe-1) 1) worker
--   processes. Skeletons ending on <tt>S</tt> use round-robin
--   distribution, skeletons ending on <tt>B</tt> use block distribution of
--   tasks.
mapOfflineFarmS :: (Trans a, Trans b) => (a -> b) -> [a] -> [b]

-- | Parallel map variant with map interface using (max (noPe-1) 1) worker
--   processes. Skeletons ending on <tt>S</tt> use round-robin
--   distribution, skeletons ending on <tt>B</tt> use block distribution of
--   tasks.
mapOfflineFarmB :: (Trans a, Trans b) => (a -> b) -> [a] -> [b]

-- | Deprecated, use the <a>farm</a>; <tt>farmClassic</tt> distributes its
--   input to a number of worker processes. This is the Classic version as
--   described in the Eden standard reference "Parallel Functional
--   Programming in Eden". The distribution function is expected to divide
--   the input list into the given number of sublists. In the new farm the
--   number of sublists is determined only by the distribution function.
--   
--   Use <a>map_farm</a> if you want a simpler interface.

-- | <i>Deprecated: better use farm instead</i>
farmClassic :: (Trans a, Trans b) => Int -> (Int -> [a] -> [[a]]) -> ([[b]] -> [b]) -> (a -> b) -> [a] -> [b]

-- | Deprecated, use <a>offlineFarm</a>; Self service farm. Like the farm,
--   but tasks are evaluated in the workers (less communication overhead).
--   This is the classic version. The distribution function is expected to
--   divide the input list into the given number of sublists. In the new
--   self service farm the number of sublists is determined only by the
--   distribution function.
--   
--   Use <a>map_ssf</a> if you want a simpler interface.
--   
--   Notice: The task lists structure has to be completely defined before
--   process instantiation takes place.

-- | <i>Deprecated: better use offlineFarm instead</i>
ssf :: Trans b => Int -> (Int -> [a] -> [[a]]) -> ([[b]] -> [b]) -> (a -> b) -> [a] -> [b]

-- | Deprecated: Same as <a>offlineFarm</a>.

-- | <i>Deprecated: better use offlineFarm instead</i>
offline_farm :: Trans b => Int -> ([a] -> [[a]]) -> ([[b]] -> [b]) -> (a -> b) -> [a] -> [b]

-- | Deprecated: Same as <a>parMap</a>.

-- | <i>Deprecated: better use parMap instead</i>
map_par :: (Trans a, Trans b) => (a -> b) -> [a] -> [b]

-- | Deprecated: Parallel map variants with map interface using noPe worker
--   processes.

-- | <i>Deprecated: better use mapFarmS or mapOfflineFarmS instead</i>
map_farm :: (Trans a, Trans b) => (a -> b) -> [a] -> [b]

-- | Deprecated: Parallel map variants with map interface using noPe worker
--   processes.

-- | <i>Deprecated: better use mapFarmS or mapOfflineFarmS instead</i>
map_offlineFarm :: (Trans a, Trans b) => (a -> b) -> [a] -> [b]

-- | Deprecated: Parallel map variants with map interface using noPe worker
--   processes.

-- | <i>Deprecated: better use mapFarmS or mapOfflineFarmS instead</i>
map_ssf :: (Trans a, Trans b) => (a -> b) -> [a] -> [b]


-- | This Haskell module defines map-reduce skeletons for the parallel
--   functional language Eden.
--   
--   Depends on GHC. Using standard GHC, you will get a threaded simulation
--   of Eden. Use the forked GHC-Eden compiler from
--   http://www.mathematik.uni-marburg.de/~eden for a parallel build.
--   
--   Eden Group ( http://www.mathematik.uni-marburg.de/~eden ) Depends on
--   the Eden Compiler.
module Control.Parallel.Eden.MapReduce
mapRedr :: (b -> c -> c) -> c -> (a -> b) -> [a] -> c
mapRedl :: (c -> b -> c) -> c -> (a -> b) -> [a] -> c
mapRedl' :: (c -> b -> c) -> c -> (a -> b) -> [a] -> c

-- | Basic parMapRedr skeleton - as many processes as noPe. local
--   pre-folding per PE and final folding of PE-results via different fold
--   variants
parMapRedr :: (Trans a, Trans b) => (b -> b -> b) -> b -> (a -> b) -> [a] -> b

-- | Basic parMapRedl skeleton - as many processes as noPe. local
--   pre-folding per PE and final folding of PE-results via different fold
--   variants
parMapRedl :: (Trans a, Trans b) => (b -> b -> b) -> b -> (a -> b) -> [a] -> b

-- | Basic parMapRedl' skeleton - as many processes as noPe. local
--   pre-folding per PE and final folding of PE-results via different fold
--   variants
parMapRedl' :: (Trans a, Trans b) => (b -> b -> b) -> b -> (a -> b) -> [a] -> b

-- | Offline parMapRedr skeleton - as many processes as noPe. local
--   pre-folding per PE and final folding of PE-results via different fold
--   variants, BUT local selection of input sub-list by worker processes
offlineParMapRedr :: (Trans a, Trans b) => (b -> b -> b) -> b -> (a -> b) -> [a] -> b

-- | Offline parMapRedl skeleton - as many processes as noPe. local
--   pre-folding per PE and final folding of PE-results via different fold
--   variants, BUT local selection of input sub-list by worker processes
offlineParMapRedl :: (Trans a, Trans b) => (b -> b -> b) -> b -> (a -> b) -> [a] -> b

-- | Offline parMapRedl' skeleton - as many processes as noPe. local
--   pre-folding per PE and final folding of PE-results via different fold
--   variants, BUT local selection of input sub-list by worker processes
offlineParMapRedl' :: (Trans a, Trans b) => (b -> b -> b) -> b -> (a -> b) -> [a] -> b


-- | This Haskell module defines divide-and-conquer skeletons for the
--   parallel functional language Eden.
--   
--   All divide-and-conquer algorithms are parameterised with control
--   functions which decide if a problem is trivial, how to solve a trivial
--   problem, how to split a non-trivial problem into smaller problems and
--   how to combine solutions of subproblems into a solution of the
--   problem.
--   
--   Depends on GHC. Using standard GHC, you will get a threaded simulation
--   of Eden. Use the forked GHC-Eden compiler from
--   http://www.mathematik.uni-marburg.de/~eden for a parallel build.
--   
--   Eden Group ( http://www.mathematik.uni-marburg.de/~eden )
module Control.Parallel.Eden.DivConq
type DivideConquer a b = (a -> Bool) -> (a -> b) -> (a -> [a]) -> (a -> [b] -> b) -> a -> b

-- | The simple interface (deprecated): combine function without input
type DivideConquerSimple a b = (a -> Bool) -> (a -> b) -> (a -> [a]) -> ([b] -> b) -> a -> b

-- | Sequential Version.
dc :: DivideConquer a b

-- | Simple parMap parallelisation with depth control but no placement
--   control. This variant allows to give an additional depth parameter for
--   the recursion, proceeding in a sequential manner when
--   <tt>depth=0</tt>. The process scheme unfolds the call tree on
--   processors chosen by the runtime environment. Round-Robin distribution
--   is unfavourable for this skeleton, better use RTS option <tt>+RTS
--   -qrnd</tt> when using it.
parDC :: (Trans a, Trans b) => Int -> DivideConquer a b

-- | Distributed-expansion divide-and-conquer skeleton (tutorial version,
--   similar to dcNTickets).
disDC :: (Trans a, Trans b) => Int -> Places -> DivideConquer a b

-- | offline distributed-expansion divide-and-conquer skeleton.
offline_disDC :: Trans b => Int -> [Int] -> DivideConquer a b

-- | DC skeleton with fixed branching degree, parallel depth control and
--   explicit process placement (tree-shaped process creation, one task in
--   each recursive step stays local).
disDCdepth :: (Trans a, Trans b) => Int -> Int -> DivideConquer a b

-- | Like <a>disDCdepth</a>, but controls parallelism by limiting the
--   number of processes instead of the parallel depth.
disDCn :: (Trans a, Trans b) => Int -> Int -> DivideConquer a b

-- | DC Skeleton with flat expansion of upper DC-tree levels, takes custom
--   map skeletons to solve expanded tasks (a sequential map skeleton leads
--   to a sequential DC-skeleton).
flatDC :: (Trans a, Trans b) => ((a -> b) -> [a] -> [b]) -> Int -> DivideConquer a b

-- | Like <a>dc</a> but uses simple DC Interface.

-- | <i>Deprecated: better use dc instead</i>
divConSeq :: (Trans a, Trans b) => DivideConquerSimple a b

-- | Tutorial version, same as <a>dc</a>

-- | <i>Deprecated: better use dc instead</i>
divConSeq_c :: (Trans a, Trans b) => DivideConquer a b

-- | Straightforward implementation.
--   
--   The straightforward method to parallelise divide-and-conquer
--   algorithms is to unfold the call tree onto different processors. The
--   process scheme unfolds the call tree on processors chosen by the
--   runtime environment. Round-Robin distribution is unfavourable for this
--   skeleton, better use runtime option <tt>-qrnd</tt> when using it.

-- | <i>Deprecated: better use parDC instead</i>
divCon :: (Trans a, Trans b) => DivideConquerSimple a b

-- | Like <a>divCon</a> but with different combine signature (takes the
--   original problem as additional input).

-- | <i>Deprecated: better use parDC instead</i>
divCon_c :: (Trans a, Trans b) => DivideConquer a b

-- | Like <a>parDC</a> but uses simple DC Interface.

-- | <i>Deprecated: better use parDC instead</i>
divConD :: (Trans a, Trans b) => Int -> DivideConquerSimple a b

-- | Tutorial version, same as <a>parDC</a>.

-- | <i>Deprecated: better use parDC instead</i>
divConD_c :: (Trans a, Trans b) => Int -> DivideConquer a b

-- | Like <a>disDCdepth</a> but uses simple DC Interface.

-- | <i>Deprecated: better use disDCdepth instead</i>
dcN :: (Trans a, Trans b) => Int -> Int -> DivideConquerSimple a b

-- | Tutorial version, same as <a>disDCdepth</a>

-- | <i>Deprecated: better use disDCdepth instead</i>
dcN_c :: (Trans a, Trans b) => Int -> Int -> DivideConquer a b

-- | Like <a>disDCn</a> but uses simple DC Interface.

-- | <i>Deprecated: better use disDCn instead</i>
dcN' :: (Trans a, Trans b) => Int -> Int -> DivideConquerSimple a b

-- | Tutorial version, same as <a>disDCn</a>.

-- | <i>Deprecated: better use disDCn instead</i>
dcN_c' :: (Trans a, Trans b) => Int -> Int -> DivideConquer a b

-- | Like <a>disDC</a>, but differs in demand control and uses simple DC
--   Interface.

-- | <i>Deprecated: better use disDC instead</i>
dcNTickets :: (Trans a, Trans b) => Int -> Places -> DivideConquerSimple a b

-- | Like <a>disDC</a>, but differs in demand control.

-- | <i>Deprecated: better use disDC instead</i>
dcNTickets_c :: (Trans a, Trans b) => Int -> Places -> DivideConquer a b

-- | Like as <a>flatDC</a> but uses simple DC Interface.

-- | <i>Deprecated: better use flatDC instead</i>
divConFlat :: (Trans a, Trans b) => ((a -> b) -> [a] -> [b]) -> Int -> DivideConquerSimple a b

-- | Tutorial version, same as <a>flatDC</a>.

-- | <i>Deprecated: better use flatDC instead</i>
divConFlat_c :: (Trans a, Trans b) => ((a -> b) -> [a] -> [b]) -> Int -> DivideConquer a b
instance Show a => Show (Tree a)
instance NFData a => NFData (Tree a)


-- | This Haskell module defines topology skeletons for the parallel
--   functional language Eden. Topology skeletons are skeletons that
--   implement a network of processes interconnected by a characteristic
--   communication topology.
--   
--   Depends on GHC. Using standard GHC, you will get a threaded simulation
--   of Eden. Use the forked GHC-Eden compiler from
--   http://www.mathematik.uni-marburg.de/~eden for a parallel build.
--   
--   Eden Group ( http://www.mathematik.uni-marburg.de/~eden )
module Control.Parallel.Eden.Topology

-- | Simple pipe where the parent process creates all pipe processes. The
--   processes communicate their results via the caller process.
pipe :: Trans a => [a -> a] -> a -> a

-- | Process pipe where the processes communicate their Remote Data handles
--   via the caller process but fetch the actual data from their
--   predecessor processes
pipeRD :: Trans a => [a -> a] -> RD a -> RD a

-- | Simple ring skeleton (tutorial version) using remote data for
--   providing direct inter-ring communication without input distribution
--   and output combination
ringSimple :: (Trans i, Trans o, Trans r) => (i -> r -> (o, r)) -> [i] -> [o]

-- | The ring establishes a ring topology, the ring process function
--   transforms the initial input of a ring process and the input stream
--   from the ring into the ring output stream and the ring processes final
--   result. The same function is used by every ring process. Use ringFl if
--   you need different functions in the processes. Use ringAt if explicit
--   placement is desired.
ring :: (Trans a, Trans b, Trans r) => (i -> [a]) -> ([b] -> o) -> (a -> r -> (b, r)) -> i -> o

-- | The ringFl establishes a ring topology, the ring process functions
--   transform the initial input of a ring process and the input stream
--   from the ring into the ring output stream and the ring processes'
--   final result. Every ring process applies an individual function which
--   e.g. allows to route individual offline input into the ring processes.
--   Use ringFlAt if explicit placement is desired.
ringFl :: (Trans a, Trans b, Trans r) => (i -> [a]) -> ([b] -> o) -> [(a -> r -> (b, r))] -> i -> o

-- | Skeleton <tt>ringAt</tt> establishes a ring topology, the ring process
--   function transforms the initial input of a ring process and the input
--   stream from the ring into the ring output stream and the ring
--   processes' final result. The same function is used by every ring
--   process. Use ringFlAt if you need different functions in the
--   processes. This version uses explicit placement.
ringAt :: (Trans a, Trans b, Trans r) => Places -> (i -> [a]) -> ([b] -> o) -> (a -> r -> (b, r)) -> i -> o

-- | The ringFlAt establishes a ring topology, the ring process functions
--   transform the initial input of a ring process and the input stream
--   from the ring into the ring output stream and the ring processes'
--   final result. Every ring process applies its individual function which
--   e.g. allows to route individual offline input into the ring processes.
--   This version uses explicit placement.
ringFlAt :: (Trans a, Trans b, Trans r) => Places -> (i -> [a]) -> ([b] -> o) -> [(a -> r -> (b, r))] -> i -> o

-- | Parallel torus skeleton (tutorial version) with stream rotation in 2
--   directions: initial inputs for each torus element are given. The node
--   function is used on each torus element to transform the initial input
--   and a stream of inputs from each direction to a stream of outputs to
--   each direction. Each torus input should have the same size in both
--   dimensions, otherwise the smaller input will determine the size of the
--   torus.
torus :: (Trans a, Trans b, Trans c, Trans d) => (c -> [a] -> [b] -> (d, [a], [b])) -> [[c]] -> [[d]]

-- | The skeleton creates as many processes as elements in the input list
--   (<tt>np</tt>). The processes get all-to-all connected, each process
--   input is transformed to <tt>np</tt> intermediate values by the first
--   parameter function, where the <tt>i</tt>-th value will be send to
--   process <tt>i</tt>. The second transformation function combines the
--   initial input and the <tt>np</tt> received intermediate values to the
--   final output.
allToAllRDAt :: (Trans a, Trans b, Trans i) => Places -> (Int -> a -> [i]) -> (a -> [i] -> b) -> [RD a] -> [RD b]

-- | The skeleton creates as many processes as elements in the input list
--   (<tt>np</tt>). The processes get all-to-all connected, each process
--   input is transformed to <tt>np</tt> intermediate values by the first
--   parameter function, where the <tt>i</tt>-th value will be send to
--   process <tt>i</tt>. The second transformation function combines the
--   initial input and the <tt>np</tt> received intermediate values to the
--   final output.
allToAllRD :: (Trans a, Trans b, Trans i) => (Int -> a -> [i]) -> (a -> [i] -> b) -> [RD a] -> [RD b]

-- | Parallel transposition for matrizes which are row-wise round robin
--   distributed among the machines, the transposed result matrix is also
--   row-wise round robin distributed.
parTransposeRDAt :: Trans b => Places -> [RD [[b]]] -> [RD [[b]]]

-- | Parallel transposition for matrizes which are row-wise round robin
--   distributed among the machines, the transposed result matrix is also
--   row-wise round robin distributed.
parTransposeRD :: Trans b => [RD [[b]]] -> [RD [[b]]]

-- | Performs an all-gather using all to all comunication (based on
--   allToAllRDAt). The initial transformation is applied in the processes
--   to obtain the values that will be reduced. The final combine function
--   is used to create a processes outputs from the initial input and the
--   gathered values.
allGatherRDAt :: (Trans a, Trans b, Trans c) => Places -> (a -> b) -> (a -> [b] -> c) -> [RD a] -> [RD c]

-- | Performs an all-gather using all to all comunication (based on
--   allToAllRDAt). The initial transformation is applied in the processes
--   to obtain the values that will be reduced. The final combine function
--   is used to create a processes outputs from the initial input and the
--   gathered values.
allGatherRD :: (Trans a, Trans b, Trans c) => (a -> b) -> (a -> [b] -> c) -> [RD a] -> [RD c]

-- | Performs an all-reduce with the reduce function using a butterfly
--   scheme. The initial transformation is applied in the processes to
--   obtain the values that will be reduced. The final combine function is
--   used to create a processes output. result from the initial input and
--   the reduced value.
allReduceRDAt :: (Trans a, Trans b, Trans c) => Places -> (a -> b) -> (b -> b -> b) -> (a -> b -> c) -> [RD a] -> [RD c]

-- | Performs an all-reduce with the reduce function using a butterfly
--   scheme. The initial transformation is applied in the processes to
--   obtain the values that will be reduced. The final combine function is
--   used to create a processes outputs. result from the initial input and
--   the reduced value.
allReduceRD :: (Trans a, Trans b, Trans c) => (a -> b) -> (b -> b -> b) -> (a -> b -> c) -> [RD a] -> [RD c]

-- | Performs an all-gather using a butterfly scheme (based on
--   allReduceRDAt). The initial transformation is applied in the processes
--   to obtain the values that will be reduced. The final combine function
--   is used to create a processes outputs from the initial input and the
--   gathered values.
allGatherBuFlyRDAt :: (Trans a, Trans b, Trans c) => Places -> (a -> b) -> (a -> [b] -> c) -> [RD a] -> [RD c]

-- | Performs an all-gather using a butterfly scheme (based on
--   allReduceRDAt). The initial transformation is applied in the processes
--   to obtain the values that will be reduced. The final combine function
--   is used to create a processes outputs from the initial input and the
--   gathered values.
allGatherBuFlyRD :: (Trans a, Trans b, Trans c) => (a -> b) -> (a -> [b] -> c) -> [RD a] -> [RD c]


-- | This Haskell module defines workpool skeletons for dynamic task
--   distribution for the parallel functional language Eden.
--   
--   Depends on GHC. Using standard GHC, you will get a threaded simulation
--   of Eden. Use the forked GHC-Eden compiler from
--   http://www.mathematik.uni-marburg.de/~eden for a parallel build.
--   
--   Eden Group ( http://www.mathematik.uni-marburg.de/~eden )
module Control.Parallel.Eden.Workpool

-- | Simple workpool (result list in non-deterministic order)
--   
--   Notice: Result list in non-deterministic order.
workpool :: (Trans t, Trans r) => Int -> Int -> (t -> r) -> [t] -> [r]

-- | Sorted workpool: Efficient implementation using a the distribution
--   lookup list.
--   
--   Notice: Results in the order of the tasks.
workpoolSorted :: (Trans t, Trans r) => Int -> Int -> (t -> r) -> [t] -> [r]

-- | Non-blocking sorted workpool (results in the order of the tasks).
--   Result list is structurally defined up to the position where tasks are
--   distributed, independent of the received worker results. This version
--   needs still performance testing. This version takes places for
--   instantiation.
--   
--   Notice: Results in the order of the tasks.
workpoolSortedNonBlock :: (Trans t, Trans r) => Int -> Int -> (t -> r) -> [t] -> [r]

-- | Simple workpool with additional reduce function for worker outputs.
--   This version takes places for instantiation.
--   
--   Notice: Result list in non-deterministic order.
workpoolReduce :: (Trans t, Trans r, Trans r') => Int -> Int -> (r' -> r -> r) -> r -> (t -> r') -> [t] -> [r]

-- | Simple workpool (result list in non-deterministic order) This version
--   takes places for instantiation.
--   
--   Notice: Result list in non-deterministic order.
workpoolAt :: (Trans t, Trans r) => Places -> Int -> Int -> (t -> r) -> [t] -> [r]

-- | Sorted workpool (results in the order of the tasks). This version
--   takes places for instantiation.
workpoolSortedAt :: (Trans t, Trans r) => Places -> Int -> Int -> (t -> r) -> [t] -> [r]

-- | Non-blocking sorted workpool. Result list is structurally defined up
--   to the position where tasks are distributed, independent of the
--   received worker results. This version needs still performance testing.
--   
--   Notice: Results in the order of the tasks.
workpoolSortedNonBlockAt :: (Trans t, Trans r) => Places -> Int -> Int -> (t -> r) -> [t] -> [r]

-- | Simple workpool with additional reduce function for worker outputs.
--   This version takes places for instantiation.
--   
--   Notice: Result list in non-deterministic order.
workpoolReduceAt :: (Trans t, Trans r, Trans r') => Places -> Int -> Int -> (r' -> r -> r) -> r -> (t -> r') -> [t] -> [r]

-- | Workpool version with one result stream for each worker and meta
--   information about the task distribution. This meta-skeleton can be
--   used to define workpool-skeletons which can reestablish the result
--   list order.
--   
--   Notice: Result list in non-deterministic order.
workpoolAuxAt :: (Trans t, Trans r) => Places -> Int -> Int -> (t -> r) -> [t] -> ([Int], [[Int]], [[r]])

-- | Hierachical WP-Skeleton. The worker function is mapped to the worker
--   input stream (list type). A worker produces a result. The workers are
--   located on the leaves of a WP-hierarchy, in the intermediate levels
--   are submasters which unload the master by streaming <tt>result</tt>
--   streams of their child processes into a single result stream.
--   
--   Notice: Result list in non-deterministic order.
wpNested :: (Trans t, Trans r) => [Int] -> [Int] -> (t -> r) -> [t] -> [r]

-- | Hierachical WP-Skeleton with dynamic task creation. The worker
--   function is mapped to the worker input stream (list type). A worker
--   produces a tuple of result and dynamicly created tasks for each
--   processed task. The workers are located on the leaves of a
--   WP-hierarchy, in the intermediate levels are submasters which unload
--   the master by streamlining 'result/newtask' streams of their child
--   processes into a single result/newtask stream. Furthermore, the
--   submasters retain locally half of the tasks which are dynamically
--   created by the workers in their subtree.
--   
--   Notice: Result list in non-deterministic order.
wpDynNested :: (Trans t, Trans r) => [Int] -> [Int] -> (t -> (r, [t])) -> [t] -> [r]

-- | Simple interface for <a>wpDynNested</a>. Parameters are the number of
--   child processes, the first level branching degree, the nesting depth
--   (use 1 for a single master), and the task prefetch amount for the
--   worker level. All processes that are not needed for the submasters are
--   used for the workers. If the number of submasters in the last level
--   and the number of remaining child processes are prime to each other,
--   then the next larger divisor is chosen for the number of workers.
--   
--   Notice: Result list in non-deterministic order.
wpDNI :: (Trans t, Trans r) => Int -> Int -> Int -> Int -> (t -> (r, [t])) -> [t] -> [r]

-- | A distributed workpool skeleton that uses task generation and a global
--   state (s) with a total order. Split and Detatch policy must give tasks
--   away (may not produce empty lists), unless all tasks are pruned!
distribWPAt :: (Trans onT, Trans t, Trans r, Trans s, NFData r') => Places -> ((t, s) -> (Maybe (r', s), [t])) -> (Maybe ofT -> Maybe onT -> [t]) -> ([Maybe (r', s)] -> s -> r) -> ([t] -> [t] -> s -> [t]) -> ([t] -> s -> ([t], Maybe (t, s))) -> ([t] -> s -> ([t], [t])) -> (s -> s -> Bool) -> s -> [ofT] -> [onT] -> [r]

-- | Deprecated, same as <a>workpoolSortedNonBlock</a>

-- | <i>Deprecated: better use workpoolSortedNonBlock instead</i>
masterWorker :: (Trans a, Trans b) => Int -> Int -> (a -> b) -> [a] -> [b]

-- | Deprecated, same as <a>wpNested</a>

-- | <i>Deprecated: better use wpNested instead</i>
mwNested :: (Trans t, Trans r) => [Int] -> [Int] -> (t -> r) -> [t] -> [r]

-- | Deprecated, same as <a>wpDynNested</a>

-- | <i>Deprecated: better use wpDynNested instead</i>
mwDynNested :: (Trans t, Trans r) => [Int] -> [Int] -> (t -> (r, [t])) -> [t] -> [r]

-- | Deprecated, same as <a>wpDNI</a>

-- | <i>Deprecated: better use wpDNI instead</i>
mwDNI :: (Trans t, Trans r) => Int -> Int -> Int -> Int -> (t -> (r, [t])) -> [t] -> [r]
instance Eq Tag
instance NFData Tag
instance (Trans t, Trans s) => Trans (Req t s)
instance (NFData t, NFData s) => NFData (Req t s)


-- | This Haskell module defines iteration skeletons for Eden.
--   
--   Depends on the Eden Compiler.
--   
--   Eden Project
module Control.Parallel.Eden.Iteration

-- | This is the basic implementation, using places for explicit process |
--   placement of the worker processes.
iterUntilAt :: (Trans wl, Trans t, Trans sr) => Places -> (inp -> ([wl], [t], ml)) -> (wl -> t -> (sr, wl)) -> (ml -> [sr] -> Either r ([t], ml)) -> inp -> r

-- | The iterUntil skeleton is an iterated map skeleton. Each worker
--   function transforms one local worker state and one task per iteration.
--   The result is the next local state and the iterations result, which is
--   send back to the master. The master transforms the output of all tasks
--   of one iteration and a local master state into the worker inputs of
--   the next iteration and a new master state using the combine function
--   (output: Right tasks masterState) or decides to terminate the
--   iteration (output: Left result). The input transformation function
--   generates all initial worker states and initial worker tasks and the
--   initial master state from the skeleton.
iterUntil :: (Trans wl, Trans t, Trans sr) => (inp -> ([wl], [t], ml)) -> (wl -> t -> (sr, wl)) -> (ml -> [sr] -> Either r ([t], ml)) -> inp -> r
