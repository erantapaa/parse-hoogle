-- Hoogle documentation, generated by Haddock
-- See Hoogle, http://www.haskell.org/hoogle/


-- | Scoring functions commonly used for evaluation in NLP and IR
--   
@package nlp-scores
@version 0.7.0

module NLP.Scores.Internals

-- | Count table
data Counts a b
Counts :: !(Map (Pair a b) Count) -> !(Map a Count) -> !(Map b Count) -> Counts a b

-- | Counts of both components
joint :: Counts a b -> !(Map (Pair a b) Count)

-- | Counts of the first component
marginalFst :: Counts a b -> !(Map a Count)

-- | Counts of the second component
marginalSnd :: Counts a b -> !(Map b Count)

-- | A count
type Count = Double

-- | The empty count table
empty :: (Ord a, Ord b) => Counts a b
unionPlus :: (Num a, Ord k) => Map k a -> Map k a -> Map k a
instance (Ord a, Ord b) => Monoid (Counts a b)


-- | Scoring functions commonly used for evaluation of NLP systems. Most
--   functions in this module work on sequences which are instances of
--   <a>Foldable</a>, but some take a precomputed table of <a>Counts</a>.
--   This will give a speedup if you want to compute multiple scores on the
--   same data. For example to compute the Mutual Information, Variation of
--   Information and the Adjusted Rand Index on the same pair of
--   clusterings:
--   
--   <pre>
--   &gt;&gt;&gt; let cs = counts "abcabc" "abaaba"
--   
--   &gt;&gt;&gt; mapM_ (print . ($ cs)) [mi, ari, vi]
--   
--   &gt;&gt;&gt; 0.9182958340544894
--   
--   &gt;&gt;&gt; 0.4444444444444445
--   
--   &gt;&gt;&gt; 0.6666666666666663
--   </pre>
module NLP.Scores

-- | Error rate: the proportion of elements in the first sequence NOT equal
--   to elements at corresponding positions in second sequence. Sequences
--   should be of equal lengths.
errorRate :: (Eq a, Fractional c, Traversable t, Foldable s) => t a -> s a -> c

-- | Accuracy: the proportion of elements in the first sequence equal to
--   elements at corresponding positions in second sequence. Sequences
--   should be of equal lengths.
accuracy :: (Eq a, Fractional c, Traversable t, Foldable s) => t a -> s a -> c

-- | Reciprocal rank: the reciprocal of the rank at which the first
--   arguments occurs in the sequence given as the second argument.
recipRank :: (Eq a, Fractional b, Foldable t) => a -> t a -> b

-- | Average precision.
--   <a>http://en.wikipedia.org/wiki/Information_retrieval#Average_precision</a>
avgPrecision :: (Fractional n, Ord a, Foldable t) => Set a -> t a -> n

-- | Adjusted Rand Index: <a>http://en.wikipedia.org/wiki/Rand_index</a>
ari :: (Ord a, Ord b) => Counts a b -> Double

-- | Mutual information: MI(X,Y) = H(X) - H(X|Y) = H(Y) - H(Y|X). Also
--   known as information gain.
mi :: (Ord a, Ord b) => Counts a b -> Double

-- | Variation of information: VI(X,Y) = H(X) + H(Y) - 2 MI(X,Y)
vi :: (Ord a, Ord b) => Counts a b -> Double

-- | Log-likelihood ratio for two binomial distributions. H_0: P(x|y) = p =
--   P(x|~y) H_1: P(x|y) = p1 =/= p2 = P(x|~y)
logLikelihoodRatio :: (Ord a, Ord b) => Counts a b -> a -> b -> Double

-- | Kullback-Leibler divergence: KL(X,Y) = SUM_i P(X=i)
--   log_2(P(X=i)/P(Y=i)). The distributions can be unnormalized.
kullbackLeibler :: (Eq a, Floating a, Foldable f, Traversable t) => t a -> f a -> a

-- | Jensen-Shannon divergence: JS(X,Y) = 1/2 KL(X,(X+Y)/2) + 1/2
--   KL(Y,(X+Y)/2). The distributions can be unnormalized.
jensenShannon :: (Eq a, Floating a, Traversable t, Traversable u) => t a -> u a -> a

-- | A count
type Count = Double

-- | Count table
data Counts a b

-- | Creates count table <a>Counts</a>
counts :: (Ord a, Ord b, Traversable t, Foldable s) => t a -> s b -> Counts a b

-- | The sum of a sequence of numbers
sum :: (Foldable t, Num a) => t a -> a

-- | The mean of a sequence of numbers.
mean :: (Foldable t, Fractional n, Real a) => t a -> n

-- | Jaccard coefficient J(A,B) = |AB| / |A union B|
jaccard :: (Fractional n, Ord a) => Set a -> Set a -> n

-- | Entropy: H(X) = -SUM_i P(X=i) log_2(P(X=i)). <tt>entropy xs</tt> is
--   the entropy of the random variable represented by the sequence
--   <tt>xs</tt>, where each element of <tt>xs</tt> is the count of the one
--   particular value the random variable can take. If you need to compute
--   the entropy from a sequence of outcomes, the following will work:
--   
--   <pre>
--   entropy . elems . histogram
--   </pre>
entropy :: (Floating c, Foldable t) => t c -> c

-- | <tt>histogram xs</tt> is returns the map of the frequency counts of
--   the elements in sequence <tt>xs</tt>
histogram :: (Num a, Ord k, Foldable t) => t k -> Map k a

-- | Joint count
countJoint :: (Ord a, Ord b) => a -> b -> Counts a b -> Count

-- | Count of first element
countFst :: Ord k => k -> Counts k b -> Count

-- | Count of second element
countSnd :: Ord k => k -> Counts a k -> Count

-- | Total element count
countTotal :: Counts a k -> Count

-- | List of values of first element
fstElems :: Counts k b -> [k]

-- | List of values of second element
sndElems :: Counts a k -> [k]
