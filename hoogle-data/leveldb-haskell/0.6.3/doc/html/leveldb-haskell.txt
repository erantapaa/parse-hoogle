-- Hoogle documentation, generated by Haddock
-- See Hoogle, http://www.haskell.org/hoogle/


-- | Haskell bindings to LevelDB
--   
--   From <a>http://code.google.com/p/snappy</a>:
--   
--   LevelDB is a fast key-value storage library written at Google that
--   provides an ordered mapping from string keys to string values.
--   
--   This library provides a Haskell language binding to LeveldDB. It is in
--   very early stage and has seen very limited testing.
--   
--   Note: as of v1.3, LevelDB can be built as a shared library. Thus, as
--   of v0.1.0 of this library, LevelDB is no longer bundled and must be
--   installed on the target system (version 1.7 or greater is required).
@package leveldb-haskell
@version 0.6.3


-- | (Mostly mechanical) adaptation of the <a>Data.Stream</a> module from
--   the <a>stream-fusion</a> package to a monadic <a>Stream</a> datatype
--   similar to the one <a>proposed</a> by Michael Snoyman for the
--   <a>conduit</a> package.
--   
--   The intention here is to provide a high-level, <a>Data.List</a>-like
--   interface to <a>Database.LevelDB.Iterator</a>s with predictable space
--   and time complexity (see <a>Database.LevelDB.Streaming</a>), and
--   without introducing a dependency eg. on one of the streaming libraries
--   (all relevant datatypes are fully exported, though, so it should be
--   straightforward to write wrappers for your favourite streaming
--   library).
--   
--   Fusion and inlining rules and strictness annotations have been put in
--   place faithfully, and may need further profiling. Also, some functions
--   (from <a>Data.List</a>) have been omitted for various reasons. Missing
--   functions may be added upon <a>request</a>.
module Data.Stream.Monadic
data Step a s
Yield :: a -> !s -> Step a s
Skip :: !s -> Step a s
Done :: Step a s
data Stream m a
Stream :: (s -> m (Step a s)) -> (m s) -> Stream m a
toList :: (Functor m, Monad m) => Stream m a -> m [a]
fromList :: Monad m => [a] -> Stream m a
append :: (Functor m, Monad m) => Stream m a -> Stream m a -> Stream m a
cons :: (Functor m, Monad m) => a -> Stream m a -> Stream m a
snoc :: (Functor m, Monad m) => Stream m a -> a -> Stream m a

-- | Unlike <a>head</a>, this function does not diverge if the
--   <a>Stream</a> is empty. Instead, <a>Nothing</a> is returned.
head :: Monad m => Stream m a -> m (Maybe a)

-- | Unlike <a>last</a>, this function does not diverge if the
--   <a>Stream</a> is empty. Instead, <a>Nothing</a> is returned.
last :: Monad m => Stream m a -> m (Maybe a)

-- | Unlike <a>tail</a>, this function does not diverge if the
--   <a>Stream</a> is empty. Instead, it is the identity in this case.
tail :: (Functor m, Monad m) => Stream m a -> Stream m a

-- | Unlike <a>init</a>, this function does not diverge if the
--   <a>Stream</a> is empty. Instead, it is the identity in this case.
init :: (Functor m, Monad m) => Stream m a -> Stream m a
null :: Monad m => Stream m a -> m Bool
length :: Monad m => Stream m a -> m Int
map :: Monad m => (a -> b) -> Stream m a -> Stream m b
mapM :: (Functor m, Monad m) => (a -> m b) -> Stream m a -> Stream m b
mapM_ :: (Functor m, Monad m) => (a -> m b) -> Stream m a -> Stream m ()
reverse :: (Functor m, Monad m) => Stream m a -> m (Stream m a)
intersperse :: (Functor m, Monad m) => a -> Stream m a -> Stream m a
intercalate :: (Functor m, Monad m) => Stream m a -> Stream m [a] -> Stream m a
foldl :: Monad m => (b -> a -> b) -> b -> Stream m a -> m b
foldl' :: Monad m => (b -> a -> b) -> b -> Stream m a -> m b
foldr :: (Functor m, Monad m) => (a -> b -> b) -> b -> Stream m a -> m b
foldMap :: (Monoid m, Functor n, Monad n) => (a -> m) -> Stream n a -> n m
foldM :: Monad m => (b -> a -> m b) -> b -> Stream m a -> m b
foldM_ :: Monad m => (b -> a -> m b) -> b -> Stream m a -> m ()
concat :: (Functor m, Monad m) => Stream m [a] -> Stream m a
concatMap :: (Functor m, Monad m) => (a -> Stream m b) -> Stream m a -> Stream m b
and :: (Functor m, Monad m) => Stream m Bool -> m Bool
or :: (Functor m, Monad m) => Stream m Bool -> m Bool
any :: Monad m => (a -> Bool) -> Stream m a -> m Bool
all :: Monad m => (a -> Bool) -> Stream m a -> m Bool
sum :: (Num a, Monad m) => Stream m a -> m a
product :: (Num a, Monad m) => Stream m a -> m a
scanl :: (Functor m, Monad m) => (b -> a -> b) -> b -> Stream m a -> Stream m b
iterate :: Monad m => (a -> a) -> a -> Stream m a
repeat :: Monad m => a -> Stream m a
replicate :: Monad m => Int -> a -> Stream m a

-- | Unlike <a>cycle</a>, this function does not diverge if the
--   <a>Stream</a> is empty. Instead, it is the identity in this case.
cycle :: (Functor m, Monad m) => Stream m a -> Stream m a
unfoldr :: Monad m => (b -> Maybe (a, b)) -> b -> Stream m a

-- | Build a stream from a monadic seed (or state function).
unfoldrM :: (Functor m, Monad m) => (b -> Maybe (a, m b)) -> m b -> Stream m a
take :: (Functor m, Monad m) => Int -> Stream m a -> Stream m a
drop :: (Functor m, Monad m) => Int -> Stream m a -> Stream m a

-- | <pre>
--   splitAt n s = (take n s, drop n s)
--   </pre>
--   
--   Note that the resulting <tt>Streams</tt> share their state, so do not
--   interleave traversals.
splitAt :: (Functor m, Monad m) => Int -> Stream m a -> (Stream m a, Stream m a)
takeWhile :: Monad m => (a -> Bool) -> Stream m a -> Stream m a
dropWhile :: (Functor m, Monad m) => (a -> Bool) -> Stream m a -> Stream m a
span :: (Functor m, Monad m) => (a -> Bool) -> Stream m a -> (Stream m a, Stream m a)
break :: (Functor m, Monad m) => (a -> Bool) -> Stream m a -> (Stream m a, Stream m a)
isPrefixOf :: (Eq a, Monad m) => Stream m a -> Stream m a -> m Bool

-- | Note that this is:
--   
--   <pre>
--   isSuffixOf a b = reverse a `isPrefixOf` reverse b
--   </pre>
--   
--   It might be more efficient to construct the <a>Stream</a>s in reverse
--   order and use <a>isPrefixOf</a> directly, as <a>reverse</a> is
--   <i>O(n)</i> and requires a finite stream argument.
isSuffixOf :: (Eq a, Functor m, Monad m) => Stream m a -> Stream m a -> m Bool
elem :: (Eq a, Monad m) => a -> Stream m a -> m Bool
notElem :: (Eq a, Monad m) => a -> Stream m a -> m Bool
lookup :: (Eq a, Monad m) => a -> Stream m (a, b) -> m (Maybe b)
find :: Monad m => (a -> Bool) -> Stream m a -> m (Maybe a)
filter :: Monad m => (a -> Bool) -> Stream m a -> Stream m a
zip :: (Functor m, Applicative m, Monad m) => Stream m a -> Stream m b -> Stream m (a, b)
zip3 :: (Functor m, Applicative m, Monad m) => Stream m a -> Stream m b -> Stream m c -> Stream m (a, b, c)
zip4 :: (Functor m, Applicative m, Monad m) => Stream m a -> Stream m b -> Stream m c -> Stream m d -> Stream m (a, b, c, d)
zipWith :: (Functor m, Applicative m, Monad m) => (a -> b -> c) -> Stream m a -> Stream m b -> Stream m c
zipWith3 :: (Functor m, Applicative m, Monad m) => (a -> b -> c -> d) -> Stream m a -> Stream m b -> Stream m c -> Stream m d
zipWith4 :: (Functor m, Applicative m, Monad m) => (a -> b -> c -> d -> e) -> Stream m a -> Stream m b -> Stream m c -> Stream m d -> Stream m e
unzip :: (Functor m, Monad m) => Stream m (a, b) -> m ([a], [b])
unzip3 :: (Functor m, Monad m) => Stream m (a, b, c) -> m ([a], [b], [c])
unzip4 :: (Functor m, Monad m) => Stream m (a, b, c, d) -> m ([a], [b], [c], [d])
delete :: (Eq a, Functor m, Monad m) => a -> Stream m a -> Stream m a
insert :: (Ord a, Functor m, Monad m) => a -> Stream m a -> Stream m a
deleteBy :: (Functor m, Monad m) => (a -> a -> Bool) -> a -> Stream m a -> Stream m a
insertBy :: (Functor m, Monad m) => (a -> a -> Ordering) -> a -> Stream m a -> Stream m a
genericLength :: (Num i, Functor m, Monad m) => Stream m a -> m i
genericTake :: (Integral i, Functor m, Monad m) => i -> Stream m a -> Stream m a
genericDrop :: (Integral i, Functor m, Monad m) => i -> Stream m a -> Stream m a
genericSplitAt :: (Integral i, Functor m, Monad m) => i -> Stream m a -> (Stream m a, Stream m a)
genericReplicate :: (Integral i, Functor m, Monad m) => i -> a -> Stream m a

-- | Like <tt>fromList ([n..m] :: [Int])</tt> but avoids allocating a list
enumFromToInt :: Monad m => Int -> Int -> Stream m Int

-- | Like <tt>fromList ([n..m] :: [Char])</tt> but avoids allocating a list
enumFromToChar :: Monad m => Char -> Char -> Stream m Char

-- | Like <tt>fromList ([n,n+d..] :: [Integer])</tt> but avoids allocating
--   a list
enumDeltaInteger :: Monad m => Integer -> Integer -> Stream m Integer
instance Monad m => Functor (Stream m)


module Database.LevelDB.C
data LevelDB
data LCache
data LComparator
data LIterator
data LLogger
data LOptions
data LReadOptions
data LSnapshot
data LWriteBatch
data LWriteOptions
data LFilterPolicy
type LevelDBPtr = Ptr LevelDB
type CachePtr = Ptr LCache
type ComparatorPtr = Ptr LComparator
type IteratorPtr = Ptr LIterator
type LoggerPtr = Ptr LLogger
type OptionsPtr = Ptr LOptions
type ReadOptionsPtr = Ptr LReadOptions
type SnapshotPtr = Ptr LSnapshot
type WriteBatchPtr = Ptr LWriteBatch
type WriteOptionsPtr = Ptr LWriteOptions
type FilterPolicyPtr = Ptr LFilterPolicy
type DBName = CString
type ErrPtr = Ptr CString
type Key = CString
type Val = CString
newtype CompressionOpt
CompressionOpt :: CInt -> CompressionOpt
compressionOpt :: CompressionOpt -> CInt
noCompression :: CompressionOpt
snappyCompression :: CompressionOpt
c_leveldb_open :: OptionsPtr -> DBName -> ErrPtr -> IO LevelDBPtr
c_leveldb_close :: LevelDBPtr -> IO ()
c_leveldb_put :: LevelDBPtr -> WriteOptionsPtr -> Key -> CSize -> Val -> CSize -> ErrPtr -> IO ()
c_leveldb_delete :: LevelDBPtr -> WriteOptionsPtr -> Key -> CSize -> ErrPtr -> IO ()
c_leveldb_write :: LevelDBPtr -> WriteOptionsPtr -> WriteBatchPtr -> ErrPtr -> IO ()

-- | Returns NULL if not found. A malloc()ed array otherwise. Stores the
--   length of the array in *vallen.
c_leveldb_get :: LevelDBPtr -> ReadOptionsPtr -> Key -> CSize -> Ptr CSize -> ErrPtr -> IO CString
c_leveldb_create_snapshot :: LevelDBPtr -> IO SnapshotPtr
c_leveldb_release_snapshot :: LevelDBPtr -> SnapshotPtr -> IO ()

-- | Returns NULL if property name is unknown. Else returns a pointer to a
--   malloc()-ed null-terminated value.
c_leveldb_property_value :: LevelDBPtr -> CString -> IO CString
c_leveldb_approximate_sizes :: LevelDBPtr -> CInt -> Ptr CString -> Ptr CSize -> Ptr CString -> Ptr CSize -> Ptr Word64 -> IO ()
c_leveldb_compact_range :: LevelDBPtr -> CString -> CSize -> CString -> CSize -> IO ()
c_leveldb_destroy_db :: OptionsPtr -> DBName -> ErrPtr -> IO ()
c_leveldb_repair_db :: OptionsPtr -> DBName -> ErrPtr -> IO ()
c_leveldb_create_iterator :: LevelDBPtr -> ReadOptionsPtr -> IO IteratorPtr
c_leveldb_iter_destroy :: IteratorPtr -> IO ()
c_leveldb_iter_valid :: IteratorPtr -> IO CUChar
c_leveldb_iter_seek_to_first :: IteratorPtr -> IO ()
c_leveldb_iter_seek_to_last :: IteratorPtr -> IO ()
c_leveldb_iter_seek :: IteratorPtr -> Key -> CSize -> IO ()
c_leveldb_iter_next :: IteratorPtr -> IO ()
c_leveldb_iter_prev :: IteratorPtr -> IO ()
c_leveldb_iter_key :: IteratorPtr -> Ptr CSize -> IO Key
c_leveldb_iter_value :: IteratorPtr -> Ptr CSize -> IO Val
c_leveldb_iter_get_error :: IteratorPtr -> ErrPtr -> IO ()
c_leveldb_writebatch_create :: IO WriteBatchPtr
c_leveldb_writebatch_destroy :: WriteBatchPtr -> IO ()
c_leveldb_writebatch_clear :: WriteBatchPtr -> IO ()
c_leveldb_writebatch_put :: WriteBatchPtr -> Key -> CSize -> Val -> CSize -> IO ()
c_leveldb_writebatch_delete :: WriteBatchPtr -> Key -> CSize -> IO ()
c_leveldb_writebatch_iterate :: WriteBatchPtr -> Ptr () -> FunPtr (Ptr () -> Key -> CSize -> Val -> CSize) -> FunPtr (Ptr () -> Key -> CSize) -> IO ()
c_leveldb_options_create :: IO OptionsPtr
c_leveldb_options_destroy :: OptionsPtr -> IO ()
c_leveldb_options_set_comparator :: OptionsPtr -> ComparatorPtr -> IO ()
c_leveldb_options_set_filter_policy :: OptionsPtr -> FilterPolicyPtr -> IO ()
c_leveldb_options_set_create_if_missing :: OptionsPtr -> CUChar -> IO ()
c_leveldb_options_set_error_if_exists :: OptionsPtr -> CUChar -> IO ()
c_leveldb_options_set_paranoid_checks :: OptionsPtr -> CUChar -> IO ()
c_leveldb_options_set_info_log :: OptionsPtr -> LoggerPtr -> IO ()
c_leveldb_options_set_write_buffer_size :: OptionsPtr -> CSize -> IO ()
c_leveldb_options_set_max_open_files :: OptionsPtr -> CInt -> IO ()
c_leveldb_options_set_block_size :: OptionsPtr -> CSize -> IO ()
c_leveldb_options_set_block_restart_interval :: OptionsPtr -> CInt -> IO ()
c_leveldb_options_set_compression :: OptionsPtr -> CompressionOpt -> IO ()
c_leveldb_options_set_cache :: OptionsPtr -> CachePtr -> IO ()
type StatePtr = Ptr ()
type Destructor = StatePtr -> ()
type CompareFun = StatePtr -> CString -> CSize -> CString -> CSize -> IO CInt
type NameFun = StatePtr -> CString

-- | Make a FunPtr to a user-defined comparator function
mkCmp :: CompareFun -> IO (FunPtr CompareFun)

-- | Make a destructor FunPtr
mkDest :: Destructor -> IO (FunPtr Destructor)

-- | Make a name FunPtr
mkName :: NameFun -> IO (FunPtr NameFun)
c_leveldb_comparator_create :: StatePtr -> FunPtr Destructor -> FunPtr CompareFun -> FunPtr NameFun -> IO ComparatorPtr
c_leveldb_comparator_destroy :: ComparatorPtr -> IO ()
type CreateFilterFun = StatePtr -> Ptr CString -> Ptr CSize -> CInt -> Ptr CSize -> IO CString
type KeyMayMatchFun = StatePtr -> CString -> CSize -> CString -> CSize -> IO CUChar

-- | Make a FunPtr to a user-defined create_filter function
mkCF :: CreateFilterFun -> IO (FunPtr CreateFilterFun)

-- | Make a FunPtr to a user-defined key_may_match function
mkKMM :: KeyMayMatchFun -> IO (FunPtr KeyMayMatchFun)
c_leveldb_filterpolicy_create :: StatePtr -> FunPtr Destructor -> FunPtr CreateFilterFun -> FunPtr KeyMayMatchFun -> FunPtr NameFun -> IO FilterPolicyPtr
c_leveldb_filterpolicy_destroy :: FilterPolicyPtr -> IO ()
c_leveldb_filterpolicy_create_bloom :: CInt -> IO FilterPolicyPtr
c_leveldb_readoptions_create :: IO ReadOptionsPtr
c_leveldb_readoptions_destroy :: ReadOptionsPtr -> IO ()
c_leveldb_readoptions_set_verify_checksums :: ReadOptionsPtr -> CUChar -> IO ()
c_leveldb_readoptions_set_fill_cache :: ReadOptionsPtr -> CUChar -> IO ()
c_leveldb_readoptions_set_snapshot :: ReadOptionsPtr -> SnapshotPtr -> IO ()
c_leveldb_writeoptions_create :: IO WriteOptionsPtr
c_leveldb_writeoptions_destroy :: WriteOptionsPtr -> IO ()
c_leveldb_writeoptions_set_sync :: WriteOptionsPtr -> CUChar -> IO ()
c_leveldb_cache_create_lru :: CSize -> IO CachePtr
c_leveldb_cache_destroy :: CachePtr -> IO ()
c_leveldb_major_version :: IO CInt
c_leveldb_minor_version :: IO CInt
instance Eq CompressionOpt
instance Show CompressionOpt


module Database.LevelDB.Types

-- | Batch operation
data BatchOp
Put :: ByteString -> ByteString -> BatchOp
Del :: ByteString -> BatchOp

-- | Represents the built-in Bloom Filter
newtype BloomFilter
BloomFilter :: FilterPolicyPtr -> BloomFilter

-- | User-defined comparator
newtype Comparator
Comparator :: (ByteString -> ByteString -> Ordering) -> Comparator

-- | Compression setting
data Compression
NoCompression :: Compression
Snappy :: Compression

-- | User-defined filter policy
data FilterPolicy
FilterPolicy :: String -> ([ByteString] -> ByteString) -> (ByteString -> ByteString -> Bool) -> FilterPolicy
fpName :: FilterPolicy -> String
createFilter :: FilterPolicy -> [ByteString] -> ByteString
keyMayMatch :: FilterPolicy -> ByteString -> ByteString -> Bool

-- | Options when opening a database
data Options
Options :: !Int -> !Int -> !Int -> !(Maybe Comparator) -> !Compression -> !Bool -> !Bool -> !Int -> !Bool -> !Int -> !(Maybe (Either BloomFilter FilterPolicy)) -> Options

-- | Number of keys between restart points for delta encoding of keys.
--   
--   This parameter can be changed dynamically. Most clients should leave
--   this parameter alone.
--   
--   Default: 16
blockRestartInterval :: Options -> !Int

-- | Approximate size of user data packed per block.
--   
--   Note that the block size specified here corresponds to uncompressed
--   data. The actual size of the unit read from disk may be smaller if
--   compression is enabled.
--   
--   This parameter can be changed dynamically.
--   
--   Default: 4k
blockSize :: Options -> !Int

-- | Control over blocks (user data is stored in a set of blocks, and a
--   block is the unit of reading from disk).
--   
--   If &gt; 0, use the specified cache (in bytes) for blocks. If 0,
--   leveldb will automatically create and use an 8MB internal cache.
--   
--   Default: 0
cacheSize :: Options -> !Int

-- | Comparator used to defined the order of keys in the table.
--   
--   If <a>Nothing</a>, the default comparator is used, which uses
--   lexicographic bytes-wise ordering.
--   
--   NOTE: the client must ensure that the comparator supplied here has the
--   same name and orders keys <i>exactly</i> the same as the comparator
--   provided to previous open calls on the same DB.
--   
--   Default: Nothing
comparator :: Options -> !(Maybe Comparator)

-- | Compress blocks using the specified compression algorithm.
--   
--   This parameter can be changed dynamically.
--   
--   Default: <a>Snappy</a>
compression :: Options -> !Compression

-- | If true, the database will be created if it is missing.
--   
--   Default: False
createIfMissing :: Options -> !Bool

-- | It true, an error is raised if the database already exists.
--   
--   Default: False
errorIfExists :: Options -> !Bool

-- | Number of open files that can be used by the DB.
--   
--   You may need to increase this if your database has a large working set
--   (budget one open file per 2MB of working set).
--   
--   Default: 1000
maxOpenFiles :: Options -> !Int

-- | If true, the implementation will do aggressive checking of the data it
--   is processing and will stop early if it detects any errors.
--   
--   This may have unforeseen ramifications: for example, a corruption of
--   one DB entry may cause a large number of entries to become unreadable
--   or for the entire DB to become unopenable.
--   
--   Default: False
paranoidChecks :: Options -> !Bool

-- | Amount of data to build up in memory (backed by an unsorted log on
--   disk) before converting to a sorted on-disk file.
--   
--   Larger values increase performance, especially during bulk loads. Up
--   to to write buffers may be held in memory at the same time, so you may
--   with to adjust this parameter to control memory usage. Also, a larger
--   write buffer will result in a longer recovery time the next time the
--   database is opened.
--   
--   Default: 4MB
writeBufferSize :: Options -> !Int
filterPolicy :: Options -> !(Maybe (Either BloomFilter FilterPolicy))

-- | Properties exposed by LevelDB
data Property
NumFilesAtLevel :: Int -> Property
Stats :: Property
SSTables :: Property

-- | Options for read operations
data ReadOptions
ReadOptions :: !Bool -> !Bool -> !(Maybe Snapshot) -> ReadOptions

-- | If true, all data read from underlying storage will be verified
--   against corresponding checksuyms.
--   
--   Default: False
verifyCheckSums :: ReadOptions -> !Bool

-- | Should the data read for this iteration be cached in memory? Callers
--   may with to set this field to false for bulk scans.
--   
--   Default: True
fillCache :: ReadOptions -> !Bool

-- | If <a>Just</a>, read as of the supplied snapshot (which must belong to
--   the DB that is being read and which must not have been released). If
--   <a>Nothing</a>, use an implicit snapshot of the state at the beginning
--   of this read operation.
--   
--   Default: Nothing
useSnapshot :: ReadOptions -> !(Maybe Snapshot)

-- | Snapshot handle
newtype Snapshot
Snapshot :: SnapshotPtr -> Snapshot
type WriteBatch = [BatchOp]

-- | Options for write operations
data WriteOptions
WriteOptions :: !Bool -> WriteOptions

-- | If true, the write will be flushed from the operating system buffer
--   cache (by calling WritableFile::Sync()) before the write is considered
--   complete. If this flag is true, writes will be slower.
--   
--   If this flag is false, and the machine crashes, some recent writes may
--   be lost. Note that if it is just the process that crashes (i.e., the
--   machine does not reboot), no writes will be lost even if sync==false.
--   
--   In other words, a DB write with sync==false has similar crash
--   semantics as the "write()" system call. A DB write with sync==true has
--   similar crash semantics to a "write()" system call followed by
--   "fsync()".
--   
--   Default: False
sync :: WriteOptions -> !Bool
defaultOptions :: Options
defaultReadOptions :: ReadOptions
defaultWriteOptions :: WriteOptions
instance Eq Snapshot
instance Eq Compression
instance Show Compression
instance Eq WriteOptions
instance Show WriteOptions
instance Eq ReadOptions
instance Eq BatchOp
instance Show BatchOp
instance Eq Property
instance Show Property
instance Default ReadOptions
instance Default WriteOptions
instance Default Options


module Database.LevelDB.Internal

-- | Database handle
data DB
DB :: LevelDBPtr -> Options' -> (IORef Bool) -> DB

-- | Internal representation of a <a>Comparator</a>
data Comparator'

-- | Internal representation of a <a>FilterPolicy</a>
data FilterPolicy'

-- | Internal representation of the <a>Options</a>
data Options'
Options' :: !OptionsPtr -> !(Maybe CachePtr) -> !(Maybe Comparator') -> !(Maybe (Either FilterPolicyPtr FilterPolicy')) -> Options'
_optsPtr :: Options' -> !OptionsPtr
_cachePtr :: Options' -> !(Maybe CachePtr)
_comp :: Options' -> !(Maybe Comparator')
_fpPtr :: Options' -> !(Maybe (Either FilterPolicyPtr FilterPolicy'))

-- | Closes the database.
--   
--   The function is safe in that it doesn't double-free the pointer, but
--   is <i>unsafe</i> because other functions which use the <a>DB</a>
--   handle do <i>not</i> check if the handle is live. If the handle is
--   used after it was freed, the program will segfault (internally,
--   leveldb performs a <tt>delete</tt> on the pointer).
unsafeClose :: DB -> IO ()
freeCReadOpts :: ReadOptionsPtr -> IO ()
freeComparator :: Comparator' -> IO ()
freeFilterPolicy :: FilterPolicy' -> IO ()
freeOpts :: Options' -> IO ()
mkCReadOpts :: ReadOptions -> IO ReadOptionsPtr
mkComparator :: String -> (ByteString -> ByteString -> Ordering) -> IO Comparator'
mkCompareFun :: (ByteString -> ByteString -> Ordering) -> CompareFun
mkCreateFilterFun :: ([ByteString] -> ByteString) -> CreateFilterFun
mkFilterPolicy :: FilterPolicy -> IO FilterPolicy'
mkKeyMayMatchFun :: (ByteString -> ByteString -> Bool) -> KeyMayMatchFun
mkOpts :: Options -> IO Options'
withCWriteOpts :: WriteOptions -> (WriteOptionsPtr -> IO a) -> IO a
withCReadOpts :: ReadOptions -> (ReadOptionsPtr -> IO a) -> IO a
throwIfErr :: String -> (ErrPtr -> IO a) -> IO a
cSizeToInt :: CSize -> Int
intToCSize :: Int -> CSize
intToCInt :: Int -> CInt
cIntToInt :: CInt -> Int
boolToNum :: Num b => Bool -> b
instance Eq DB


-- | Iterating over key ranges.
module Database.LevelDB.Iterator

-- | Iterator handle
--   
--   Note that an <a>Iterator</a> requires external synchronization if it
--   is shared between multiple threads which mutate it's state. See
--   <tt>examples/iterforkio.hs</tt> for a simple example of how to do
--   that.
data Iterator

-- | Create an <a>Iterator</a>.
--   
--   The iterator should be released with <a>releaseIter</a>.
--   
--   Note that an <a>Iterator</a> creates a snapshot of the database
--   implicitly, so updates written after the iterator was created are not
--   visible. You may, however, specify an older <a>Snapshot</a> in the
--   <a>ReadOptions</a>.
createIter :: MonadIO m => DB -> ReadOptions -> m Iterator

-- | Return the current entry as a pair, if the iterator is currently
--   positioned at an entry, ie. <a>iterValid</a>.
iterEntry :: MonadIO m => Iterator -> m (Maybe (ByteString, ByteString))

-- | Position at the first key in the source. The iterator is <i>valid</i>
--   after this call iff the source is not empty.
iterFirst :: MonadIO m => Iterator -> m ()

-- | Check for errors
--   
--   Note that this captures somewhat severe errors such as a corrupted
--   database.
iterGetError :: MonadIO m => Iterator -> m (Maybe ByteString)

-- | Return the key for the current entry if the iterator is currently
--   positioned at an entry, ie. <a>iterValid</a>.
iterKey :: MonadIO m => Iterator -> m (Maybe ByteString)

-- | Position at the last key in the source. The iterator is <i>valid</i>
--   after this call iff the source is not empty.
iterLast :: MonadIO m => Iterator -> m ()

-- | Moves to the next entry in the source. After this call,
--   <a>iterValid</a> is <i>true</i> iff the iterator was not positioned at
--   the last entry in the source.
--   
--   If the iterator is not valid, this function does nothing. Note that
--   this is a shortcoming of the C API: an <a>iterPrev</a> might still be
--   possible, but we can't determine if we're at the last or first entry.
iterNext :: MonadIO m => Iterator -> m ()

-- | Moves to the previous entry in the source. After this call,
--   <a>iterValid</a> is <i>true</i> iff the iterator was not positioned at
--   the first entry in the source.
--   
--   If the iterator is not valid, this function does nothing. Note that
--   this is a shortcoming of the C API: an <a>iterNext</a> might still be
--   possible, but we can't determine if we're at the last or first entry.
iterPrev :: MonadIO m => Iterator -> m ()

-- | Position at the first key in the source that is at or past target. The
--   iterator is <i>valid</i> after this call iff the source contains an
--   entry that comes at or past target.
iterSeek :: MonadIO m => Iterator -> ByteString -> m ()

-- | An iterator is either positioned at a key/value pair, or not valid.
--   This function returns <i>true</i> iff the iterator is valid.
iterValid :: MonadIO m => Iterator -> m Bool

-- | Return the value for the current entry if the iterator is currently
--   positioned at an entry, ie. <a>iterValid</a>.
iterValue :: MonadIO m => Iterator -> m (Maybe ByteString)

-- | Release an <a>Iterator</a>.
--   
--   The handle will be invalid after calling this action and should no
--   longer be used. Calling this function with an already released
--   <a>Iterator</a> will cause a double-free error!
releaseIter :: MonadIO m => Iterator -> m ()

-- | Run an action with an <a>Iterator</a>
withIter :: (MonadMask m, MonadIO m) => DB -> ReadOptions -> (Iterator -> m a) -> m a
instance Eq Iterator


-- | LevelDB Haskell binding.
--   
--   The API closely follows the C-API of LevelDB. For more information,
--   see: <a>http://leveldb.googlecode.com</a>
module Database.LevelDB.Base

-- | Database handle
data DB

-- | Batch operation
data BatchOp
Put :: ByteString -> ByteString -> BatchOp
Del :: ByteString -> BatchOp

-- | User-defined comparator
newtype Comparator
Comparator :: (ByteString -> ByteString -> Ordering) -> Comparator

-- | Compression setting
data Compression
NoCompression :: Compression
Snappy :: Compression

-- | Options when opening a database
data Options
Options :: !Int -> !Int -> !Int -> !(Maybe Comparator) -> !Compression -> !Bool -> !Bool -> !Int -> !Bool -> !Int -> !(Maybe (Either BloomFilter FilterPolicy)) -> Options

-- | Number of keys between restart points for delta encoding of keys.
--   
--   This parameter can be changed dynamically. Most clients should leave
--   this parameter alone.
--   
--   Default: 16
blockRestartInterval :: Options -> !Int

-- | Approximate size of user data packed per block.
--   
--   Note that the block size specified here corresponds to uncompressed
--   data. The actual size of the unit read from disk may be smaller if
--   compression is enabled.
--   
--   This parameter can be changed dynamically.
--   
--   Default: 4k
blockSize :: Options -> !Int

-- | Control over blocks (user data is stored in a set of blocks, and a
--   block is the unit of reading from disk).
--   
--   If &gt; 0, use the specified cache (in bytes) for blocks. If 0,
--   leveldb will automatically create and use an 8MB internal cache.
--   
--   Default: 0
cacheSize :: Options -> !Int

-- | Comparator used to defined the order of keys in the table.
--   
--   If <a>Nothing</a>, the default comparator is used, which uses
--   lexicographic bytes-wise ordering.
--   
--   NOTE: the client must ensure that the comparator supplied here has the
--   same name and orders keys <i>exactly</i> the same as the comparator
--   provided to previous open calls on the same DB.
--   
--   Default: Nothing
comparator :: Options -> !(Maybe Comparator)

-- | Compress blocks using the specified compression algorithm.
--   
--   This parameter can be changed dynamically.
--   
--   Default: <a>Snappy</a>
compression :: Options -> !Compression

-- | If true, the database will be created if it is missing.
--   
--   Default: False
createIfMissing :: Options -> !Bool

-- | It true, an error is raised if the database already exists.
--   
--   Default: False
errorIfExists :: Options -> !Bool

-- | Number of open files that can be used by the DB.
--   
--   You may need to increase this if your database has a large working set
--   (budget one open file per 2MB of working set).
--   
--   Default: 1000
maxOpenFiles :: Options -> !Int

-- | If true, the implementation will do aggressive checking of the data it
--   is processing and will stop early if it detects any errors.
--   
--   This may have unforeseen ramifications: for example, a corruption of
--   one DB entry may cause a large number of entries to become unreadable
--   or for the entire DB to become unopenable.
--   
--   Default: False
paranoidChecks :: Options -> !Bool

-- | Amount of data to build up in memory (backed by an unsorted log on
--   disk) before converting to a sorted on-disk file.
--   
--   Larger values increase performance, especially during bulk loads. Up
--   to to write buffers may be held in memory at the same time, so you may
--   with to adjust this parameter to control memory usage. Also, a larger
--   write buffer will result in a longer recovery time the next time the
--   database is opened.
--   
--   Default: 4MB
writeBufferSize :: Options -> !Int
filterPolicy :: Options -> !(Maybe (Either BloomFilter FilterPolicy))

-- | Options for read operations
data ReadOptions
ReadOptions :: !Bool -> !Bool -> !(Maybe Snapshot) -> ReadOptions

-- | If true, all data read from underlying storage will be verified
--   against corresponding checksuyms.
--   
--   Default: False
verifyCheckSums :: ReadOptions -> !Bool

-- | Should the data read for this iteration be cached in memory? Callers
--   may with to set this field to false for bulk scans.
--   
--   Default: True
fillCache :: ReadOptions -> !Bool

-- | If <a>Just</a>, read as of the supplied snapshot (which must belong to
--   the DB that is being read and which must not have been released). If
--   <a>Nothing</a>, use an implicit snapshot of the state at the beginning
--   of this read operation.
--   
--   Default: Nothing
useSnapshot :: ReadOptions -> !(Maybe Snapshot)

-- | Snapshot handle
data Snapshot
type WriteBatch = [BatchOp]

-- | Options for write operations
data WriteOptions
WriteOptions :: !Bool -> WriteOptions

-- | If true, the write will be flushed from the operating system buffer
--   cache (by calling WritableFile::Sync()) before the write is considered
--   complete. If this flag is true, writes will be slower.
--   
--   If this flag is false, and the machine crashes, some recent writes may
--   be lost. Note that if it is just the process that crashes (i.e., the
--   machine does not reboot), no writes will be lost even if sync==false.
--   
--   In other words, a DB write with sync==false has similar crash
--   semantics as the "write()" system call. A DB write with sync==true has
--   similar crash semantics to a "write()" system call followed by
--   "fsync()".
--   
--   Default: False
sync :: WriteOptions -> !Bool
type Range = (ByteString, ByteString)
defaultOptions :: Options
defaultReadOptions :: ReadOptions
defaultWriteOptions :: WriteOptions

-- | Run an action with a <a>DB</a>.
--   
--   <pre>
--   withDB path opts = bracket (open path opts) unsafeClose
--   </pre>
--   
--   Note that the <a>DB</a> handle will be released promptly when this
--   function exits.
withDB :: (MonadMask m, MonadIO m) => FilePath -> Options -> (DB -> m a) -> m a

-- | Open a database.
--   
--   The returned handle has a finalizer attached which will free the
--   underlying pointers once it goes out of scope. Note, however, that
--   finalizers are <i>not</i> guaranteed to run, and may not run promptly
--   if they do. Use <a>unsafeClose</a> to free the handle immediately, but
--   ensure it is not used after that (otherwise, the program will
--   segault). Alternatively, use the <a>Database.LevelDB.MonadResource</a>
--   API, which will take care of resource management automatically.
open :: MonadIO m => FilePath -> Options -> m DB

-- | Write a key/value pair.
put :: MonadIO m => DB -> WriteOptions -> ByteString -> ByteString -> m ()

-- | Delete a key/value pair.
delete :: MonadIO m => DB -> WriteOptions -> ByteString -> m ()

-- | Perform a batch mutation.
write :: MonadIO m => DB -> WriteOptions -> WriteBatch -> m ()

-- | Read a value by key.
get :: MonadIO m => DB -> ReadOptions -> ByteString -> m (Maybe ByteString)

-- | Run an action with a <a>Snapshot</a> of the database.
withSnapshot :: (MonadMask m, MonadIO m) => DB -> (Snapshot -> m a) -> m a

-- | Create a snapshot of the database.
--   
--   The returned <a>Snapshot</a> should be released with
--   <a>releaseSnapshot</a>.
createSnapshot :: MonadIO m => DB -> m Snapshot

-- | Release a snapshot.
--   
--   The handle will be invalid after calling this action and should no
--   longer be used.
releaseSnapshot :: MonadIO m => DB -> Snapshot -> m ()

-- | User-defined filter policy
data FilterPolicy
FilterPolicy :: String -> ([ByteString] -> ByteString) -> (ByteString -> ByteString -> Bool) -> FilterPolicy
fpName :: FilterPolicy -> String
createFilter :: FilterPolicy -> [ByteString] -> ByteString
keyMayMatch :: FilterPolicy -> ByteString -> ByteString -> Bool

-- | Represents the built-in Bloom Filter
data BloomFilter
createBloomFilter :: MonadIO m => Int -> m BloomFilter
releaseBloomFilter :: MonadIO m => BloomFilter -> m ()

-- | Properties exposed by LevelDB
data Property
NumFilesAtLevel :: Int -> Property
Stats :: Property
SSTables :: Property

-- | Get a DB property.
getProperty :: MonadIO m => DB -> Property -> m (Maybe ByteString)

-- | Destroy the given LevelDB database.
--   
--   The database must not be in use during this operation.
destroy :: MonadIO m => FilePath -> Options -> m ()

-- | Repair the given LevelDB database.
repair :: MonadIO m => FilePath -> Options -> m ()

-- | Inspect the approximate sizes of the different levels.
approximateSize :: MonadIO m => DB -> Range -> m Int64

-- | Compact the underlying storage for the given Range. In particular this
--   means discarding deleted and overwritten data as well as rearranging
--   the data to reduce the cost of operations accessing the data.
compactRange :: MonadIO m => DB -> Range -> m ()

-- | Return the runtime version of the underlying LevelDB library as a
--   (major, minor) pair.
version :: MonadIO m => m (Int, Int)


-- | High-level, <a>Data.List</a>-like, streaming interface to
--   <a>Database.LevelDB.Iterator</a>.
--   
--   This module contains types and functions to construct <a>Stream</a>s
--   from <a>Iterator</a>s, and re-exports the functions operating on
--   <a>Stream</a>s from <a>Data.Stream.Monadic</a>.
--   
--   <b>Note</b> that most of the functions from the latter module are
--   (intentionally) conflicting with the <a>Prelude</a>, it is thus
--   recommended to import this module qualified:
--   
--   <pre>
--   import Database.LevelDB -- or Database.LevelDB.Base
--   import qualified Database.LevelDB.Streaming as S
--   </pre>
module Database.LevelDB.Streaming
data KeyRange
KeyRange :: !ByteString -> (ByteString -> Ordering) -> KeyRange
start :: KeyRange -> !ByteString
end :: KeyRange -> ByteString -> Ordering
AllKeys :: KeyRange
data Direction
Asc :: Direction
Desc :: Direction
type Key = ByteString
type Value = ByteString
type Entry = (Key, Value)

-- | Create a <a>Stream</a> which yields only the keys of the given
--   <a>KeyRange</a> (in the given <a>Direction</a>).
keySlice :: (Applicative m, MonadIO m) => Iterator -> KeyRange -> Direction -> Stream m Key

-- | Create a <a>Stream</a> which yields key/value pairs of the given
--   <a>KeyRange</a> (in the given <a>Direction</a>).
entrySlice :: (Applicative m, MonadIO m) => Iterator -> KeyRange -> Direction -> Stream m Entry
instance Show Direction


module Database.LevelDB.MonadResource

-- | Database handle
data DB

-- | Batch operation
data BatchOp
Put :: ByteString -> ByteString -> BatchOp
Del :: ByteString -> BatchOp

-- | User-defined comparator
newtype Comparator
Comparator :: (ByteString -> ByteString -> Ordering) -> Comparator

-- | Compression setting
data Compression
NoCompression :: Compression
Snappy :: Compression

-- | Options when opening a database
data Options
Options :: !Int -> !Int -> !Int -> !(Maybe Comparator) -> !Compression -> !Bool -> !Bool -> !Int -> !Bool -> !Int -> !(Maybe (Either BloomFilter FilterPolicy)) -> Options

-- | Number of keys between restart points for delta encoding of keys.
--   
--   This parameter can be changed dynamically. Most clients should leave
--   this parameter alone.
--   
--   Default: 16
blockRestartInterval :: Options -> !Int

-- | Approximate size of user data packed per block.
--   
--   Note that the block size specified here corresponds to uncompressed
--   data. The actual size of the unit read from disk may be smaller if
--   compression is enabled.
--   
--   This parameter can be changed dynamically.
--   
--   Default: 4k
blockSize :: Options -> !Int

-- | Control over blocks (user data is stored in a set of blocks, and a
--   block is the unit of reading from disk).
--   
--   If &gt; 0, use the specified cache (in bytes) for blocks. If 0,
--   leveldb will automatically create and use an 8MB internal cache.
--   
--   Default: 0
cacheSize :: Options -> !Int

-- | Comparator used to defined the order of keys in the table.
--   
--   If <a>Nothing</a>, the default comparator is used, which uses
--   lexicographic bytes-wise ordering.
--   
--   NOTE: the client must ensure that the comparator supplied here has the
--   same name and orders keys <i>exactly</i> the same as the comparator
--   provided to previous open calls on the same DB.
--   
--   Default: Nothing
comparator :: Options -> !(Maybe Comparator)

-- | Compress blocks using the specified compression algorithm.
--   
--   This parameter can be changed dynamically.
--   
--   Default: <a>Snappy</a>
compression :: Options -> !Compression

-- | If true, the database will be created if it is missing.
--   
--   Default: False
createIfMissing :: Options -> !Bool

-- | It true, an error is raised if the database already exists.
--   
--   Default: False
errorIfExists :: Options -> !Bool

-- | Number of open files that can be used by the DB.
--   
--   You may need to increase this if your database has a large working set
--   (budget one open file per 2MB of working set).
--   
--   Default: 1000
maxOpenFiles :: Options -> !Int

-- | If true, the implementation will do aggressive checking of the data it
--   is processing and will stop early if it detects any errors.
--   
--   This may have unforeseen ramifications: for example, a corruption of
--   one DB entry may cause a large number of entries to become unreadable
--   or for the entire DB to become unopenable.
--   
--   Default: False
paranoidChecks :: Options -> !Bool

-- | Amount of data to build up in memory (backed by an unsorted log on
--   disk) before converting to a sorted on-disk file.
--   
--   Larger values increase performance, especially during bulk loads. Up
--   to to write buffers may be held in memory at the same time, so you may
--   with to adjust this parameter to control memory usage. Also, a larger
--   write buffer will result in a longer recovery time the next time the
--   database is opened.
--   
--   Default: 4MB
writeBufferSize :: Options -> !Int
filterPolicy :: Options -> !(Maybe (Either BloomFilter FilterPolicy))

-- | Options for read operations
data ReadOptions
ReadOptions :: !Bool -> !Bool -> !(Maybe Snapshot) -> ReadOptions

-- | If true, all data read from underlying storage will be verified
--   against corresponding checksuyms.
--   
--   Default: False
verifyCheckSums :: ReadOptions -> !Bool

-- | Should the data read for this iteration be cached in memory? Callers
--   may with to set this field to false for bulk scans.
--   
--   Default: True
fillCache :: ReadOptions -> !Bool

-- | If <a>Just</a>, read as of the supplied snapshot (which must belong to
--   the DB that is being read and which must not have been released). If
--   <a>Nothing</a>, use an implicit snapshot of the state at the beginning
--   of this read operation.
--   
--   Default: Nothing
useSnapshot :: ReadOptions -> !(Maybe Snapshot)

-- | Snapshot handle
data Snapshot
type WriteBatch = [BatchOp]

-- | Options for write operations
data WriteOptions
WriteOptions :: !Bool -> WriteOptions

-- | If true, the write will be flushed from the operating system buffer
--   cache (by calling WritableFile::Sync()) before the write is considered
--   complete. If this flag is true, writes will be slower.
--   
--   If this flag is false, and the machine crashes, some recent writes may
--   be lost. Note that if it is just the process that crashes (i.e., the
--   machine does not reboot), no writes will be lost even if sync==false.
--   
--   In other words, a DB write with sync==false has similar crash
--   semantics as the "write()" system call. A DB write with sync==true has
--   similar crash semantics to a "write()" system call followed by
--   "fsync()".
--   
--   Default: False
sync :: WriteOptions -> !Bool
type Range = (ByteString, ByteString)
defaultOptions :: Options
defaultWriteOptions :: WriteOptions
defaultReadOptions :: ReadOptions

-- | Run an action with a snapshot of the database.
--   
--   The snapshot will be released when the action terminates or throws an
--   exception. Note that this function is provided for convenience and
--   does not prevent the <a>Snapshot</a> handle to escape. It will,
--   however, be invalid after this function returns and should not be used
--   anymore.
withSnapshot :: MonadResource m => DB -> (Snapshot -> m a) -> m a

-- | Open a database
--   
--   The returned handle will automatically be released when the enclosing
--   <a>runResourceT</a> terminates.
open :: MonadResource m => FilePath -> Options -> m DB

-- | Write a key/value pair
put :: MonadResource m => DB -> WriteOptions -> ByteString -> ByteString -> m ()

-- | Delete a key/value pair
delete :: MonadResource m => DB -> WriteOptions -> ByteString -> m ()

-- | Perform a batch mutation
write :: MonadResource m => DB -> WriteOptions -> WriteBatch -> m ()

-- | Read a value by key
get :: MonadResource m => DB -> ReadOptions -> ByteString -> m (Maybe ByteString)

-- | Create a snapshot of the database.
--   
--   The returned <a>Snapshot</a> will be released automatically when the
--   enclosing <a>runResourceT</a> terminates. It is recommended to use
--   <a>createSnapshot'</a> instead and release the resource manually as
--   soon as possible.
createSnapshot :: MonadResource m => DB -> m Snapshot

-- | Create a snapshot of the database which can (and should) be released
--   early.
createSnapshot' :: MonadResource m => DB -> m (ReleaseKey, Snapshot)

-- | User-defined filter policy
data FilterPolicy
FilterPolicy :: String -> ([ByteString] -> ByteString) -> (ByteString -> ByteString -> Bool) -> FilterPolicy
fpName :: FilterPolicy -> String
createFilter :: FilterPolicy -> [ByteString] -> ByteString
keyMayMatch :: FilterPolicy -> ByteString -> ByteString -> Bool

-- | Create a <a>BloomFilter</a>
bloomFilter :: MonadResource m => Int -> m BloomFilter

-- | Properties exposed by LevelDB
data Property
NumFilesAtLevel :: Int -> Property
Stats :: Property
SSTables :: Property

-- | Get a DB property
getProperty :: MonadResource m => DB -> Property -> m (Maybe ByteString)

-- | Destroy the given leveldb database.
destroy :: MonadResource m => FilePath -> Options -> m ()

-- | Repair the given leveldb database.
repair :: MonadResource m => FilePath -> Options -> m ()

-- | Inspect the approximate sizes of the different levels
approximateSize :: MonadResource m => DB -> Range -> m Int64

-- | Compact the underlying storage for the given Range. In particular this
--   means discarding deleted and overwritten data as well as rearranging
--   the data to reduce the cost of operations accessing the data.
compactRange :: MonadResource m => DB -> Range -> m ()

-- | Return the runtime version of the underlying LevelDB library as a
--   (major, minor) pair.
version :: MonadResource m => m (Int, Int)

-- | Iterator handle
--   
--   Note that an <a>Iterator</a> requires external synchronization if it
--   is shared between multiple threads which mutate it's state. See
--   <tt>examples/iterforkio.hs</tt> for a simple example of how to do
--   that.
data Iterator

-- | Run an action with an Iterator. The iterator will be closed after the
--   action returns or an error is thrown. Thus, the iterator will
--   <i>not</i> be valid after this function terminates.
withIterator :: MonadResource m => DB -> ReadOptions -> (Iterator -> m a) -> m a

-- | Create an <a>Iterator</a>.
--   
--   The iterator will be released when the enclosing <a>runResourceT</a>
--   terminates. You may consider to use <a>iterOpen'</a> instead and
--   manually release the iterator as soon as it is no longer needed
--   (alternatively, use <a>withIterator</a>).
--   
--   Note that an <a>Iterator</a> creates a snapshot of the database
--   implicitly, so updates written after the iterator was created are not
--   visible. You may, however, specify an older <a>Snapshot</a> in the
--   <a>ReadOptions</a>.
iterOpen :: MonadResource m => DB -> ReadOptions -> m Iterator

-- | Create an <a>Iterator</a> which can be released early.
iterOpen' :: MonadResource m => DB -> ReadOptions -> m (ReleaseKey, Iterator)

-- | An iterator is either positioned at a key/value pair, or not valid.
--   This function returns <i>true</i> iff the iterator is valid.
iterValid :: MonadResource m => Iterator -> m Bool

-- | Position at the first key in the source that is at or past target. The
--   iterator is <i>valid</i> after this call iff the source contains an
--   entry that comes at or past target.
iterSeek :: MonadResource m => Iterator -> ByteString -> m ()

-- | Position at the first key in the source. The iterator is <i>valid</i>
--   after this call iff the source is not empty.
iterFirst :: MonadResource m => Iterator -> m ()

-- | Position at the last key in the source. The iterator is <i>valid</i>
--   after this call iff the source is not empty.
iterLast :: MonadResource m => Iterator -> m ()

-- | Moves to the next entry in the source. After this call,
--   <a>iterValid</a> is <i>true</i> iff the iterator was not positioned at
--   the last entry in the source.
--   
--   If the iterator is not valid, this function does nothing. Note that
--   this is a shortcoming of the C API: an <a>iterPrev</a> might still be
--   possible, but we can't determine if we're at the last or first entry.
iterNext :: MonadResource m => Iterator -> m ()

-- | Moves to the previous entry in the source. After this call,
--   <a>iterValid</a> is <i>true</i> iff the iterator was not positioned at
--   the first entry in the source.
--   
--   If the iterator is not valid, this function does nothing. Note that
--   this is a shortcoming of the C API: an <a>iterNext</a> might still be
--   possible, but we can't determine if we're at the last or first entry.
iterPrev :: MonadResource m => Iterator -> m ()

-- | Return the key for the current entry if the iterator is currently
--   positioned at an entry, ie. <a>iterValid</a>.
iterKey :: MonadResource m => Iterator -> m (Maybe ByteString)

-- | Return the value for the current entry if the iterator is currently
--   positioned at an entry, ie. <a>iterValid</a>.
iterValue :: MonadResource m => Iterator -> m (Maybe ByteString)

-- | Check for errors
--   
--   Note that this captures somewhat severe errors such as a corrupted
--   database.
iterGetError :: MonadResource m => Iterator -> m (Maybe ByteString)

-- | A <tt>Monad</tt> which allows for safe resource allocation. In theory,
--   any monad transformer stack included a <tt>ResourceT</tt> can be an
--   instance of <tt>MonadResource</tt>.
--   
--   Note: <tt>runResourceT</tt> has a requirement for a
--   <tt>MonadBaseControl IO m</tt> monad, which allows control operations
--   to be lifted. A <tt>MonadResource</tt> does not have this requirement.
--   This means that transformers such as <tt>ContT</tt> can be an instance
--   of <tt>MonadResource</tt>. However, the <tt>ContT</tt> wrapper will
--   need to be unwrapped before calling <tt>runResourceT</tt>.
--   
--   Since 0.3.0
class (MonadThrow m, MonadIO m, Applicative m, MonadBase IO m) => MonadResource (m :: * -> *)
liftResourceT :: MonadResource m => ResourceT IO a -> m a

-- | Unwrap a <a>ResourceT</a> transformer, and call all registered release
--   actions.
--   
--   Note that there is some reference counting involved due to
--   <a>resourceForkIO</a>. If multiple threads are sharing the same
--   collection of resources, only the last call to <tt>runResourceT</tt>
--   will deallocate the resources.
--   
--   Since 0.3.0
runResourceT :: MonadBaseControl IO m => ResourceT m a -> m a

-- | Introduce a reference-counting scheme to allow a resource context to
--   be shared by multiple threads. Once the last thread exits, all
--   remaining resources will be released.
--   
--   Note that abuse of this function will greatly delay the deallocation
--   of registered resources. This function should be used with care. A
--   general guideline:
--   
--   If you are allocating a resource that should be shared by multiple
--   threads, and will be held for a long time, you should allocate it at
--   the beginning of a new <tt>ResourceT</tt> block and then call
--   <tt>resourceForkIO</tt> from there.
--   
--   Since 0.3.0
resourceForkIO :: MonadBaseControl IO m => ResourceT m () -> ResourceT m ThreadId


-- | LevelDB Haskell binding.
--   
--   The API closely follows the C-API of LevelDB. For more information,
--   see: <a>http://leveldb.googlecode.com</a>
module Database.LevelDB
