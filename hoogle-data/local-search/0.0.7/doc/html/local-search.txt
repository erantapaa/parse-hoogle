-- Hoogle documentation, generated by Haddock
-- See Hoogle, http://www.haskell.org/hoogle/


-- | Generalised local search within Haskell, for applications in combinatorial optimisation.
--   
--   This library operates by representing metaheuristics as generators of
--   solutions, or streams of solutions, which are themselves the result of
--   resolving the interactions of other streams of values. The library
--   contains combinators for constructing and managing these structures.
@package local-search
@version 0.0.7


-- | These combinators are for controlling local search processes at the
--   top level and preventing stack and memory build ups. The basic
--   combinators seen in the other libraries are all lazy and will describe
--   the structure of the computations that will make up the search. When
--   it comes to accessing values and solutions from these processes you
--   can print each solution which will push the process forwards and avoid
--   memory problems.
--   
--   To avoid wasting processing time displaying many solutions in a
--   process, when all you are interested in is the Nth one, you might use
--   the common list index function (!!). However this is a lazy operator
--   and will cause Haskell to construct the computation for the Nth value,
--   in terms of the previous values, before beginning the evaluation. This
--   causes the memory problems.
--   
--   Instead we provide an eager replacement for (!!) which we call (!!!).
--   For more sophisticated applications we provide two other semi-eager
--   operations which return both an eager value and a lazy remainder.
module Control.Search.Local.Eager

-- | This is an eager list index. It acts exactly like the common (!!)
--   operation, however it evaluates each element to WHNF. In the case
--   where each element of the list depends upon previous elements in some
--   way (usually true of the local search systems), this will result in
--   the computation being pushed forwards.
(!!!) :: [a] -> Int -> a

-- | Similar to the eager list index, however it also gives back the
--   remainder of the computation as an unevaluated list. It is expected
--   that this will be used to sample a stream for a human user, allowing
--   the user to see what has happened and make a decision to continue, or
--   stop. If continue, then the lazy remainder can be processed further.
indexWithRemainder :: [a] -> Int -> (a, [a])

-- | Eager <i>splitAt</i>. Looks like <i>splitAt</i>, but the elements of
--   the first list are evaluated to WHNF.
splitAt' :: Int -> [a] -> ([a], [a])

-- | This is the helper function used by the others to force the list
--   evaluation, as the list is accessed. I think this is equivalent to
--   
--   <pre>
--   evalList rseq 
--   </pre>
--   
--   from the <i>Control.Parallel.Strategies</i> library, but reproduced
--   here to reduce dependencies.
push :: [a] -> [a]


-- | We capture the pattern of meta-heuristics and local search as a
--   process or stream of evolving solutions. These combinators provide a
--   way to describe and manipulate these processes quickly. The basic
--   pattern of their use is this;
--   
--   <pre>
--   loopP (strategy) seed 
--   </pre>
--   
--   The strategy itself is a stream transformer. The transformer becomes a
--   search strategy when it's output is fed back into it's input, which is
--   the action of the loopP function. For example, the following is not a
--   search strategy but you could write;
--   
--   <pre>
--   loopP (map (+1)) 0
--   </pre>
--   
--   Which would generate the stream [0,1,2... A real search strategy then
--   looks like;
--   
--   <pre>
--   loopP iterativeImprover tspSeed
--   </pre>
--   
--   Many search strategies do not always produce improving sequences as
--   the iterative improver does. For these we provide a simple
--   modification of <a>scanl</a> which can be applied to any stream,
--   called <a>bestSoFar</a>. Finally, these streams are usually
--   descriptions of unlimited processes. To make them practical we limit
--   them using standard Haskell combinators such as <a>take</a> and list
--   index.
--   
--   <pre>
--   take 20 . bestSoFar $ loopP searchStrategy seed
--   </pre>
--   
--   Search strategies are constructed via the composition of other
--   functions. This often resembles the composition of an arrow pipeline,
--   and this library can be rewritten in terms of arrows, however we have
--   found no significant advantage in doing this.
--   
--   A simple TABU like search strategy, that has a memory of the recent
--   past (10 elements) of the search process, and filters neighbourhoods
--   accordingly can be created like this;
--   
--   <pre>
--   searchStrategy xs = map head $ zipWith (\ws-&gt;filter (flip notElem ws)) (window 10 xs) (neighbourhood xs)  
--   </pre>
--   
--   A common way to improve meta-heuristics is to introduce stochastic
--   elements, such as random decisions from a constrained set of choices,
--   or neighbourhoods which will not generate exactly the same set of
--   options each time a particular solution is visited. Stream
--   transformations allow this because they can thread additional state
--   internally, while not exposing the user of the transformation to a
--   great deal of the process. For example in the above example, to create
--   a random choice from the constrained set at each point you would do
--   this;
--   
--   <pre>
--   searchStrategy rs xs = select uniformCDF $ zipWith (\ws-&gt;filter (flip notElem ws)) (window 10 xs) (neighbourhood xs)
--   </pre>
--   
--   The neighbourhood can be similarly modified. We must still provide the
--   starting points for the extra data used by such transformers, in this
--   case a stream of random values, or in other cases a random number
--   generator, but one provided it is hidden, and the transformer can be
--   composed with any other transformation.
--   
--   Using the same transformation, which threads an internal state, in
--   several places is harder. It involves merging and dividing streams in
--   sequenced patterns. For example;
--   
--   <pre>
--   applyToBoth tr as bs = (\xs-&gt;(map head xs,map last xs)) . chunk 2 $ tr (concat $ transpose [as,bs])
--   </pre>
module Control.Search.Local

-- | The basic stream transformation type.
type StreamT a b = Stream a -> Stream b

-- | Internally streams are represented as standard Haskell lists. This
--   type synonym is provided for readability. It is assumed that streams
--   will be infinite.
type Stream s = [s]

-- | Lists are also used to represent finite collections or groups of
--   solutions. This synonym is for where the list is being used as a
--   finite list.
type List s = [s]

-- | In previous versions I have used the standard <a>Eq</a> and <a>Ord</a>
--   classes. However I have then had to assume that every problem is a
--   minimisation. To get around this, and provide functions that match
--   more closely to optimisation problems, where the concept we seek is
--   <i>better than</i>, rather than <i>greater</i> or <i>less</i> than, I
--   provide this new class. It is however very very like <a>Ord</a>.
--   
--   It is proposed that this class is used for value of solution
--   comparisons only, and the standard <a>Eq</a> class is retained for
--   situations where the solutions are identical, and do not just share
--   the same value.
class Optimisable a
(=:=) :: Optimisable a => a -> a -> Bool
(>:) :: Optimisable a => a -> a -> Bool
(<:) :: Optimisable a => a -> a -> Bool

-- | This returns the best solution in an input list. It can be thought of
--   as similar to <a>maximum</a>.
best :: Optimisable s => [s] -> s

-- | This returns the worse solution in an input list. It can be thought of
--   as similar to <a>minimum</a>.
worst :: Optimisable s => [s] -> s

-- | This returns the best of two input solutions. It can be thought of as
--   similar to <a>max</a>.
bestOf :: Optimisable s => s -> s -> s

-- | An alternative version of <a>sort</a> (implemented in terms of
--   <a>sortBy</a>), but using <a>Optimisable</a>, so that better solutions
--   are earlier in the output list than worse ones.
sortO :: Optimisable a => [a] -> [a]

-- | A transformer that is usually used as a final step in a process, to
--   allow the user to only see the best possible solution at each point,
--   and ignore the intermediate values that a strategy may produce.
bestSoFar :: Optimisable s => StreamT s s

-- | This was original created to assist with making multiple selections
--   from a population within a genetic algorithm. More generally this is a
--   higher order function which will take a stream transformation and
--   apply it multiple times to each element of the input stream gathering
--   up the results.
--   
--   It can be used to make multiple selections from a population in a GA,
--   or to create a neighbourhood function from a perturbation operation.
--   For example;
--   
--   <pre>
--   nF = doMany 5 perturbFunction
--   </pre>
--   
--   Where <i>5</i> is just an arbitrary example constant and
--   <i>perturbFunction</i> is a placeholder.
--   
--   If the perturb function is defined with a parameter controlling the
--   perturbation, for example a random number, such as which pair of
--   cities in a TSP to exchange then you can do this for a deterministic
--   operation;
--   
--   <pre>
--   nF = doMany 5 (zipWith perturbationFunction (cycle [0..4]))
--   </pre>
--   
--   For a more stochastic effect;
--   
--   <pre>
--   nF = doMany 5 (zipWith perturbationFunction (randoms g)) 
--   </pre>
--   
--   Where <i>g</i> is assumed to be of the <a>RandomGen</a> class.
doMany :: Int -> StreamT s s' -> StreamT s (List s')

-- | Breaks down a stream into a series of chunks, frequently finds use in
--   preparing sets of random numbers for various functions, but also in
--   the <tt>makePop</tt> function that is important for genetic
--   algorithms.
chunk :: Int -> StreamT s (List s)

-- | A more flexible version of chunk which can vary the size of each
--   chunk, in accordance with a list providing the sizes required of each
--   grouping. For example;
--   
--   <pre>
--   chunk i = variableChunk (repeat i)
--   variableChunk (cycle [1,2]) [0..] = [[0],[1,2],[3],[4,5]... 
--   </pre>
variableChunk :: Stream Int -> StreamT s (List s)

-- | An operation which changes the structure of an underlying stream, but
--   not the data type, by replicating the elements of the stream in place.
--   Can be thought of as changing the <i>speed</i> of the stream. This
--   finds use in <a>doMany</a>, genetic algorithms and ant colony
--   optimisation. For example;
--   
--   <pre>
--   stretch 2 "abcd" = "aabbccdd"
--   </pre>
stretch :: Int -> StreamT s s

-- | A more flexible version of stretch which can vary how far each value
--   in the underlying stream is stretched, in accordance with a list
--   providing the sizes required of each grouping. For example;
--   
--   <pre>
--   stretch i = variableStretch (repeat i)
--   variableStretch [3,3,7,2] "abcd" = "aaabbbcccccccdd" 
--   </pre>
variableStretch :: Stream Int -> StreamT s s

-- | Creates a rolling window over a stream of values up to the size
--   parameter. The windows are then produced as a stream of lists. This
--   can also be done using a queue data structure, however this was found
--   to be slightly faster.
window :: Int -> StreamT s (List s)

-- | <i>variableDoMany</i> perfoms the same action as <a>doMany</a>, but
--   allows the programmer to vary how many times the transformation is
--   applied to each underlying solution, through the use of a stream of
--   sizes.
variableDoMany :: Stream Int -> StreamT s s' -> StreamT s (List s')

-- | A function for transforming a stream of <a>window</a>s, taking random
--   numbers of elements from the front of each window. This can be used in
--   the implementation of variations of the TABU search algorithm. Usage
--   as follows (with example values) ;
--   
--   <pre>
--   varyWindow (3,6) . window 10
--   </pre>
varyWindow :: (Int, Int) -> Stream (List s) -> Stream (List s)

-- | This function transforms a neighbourhood function to give a
--   transformation that yields <i>improving</i> neighbourhoods, that is,
--   neighbourhoods that only contain solutions that improve upon the seed
--   solution. In the case that there are no improving solutions (local
--   minima), the output is a singleton list containing the seed solution.
--   This functionality is provided byt the <a>safe</a> helper function.
improvement :: Optimisable s => StreamT s (List s) -> StreamT s (List s)

-- | The generalised selection routine. This takes a stream of lists and
--   selects one element from each list, to construct the new stream. The
--   selection routine takes a <tt>DistributionMaker</tt>, and selects
--   based upon this. This only really makes sense when there is some
--   internal structure in the stream of lists. For example;
--   
--   <pre>
--   select (poissonCDF 1) . map sortO   
--   </pre>
--   
--   Each list in the input stream is sorted, so that the best solutions
--   appear first. This is then selected from using a Poisson distribution,
--   with the mean at 1. This means that the early (better) solutions are
--   much more likely to be selected.
select :: (Random r, Ord r) => (Int -> List r) -> StreamT (List a) a

-- | This function acts like <a>select</a>, however the distribution is
--   fixed, not being constructed anew for each list in the input stream.
--   This is much more efficient, but does assume that the size of each
--   list in the input is the same (a fixed size neighbourhood is perfect
--   for this).
select' :: (Random r, Ord r) => List r -> StreamT (List a) a

-- | This function is very similar to the <i>until</i> function of FRP. It
--   takes a stream and returns the elements of that stream until
--   <a>True</a> appears on the trigger stream. At this point one of the
--   potential futures is chosen and becomes the remainder of the stream.
--   The potential futures are zipped with the triggers, so the choice is
--   fixed, the <i>current</i> potential future is the choice. More
--   generally this concept could be elaborated in the future.
--   
--   <ol>
--   <li>The initial stream of values to place before the trigger (2) The
--   stream of triggers (3) The stream of potential future streams</li>
--   </ol>
--   
--   Could be used to provide a temperature strategy that restarts once in
--   Simulated Annealing like so;
--   
--   <pre>
--   let t = iterate (+1) 0 
--   in until_ t triggerStream (repeat t) 
--   </pre>
--   
--   This alternative will restart every time <a>True</a> appears on the
--   trigger stream, not just the first time.
--   
--   <pre>
--   let t = until_ (iterate (+1) 0) triggerStream (repeat t) in t
--   </pre>
until_ :: Stream a -> Stream Bool -> Stream (Stream a) -> Stream a

-- | Restart is a little like loop. It will construct a stream of values by
--   applying a stream transformation to one value, and then the successor
--   and so on. It differs in that it also takes a triggering mechanism
--   that can choose to stop the current sequence and continue from a
--   different value (the next value on the initial stream). For example,
--   the following will start counting initially from 0, then -5, then -10,
--   and will count until it reaches 11 each time.
--   
--   <pre>
--   restart (map (+1)) (map (&gt;10)) [0,-5,-10]
--   </pre>
restart :: StreamT a a -> StreamT a Bool -> StreamT a a

-- | Exactly like <a>restart</a>, except that it will only return the
--   result of an iteration of transformation, not the intermediate values.
--   For example;
--   
--   <pre>
--   restartExtract (map (+1)) (map ((==0) . flip mod 4)) [1,-5,-10,-13]
--   </pre>
--   
--   gives;
--   
--   <pre>
--   [4,-4,-8..
--   </pre>
restartExtract :: StreamT a a -> StreamT a Bool -> StreamT a a

-- | Is the combination of <a>divide</a> and <a>join</a>. It takes a set of
--   indices and stream transformations, divides the input stream, using
--   the indices and a stream of indices, transforms each substream by the
--   related stream transformation, and then puts them all back together
--   again as a new stream.
--   
--   For example, to apply a transformation (f) to only every third value
--   in a stream, you could do this;
--   
--   <pre>
--   nest [(True,id),(False,f)] (cycle [True,True,False])
--   </pre>
nest :: Eq n => List (n, Stream a -> Stream b) -> Stream n -> Stream a -> Stream b

-- | This function acts like <a>nest</a>, but the name stream makes choices
--   (or can do) based upon the initial value of solutions on the input
--   stream.
preNest :: Eq n => (Stream a -> Stream n) -> List (n, Stream a -> Stream b) -> Stream a -> Stream b

-- | Divide splits a stream of values into a list of substreams. The
--   division is controlled by a list of <i>indices</i> and then a stream
--   of these indices.
divide :: Eq n => List n -> Stream n -> Stream v -> List (Stream v)

-- | Join is the inverse of <a>divide</a>, it combined substreams into a
--   stream fo values. It takes a list of substreams, and the indices that
--   indicate them, and then a stream of the indices. For each value in the
--   stream of indices, the <i>next</i> value in the appropriate substream
--   is chosen and produced.
join :: Eq n => List (n, Stream v) -> Stream n -> Stream v

-- | A more specific version of <a>loopS</a> and implemented in terms of
--   it. Rather than allowing a number of initial values, this allows only
--   1.
loopP :: StreamT s s -> s -> Stream s

-- | The standard function for <i>tying the knot</i> on a stream described
--   process. This links the outputs of the stream process to the inputs,
--   with an initial set of values, and provides a single stream of values
--   to the user.
loopS :: StreamT s s -> StreamT s s

-- | A helper function that chooses between elements of the two input
--   streams at each point in the stream, and returns one which is
--   non-empty. The check looks at values in the second stream first, if
--   this list is not empty, it is returned.
safe :: Stream (List v) -> Stream (List v) -> Stream (List v)


-- | Selection routines have been made generic through the <a>select</a>
--   and <a>select'</a> functions, which are parametrised by probability
--   distributions. This module provides functions for constructing and
--   manipulating some example probability distributions.
module Control.Search.Local.Distributions

-- | The data type for a discrete probability distribution.
type Distribution = [Double]

-- | The number of elements being selected between will often vary (such as
--   in improving neighbourhoods), so it will often be necessary to
--   construct distributions with some constant properties, but varying the
--   length.
type DistributionMaker = Int -> Distribution

-- | Parametrised as follows;
--   
--   <ol>
--   <li>mean</li>
--   <li>standard deviation</li>
--   <li>size</li>
--   </ol>
--   
--   The function generates the CDF of a Normal distribution, using the
--   mean and standard deviation, over the range of discrete values [0 ..
--   size]. The result is processed by the <a>fixEnd</a> function, so the
--   final entry in the distribution is always 1. Over larger enough values
--   of size this should be fine.
normalCDF :: Double -> Double -> DistributionMaker

-- | Parametrised as follows;
--   
--   <ol>
--   <li>mean</li>
--   <li>size</li>
--   </ol>
--   
--   This function generates the CDF of a Poisson distribution with the
--   specified mean, over the range of discrete values [0 .. size]. This
--   function includes a call to <a>fixEnd</a> so that the final value of
--   the distribution is always 1.
poissonCDF :: Double -> DistributionMaker

-- | A function to generate a Uniform distribution CDF over the range [0 ..
--   size]. For safety this includes <a>fixEnd</a>, though this should have
--   no effect.
uniformCDF :: DistributionMaker

-- | It is more likely that when always choosing the first element of list
--   of choices <a>head</a> will be employed, but this has been included
--   for completeness. This is a CDF.
firstChoice :: DistributionMaker

-- | Like <a>firstChoice</a> it is more likely that <a>last</a> will be
--   used for this effect. This is also a CDF.
lastChoice :: DistributionMaker

-- | To enable the construction of more exotic distributions from existing
--   distributions. The basic function combines them with equal weight on
--   each component. For example;
--   
--   <pre>
--   addDistributions [[0,0.5,1],[1,1,1]] = [0.5,0.75,1]
--   </pre>
--   
--   Compare this with <a>addDistributions'</a>.
addDistributions :: [Distribution] -> Distribution

-- | A more flexible variation upon <a>addDistributions</a> which allows
--   the programmer to specify the weights to merge the distributions with.
--   For example;
--   
--   <pre>
--   addDistributions [0.3,0.7] [[0,0.5,1],[1,1,1]] = [0.7,0.85,1] 
--   </pre>
addDistributions' :: [Double] -> [Distribution] -> Distribution

-- | Combines <a>DistributionMaker</a>s. This combines them with equal
--   weighting.
addDistributionMakers :: [DistributionMaker] -> DistributionMaker

-- | Combines <a>DistributionMaker</a>s but weights each one.
addDistributionMakers' :: [Double] -> [DistributionMaker] -> DistributionMaker

-- | This is parametrised as follows;
--   
--   <ol>
--   <li>mean</li>
--   <li>k</li>
--   </ol>
--   
--   The function generates the probability of element <i>k</i> being
--   chosen from a Poisson distribution with the specified mean.
--   
--   This is quite a slow function and should probably be memoized in the
--   future.
poisson :: Double -> Int -> Double

-- | The basic CDF functions (e.g. <a>poissonCDF'</a>) often do not yield
--   <i>complete</i> CDFs. The distributions that are produced tend to 1 in
--   the last position of the list, but do not actually get there. For
--   these to be used practically, the last value of the list should be
--   replaced with 1. This is a bodge, but under most circumstances should
--   not adversely effect results.
fixEnd :: Distribution -> Distribution

-- | Parametrised as follows;
--   
--   <ol>
--   <li>mean</li>
--   <li>standard deviation</li>
--   <li>size</li>
--   </ol>
--   
--   The function generates the CDF of a Normal distribution, using the
--   mean and standard deviation, over the range of discrete values [0 ..
--   size]. This function is raw, and does not use <a>fixEnd</a>.
normalCDF' :: Double -> Double -> DistributionMaker

-- | Parametrised as follows;
--   
--   <ol>
--   <li>mean</li>
--   <li>size</li>
--   </ol>
--   
--   This function generates the CDF of a Poisson distribution with the
--   specified mean, over the range of discrete values [0 .. size]. This
--   function gives the raw distribution.
poissonCDF' :: Double -> DistributionMaker

-- | The raw Uniform distribution without using <a>fixEnd</a>.
uniformCDF' :: DistributionMaker

-- | A function included for debug purposes. I expect that many users will
--   be more comfortable using CDFs, but happier thinking in terms of PDFs.
--   Use in conjunction with <a>distribution2SVG</a> to see what a
--   distribution looks like.
cdf2pdf :: Distribution -> Distribution

-- | A function included for debug purposes, to allow a user to visualise a
--   distribution. It generates a string, which can be stored in a file as
--   SVG.
distribution2SVG :: Distribution -> String


-- | A collection of common strategies, built out of the combinators in the
--   other libraries. For examples of their use, see
--   <a>Control.Search.Local.Example</a>. ACO is the least well thought
--   through.
module Control.Search.Local.Strategies

-- | The generic skeleton of iterative improvers. The first parameters is a
--   neighbourhood stream expander, the second is a stream contractor which
--   makes choices from neighbourhoods. All neighbourhoods will be filtered
--   so that the elements can only improve upon the previous solution.
--   
--   Since the parameters are stream transformers, simple functions must be
--   lifted before they can be used as parameters. For example a
--   deterministic neighbourhood function <tt>df</tt> should be lifted with
--   <tt>map</tt> and to choose the first element from each improving
--   neighbourhood you would use <tt>map head</tt>, giving
--   
--   <pre>
--   iterativeImprover (map df) (map head). 
--   </pre>
--   
--   This skeleton provides a standard infinite stream of solutions, rather
--   than terminating when a local minima is reached. This provides better
--   safety for composition than the versions suggested in the paper. When
--   the filter results in an empty list, the seed value is wrapped up as a
--   list and returned in its place.
iterativeImprover :: Optimisable s => StreamT s (List s) -> StreamT (List s) s -> StreamT s s

-- | First found iterative improvement strategy. Fixes the choice function
--   to <tt>map head</tt>.
firstFoundii :: Optimisable s => StreamT s (List s) -> StreamT s s

-- | Maximal iterative improvement strategy. Since we seek the lowest
--   possible value of solutions this translates to fixing the choice
--   function to <tt>map worst</tt>.
maximalii :: Optimisable s => StreamT s (List s) -> StreamT s s

-- | Minimal iterative improvement strategy. Fixes the choice function to
--   <tt>map best</tt>.
minimalii :: Optimisable s => StreamT s (List s) -> StreamT s s

-- | Stochastic iterative improvement strategy. The choice function is
--   required to make a random choice from the neighbourhood at each step.
--   This is implemented in terms of the <a>select</a> function, and uses a
--   <a>uniformCDF</a>.
stochasticii :: Optimisable s => StreamT s (List s) -> StreamT s s

-- | A general skeleton for TABU search. The three parameters are
--   
--   <ol>
--   <li>a stream transformer to create the stream of TABU lists (typically
--   provided by <a>window</a>)</li>
--   <li>a stream transformer to create the stream of neighbourhoods, in
--   the same manner as seen in iterative improver</li>
--   <li>a choice transformer to choose a single element from a pruned
--   neighbourhood.</li>
--   </ol>
tabu :: Ord s => StreamT s (List s) -> StreamT s (List s) -> StreamT (List s) s -> StreamT s s

-- | Commonly TABU search does not take a function which makes a TABU list,
--   but rather a size of TABU list. We provide this less flexible form
--   here, where the first parameter changes from to being the window size.
--   The choice function is set to <i>map head</i>. Implemented in terms of
--   <a>tabu</a>.
--   
--   I am not happy with this. What is really needed is a more flexible
--   version of <a>safe</a>, so that rather than just returning the
--   singleton it can return an alternative transformation of the
--   neighbourhood. This is also some scope for using compiler rules here
--   to balance usability with performance.
standardTabu :: Ord s => Int -> StreamT s (List s) -> StreamT s s
tabuFilter :: Eq s => (StreamT s (List s)) -> (StreamT s (List s)) -> (StreamT s (List s))

-- | Simulated Annealing skeleton. This requires a significant number of
--   parameters due to the various stochastic components, temperatures and
--   the need for a numerical valuation of solutions qualities. The
--   parameters are;
--   
--   <ol>
--   <li>a function to get the numerical value of a candidate solution</li>
--   <li>a function to provide a perturbation of a solution, with respect
--   to some external factor, such as a random number, which is what the
--   data type <i>r</i> is expected (though not required) to be.</li>
--   <li>a stream of values representing the temperature or cooling
--   strategy</li>
--   <li>a stream of stochastic values</li>
--   <li>a stream of (stochastic) values for the creation of
--   perturbations</li>
--   </ol>
sa :: (Floating v, Ord v) => (s -> v) -> StreamT s s -> Stream v -> Stream v -> StreamT s s

-- | A logarithmic cooling strategy intended for use within simulated
--   annealing. Broadly the first value is the starting temperature and the
--   second a value between 0 and 1.
logCooling :: Floating b => b -> b -> [b]

-- | Included for completeness, this is a cooling strategy for simulated
--   annealing that is usually not very effective, a linear changing
--   strategy. The first value is the starting temperature the second is
--   the value to increase it by at each step. In order to have it reduce
--   at each step, pass a negative value.
linCooling :: Floating b => b -> b -> [b]

-- | The most common cooling strategy for simulated annealing, geometric.
--   The first value is the starting temperature, the second a value
--   between 0 and 1, the cooling rate.
geoCooling :: Floating b => b -> b -> [b]

-- | The traditional choice function used within simulated annealing. The
--   parameters are; a function to yield quality of a solution, a value
--   between 0 and 1 (stochastic expected) a temperature, the old solution
--   and the possible future solution. Frustratingly this does not make use
--   of <a>Optimisable</a> because it requires the actual floating point
--   quality values of solutions.
saChoose :: (Floating v, Ord v) => (s -> v) -> v -> v -> s -> s -> s
ga :: Int -> Float -> StreamT (List s) s -> StreamT (List s) (List s) -> StreamT s s -> StreamT s s

-- | A simple ACO implementation. It assumes that Ants will be released in
--   groups, which is represented as the population size. It requires a
--   transformation for generating pheromones, and creating new solutions
--   from pheromone data. This will be problem specific.
aco :: Int -> (StreamT (List s) a) -> (StreamT a s) -> StreamT s s

-- | ACO's often use a degrading system, so that the next trail contains
--   some part of the previous trails. This function provides this
--   functionality, assuming that pheromone data can be summed like a
--   number, and an initial state is provided. The stream transformation
--   parameter represents a streamed degrade, for example;
--   
--   <pre>
--   map (*0.1)
--   </pre>
--   
--   would give one tenth of the previous previous pheromone data added to
--   the result. This is a stream transformation to allow for flexibility,
--   for example adding a stochastic element.
pheromoneDegrade :: Num a => a -> StreamT a a -> StreamT a a


-- | This library has embedded within it two example TSP files drawn from
--   the TSPLIB; burma14 and fl417. This module provides a loading routine
--   for these two files only. General loading routines for the TSPLIB
--   format are provided by the Combinatorial Problems library.
--   
--   This module also provides a collection of simple TSP perturbation and
--   recombination methods for use in the following examples. Much of the
--   code for these examples, in terms of the TSP implementation,
--   recombination and perturbation methods is not particularly efficient
--   and only intended for example purposes.
--   
--   To run these examples first use the following imports;
--   
--   <pre>
--   import Control.Search.Local
--   import Control.Search.Local.Example
--   import Control.Search.Local.Strategy
--   import Control.Search.Local.Eager
--   </pre>
--   
--   <ul>
--   <li>A simple maximal iterative improver. This will print out all the
--   solutions encountered.</li>
--   </ul>
--   
--   <pre>
--   loadExampleFile BURMA14 &gt;&gt;= return .  loopP (maximalii (map adjacentExchangeN))
--   </pre>
--   
--   <ul>
--   <li>A stochastic choice from the improvement neighbourhood</li>
--   </ul>
--   
--   <pre>
--   iiExample  
--      = do prob&lt;-loadExampleFile FL417
--           strat&lt;-newStdGen &gt;&gt;= return . stochasticii rChoice . randoms 
--           return . loopP (strat (map adjacentExchangeN)) $ prob
--   where
--     rChoice xs p = xs !! (floor ((p::Float) * fromIntegral (length xs)))             
--   </pre>
--   
--   <ul>
--   <li>The standard TABU search, with a TABU list size of 5</li>
--   </ul>
--   
--   <pre>
--   loadExampleFile BURMA14 &gt;&gt;= return . bestSoFar . loopP (standardTabu 5 (map adjacentExchangeN) (map head))  
--   </pre>
--   
--   <ul>
--   <li>A more complex TABU search, with a varying neighbourhood and
--   varying TABU list size</li>
--   </ul>
--   
--   <pre>
--   tabuExample 
--      = do prob&lt;-loadExampleFile FL417
--           nF  &lt;- newStdGen &gt;&gt;= return . stochasticNeighbourhood 417 
--           vWin &lt;- newStdGen &gt;&gt;= return . varyWindow . randomRs (5,10)
--           return . bestSoFar . loopP (tabu (vWin . window 15) nF (map head)) $ prob
--   </pre>
--   
--   <ul>
--   <li>A simulated annealing search, using an adjacent exchange
--   perturbation and a common geometric cooling strategy. The values of
--   the cooling strategy have been selected through rather rough and ready
--   quick testing.</li>
--   </ul>
--   
--   <pre>
--   saExample 
--    = do prob&lt;-loadExampleFile FL417
--         (fIs,sIs) &lt;- newStdGen &gt;&gt;= return . (\a-&gt;(map head a,map last a)) . chunk 2 . randomRs (0,numCities prob-1) 
--         let perturb = zipWith3 swapPositions fIs sIs
--         choiceRs &lt;-newStdGen &gt;&gt;= return . randoms 
--         return . bestSoFar . loopP (sa getTSPVal perturb 
--                                        (geoCooling 80000 (0.99 :: Float))
--                                        choiceRs) $ prob 
--   </pre>
--   
--   <ul>
--   <li>A genetic algorithm which only makes use of recombination.</li>
--   </ul>
--   
--   <pre>
--   gaNoMutate 
--    = do prob&lt;-loadExampleFile FL417
--         recomb&lt;-newStdGen &gt;&gt;= return . stochasticRecombine
--         startSols &lt;- newStdGen &gt;&gt;= return . randomStarts 20 prob
--         let dist = (++[1]) . takeWhile (&lt;1) $ iterate  (*1.0884) (0.2::Float)
--         rs &lt;- newStdGen &gt;&gt;= return . randoms 
--         return . bestSoFar . loopS (ga (makePop 20) 
--                                        (recomb . gaSelect 2 dist rs) 
--                                        id) $ startSols   
--   </pre>
--   
--   <ul>
--   <li>A complete genetic algorithm that mutates in a random pattern (at
--   a rate of 1/20th)</li>
--   </ul>
--   
--   <pre>
--   gaWithMutate 
--    = do prob&lt;-loadExampleFile FL417
--         recomb&lt;-newStdGen &gt;&gt;= return . stochasticRecombine
--         startSols &lt;- newStdGen &gt;&gt;= return . randomStarts 20 prob
--         pattern &lt;- newStdGen &gt;&gt;= return . map (&lt;(0.05::Float)) . randoms -- boolean pattern
--         (fIs,sIs) &lt;- newStdGen &gt;&gt;= return . (\a-&gt;(map head a,map last a)) . chunk 2 . randomRs (0,numCities prob-1) 
--         let dist = (++[1]) . takeWhile (&lt;1) $ iterate  (*1.0884) (0.2::Float)
--         let mut = nest pattern (zipWith3 swapPositions fIs sIs) 
--         rs &lt;- newStdGen &gt;&gt;= return . randoms 
--         return . bestSoFar . loopS (ga (makePop 20) 
--                                        (recomb . gaSelect 2 dist rs) 
--                                        mut) $ startSols  
--   </pre>
--   
--   All these examples are best demonstrated by composition with the
--   following limiting function, parametrised as seen fit by the user;
--   
--   <pre>
--   strategy &gt;&gt;= return . limiterTSP 0 10 
--   </pre>
module Control.Search.Local.Example
data ExampleFiles
FL417 :: ExampleFiles
BURMA14 :: ExampleFiles

-- | Demonstration loading routine for only two files stored within this
--   library. After loading this routine also randomises the initial
--   solution route.
--   
--   For more general TSP loading routines see <a>TSPLIB</a>.
loadExampleFile :: ExampleFiles -> IO TSPProblem

-- | A synonym for the function <a>swapCitiesOnIndex</a> found in the
--   <a>TSP</a> library. This will form the foundation of our perturbation
--   and neighbourhood functions.
swapPositions :: Int -> Int -> TSPProblem -> TSPProblem

-- | Swap a city, indicated by index, with the city after it, indicated by
--   index.
adjacentExchange :: Int -> TSPProblem -> TSPProblem

-- | For a particular path, generate every path that can exist from
--   swapping adjacent cities.
adjacentExchangeN :: TSPProblem -> [TSPProblem]

-- | Many strategies benefit from a small manageable neighbourhood, but
--   with the opportunity to access wider options. This stream transformer
--   provides this, at each step providing a neighbourhood of size N, drawn
--   randomly from the set of all possible city swaps, adjacent or
--   otherwise.
--   
--   This does not need to be defined as a stream transformer, but the
--   alternative still requires parametrisation with values that will be
--   drawn from a source of random numbers. This version would then require
--   lifting to become a stream transformer, and this introduces more
--   complications in the meta-heuristic code.
stochasticNeighbourhood :: RandomGen g => Int -> g -> StreamT TSPProblem (List TSPProblem)

-- | A recombination process, for use in the genetic algorithm examples.
--   This is presented as a contraction, however it does assume that each
--   population has already been constrained to elements that will form the
--   parents of the new solution. This process also assumes that there will
--   be exactly 2 parents to each new solution, so it is an example of a
--   recombination method only.
stochasticRecombine :: RandomGen g => g -> StreamT (List TSPProblem) TSPProblem

-- | Genetic algorithms require a number of (usually) stochastically
--   generated solutions to begin the process, not 1. This function is
--   provided for these cases, taking the parameters;
--   
--   <ol>
--   <li>the number of solutions to produce</li>
--   <li>a sample solution (for edgeweights and problem size)</li>
--   <li>a random number generator</li>
--   </ol>
randomStarts :: RandomGen g => Int -> TSPProblem -> g -> [TSPProblem]

-- | Not a loading routine, but a synonym for a function within the
--   <a>TSP</a> library.
getTSPVal :: Floating f => TSPProblem -> f

-- | A stream transformation that converts a local search process into a
--   finite list. The function takes a quality function parameter, that can
--   yield a floating point quality of a solution. The remaining functions
--   control the limiting process;
--   
--   <ol>
--   <li>When the difference in quality between two solutions is below the
--   second parameter, terminate (2) The two solutions that we are
--   comparing are divided by the integer parameter</li>
--   </ol>
limiter :: (Floating f, Ord f) => (s -> f) -> f -> Int -> StreamT s s

-- | Specialisation of limiter, fixing the quality function and the problem
--   data type.
limiterTSP :: Double -> Int -> StreamT TSPProblem TSPProblem
