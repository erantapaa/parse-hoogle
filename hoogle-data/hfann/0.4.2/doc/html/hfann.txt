-- Hoogle documentation, generated by Haddock
-- See Hoogle, http://www.haskell.org/hoogle/


-- | Haskell binding to the FANN library
--   
--   hfann is a Haskell binding to the Fast Artificial Neural Network
--   (FANN) library <a>http://leenissen.dk/fann/</a>. It provides functions
--   to easily create, train, test and use Artificial Neural Networks.
@package hfann
@version 0.4.2


-- | The Fast Artificial Neural Network Library (FANN) is a free open
--   source neural network library written in C with support for both fully
--   connected and sparsely connected networks
--   (<a>http://leenissen.dk/fann/</a>).
--   
--   HFANN is a Haskell interface to this library.
module HFANN.Data

-- | The Haskell input/output type
--   
--   This is the data type used in Haskell to represent the input/output
--   data.
type FannType = Double

-- | The C input/output type
--   
--   This is the data type used in the C library to represent the
--   input/output data.
type CFannType = CDouble

-- | A pointer to the C input/output type
type CFannTypePtr = Ptr CDouble

-- | The type of the <tt>Activation Function</tt> enumeration
type ActivationFunction = Word32

-- | The type of the <tt>Training Algorithm</tt> enumeration
type TrainAlgorithm = Word32

-- | Error function used during training.
--   
--   errorFunctionLinear - Standard linear error function.
--   errorFunctionTanH - Tanh error function, usually better but can
--   require a lower learning rate. This error function agressively target
--   outputs that differ much from the desired, while not targetting output
--   that only differ a little that much.
--   
--   The tanh function is not recommended for cascade training and
--   incremental training.
type ErrorFunction = Word32

-- | Stop function used during training
--   
--   stopFunctionMSE - stop criteria is Mean Square Error value.
--   stopFunctionBit - stop criteria is number of bits that fail
--   
--   See <tt>getBitFailLimit</tt>, <tt>setBitFailLimit</tt>.
--   
--   The bits are counted in all of the training data, so this number can
--   be higher than the number of training data.
type StopFunction = Word32

-- | The ANN structure
data Fann
Fann :: Fann

-- | A pointer to an ANN structure
type FannPtr = Ptr Fann

-- | Data type of the training data structure
data TrainData
TrainData :: TrainData

-- | A pointer to the training data structure type
type TrainDataPtr = Ptr TrainData

-- | The Haskell Callback function type
type CallbackType = FannPtr -> TrainDataPtr -> Int -> Int -> Float -> Int -> IO Bool

-- | The C callback function type
type CCallbackType = FannPtr -> TrainDataPtr -> CUInt -> CUInt -> CFloat -> CUInt -> IO Int
activationLinear :: ActivationFunction
activationThreshold :: ActivationFunction
activationThresholdSymmetric :: ActivationFunction
activationSigmoid :: ActivationFunction
activationSigmoidStepwise :: ActivationFunction
activationSigmoidSymmetric :: ActivationFunction
activationSigmoidSymmetricStepwise :: ActivationFunction
activationGaussian :: ActivationFunction
activationGaussianSymmetric :: ActivationFunction

-- | Create a callback function to be used during training for reporting
--   and to stop the training
activationGaussianStepwise :: ActivationFunction
activationElliot :: ActivationFunction
activationElliotSymmetric :: ActivationFunction
activationLinearPiece :: ActivationFunction
activationLinearPieceSymmetric :: ActivationFunction
trainIncremental :: TrainAlgorithm
trainBatch :: TrainAlgorithm
trainRPROP :: TrainAlgorithm
trainQuickProp :: TrainAlgorithm
errorFunctionLinear :: ErrorFunction
errorFunctionTanH :: ErrorFunction
stopFunctionMSE :: StopFunction
stopFunctionBit :: StopFunction
fannCallback :: (CallbackType) -> IO (FunPtr CCallbackType)


-- | The Fast Artificial Neural Network Library (FANN) is a free open
--   source neural network library written in C with support for both fully
--   connected and sparsely connected networks
--   (<a>http://leenissen.dk/fann/</a>).
--   
--   HFANN is a Haskell interface to this library.
module HFANN.IO

-- | Save an Artificial Neural Network (ANN) to a file
saveFann :: FannPtr -> String -> IO ()

-- | Load an ANN and call the given function with the ANN as argument. Once
--   finished, destroy the ANN.
withSavedFann :: String -> (FannPtr -> IO a) -> IO a


-- | The Fast Artificial Neural Network Library (FANN) is a free open
--   source neural network library written in C with support for both fully
--   connected and sparsely connected networks
--   (<a>http://leenissen.dk/fann/</a>).
--   
--   HFANN is a Haskell interface to this library.
module HFANN.Base

-- | Create a new standard fully connected Neural Network and call the
--   given function with the ANN as argument. When finished destroy the
--   Neural Network.
--   
--   The structure of the ANN is given by the first parameter. It's an Int
--   list giving the number of nodes per layer from input layer to output
--   layer.
--   
--   Example: <tt>[2,3,1]</tt> would describe an ANN with 2 nodes in the
--   input layer, one hidden layer of 3 nodes and 1 node in the output
--   layer.
--   
--   The function provided as second argument will be called with the
--   created ANN as parameter.
withStandardFann :: [Int] -> (FannPtr -> IO a) -> IO a

-- | Create a new sparse not fully connected Neural Network and call the
--   given function with the ANN as argument. When finished destroy the
--   ANN.
withSparseFann :: Float -> [Int] -> (FannPtr -> IO a) -> IO a

-- | Create a new sparse not fully connected Neural Network with shortcut
--   connections between layers and call the given function with the ANN as
--   argument. When finished destroy the Neural Network
withShortcutFann :: [Int] -> (FannPtr -> IO a) -> IO a

-- | Randomize weights to values in the given range
--   
--   Weights in a newly created ANN are already initialized to random
--   values. You can use this function if you want to customize the random
--   weights upper and lower bounds.
randomizeWeights :: FannPtr -> (FannType, FannType) -> IO ()

-- | Initialize the weights using Widrow + Nguyenâ€™s algorithm.
--   
--   This function behaves similarly to fann_randomize_weights. It will use
--   the algorithm developed by Derrick Nguyen and Bernard Widrow to set
--   the weights in such a way as to speed up training. This technique is
--   not always successful, and in some cases can be less efficient than a
--   purely random initialization.
--   
--   The algorithm requires access to the range of the input data (ie,
--   largest and smallest input), and therefore accepts a second argument,
--   data, which is the training data that will be used to train the
--   network.
initWeights :: FannPtr -> TrainDataPtr -> IO ()

-- | Run the trained Neural Network on provided input
runFann :: FannPtr -> [FannType] -> IO [FannType]

-- | Print the ANN connections
printConnections :: FannPtr -> IO ()

-- | Print the ANN parameters
printParameters :: FannPtr -> IO ()

-- | Return the number of output nodes of the Neural Network
getOutputNodesCount :: FannPtr -> IO Int

-- | Return the number of input nodes of the Neural Network
getInputNodesCount :: FannPtr -> IO Int

-- | Return the total number of nodes of the Neural Network
getTotalNodesCount :: FannPtr -> IO Int

-- | Return the total number of connections of the Neural Network
getConnectionsCount :: FannPtr -> IO Int


-- | The Fast Artificial Neural Network Library (FANN) is a free open
--   source neural network library written in C with support for both fully
--   connected and sparsely connected networks
--   (<a>http://leenissen.dk/fann/</a>).
--   
--   HFANN is a Haskell interface to this library.
module HFANN.Train

-- | Train the Neural Network on the given input and output values
train :: FannPtr -> [FannType] -> [FannType] -> IO ()

-- | Train one epoch with a set of training data
--   
--   Train one epoch with the given training data. One epoch is where all
--   the training data is considered exactly once.
--   
--   The function returns the MSE error as it is calculated either before
--   or during the actual training. This is not the actual MSE after the
--   training epoch but since calculating this will require to go through
--   the entire training set once more it is more adequate to use this
--   value during training.
--   
--   The training algorithm used by this function is chosen by the
--   <a>setTrainingAlgorithm</a> function.
--   
--   See also: <a>trainOnData</a>, <a>testData</a>
trainEpoch :: FannPtr -> TrainDataPtr -> IO Float

-- | Train the Neural Network on the given data file
trainOnFile :: FannPtr -> String -> Int -> Int -> Double -> IO ()

-- | Train the Neural Network on a training dataset.
--   
--   Instead of printing out reports every "epochs between reports", a
--   callback function can be called (see <a>setCallback</a>)
--   
--   A value of zero in the <a>epochs between reports</a> means no reports
--   should be printed.
trainOnData :: FannPtr -> TrainDataPtr -> Int -> Int -> Double -> IO ()

-- | Test ANN on training data
--   
--   This function will run the ANN on the training data and return the
--   error value. It can be used to validate the check the quality of the
--   ANN on some test data.
testData :: FannPtr -> TrainDataPtr -> IO CFloat

-- | Test the Neural Network on the given input and output values
test :: FannPtr -> [FannType] -> [FannType] -> IO [FannType]

-- | Get the mean square error from the ANN
--   
--   This value is calculated during training or testing, and can therefore
--   sometimes be a bit off if the weights have been changed since the last
--   calculation of the value.
getMSE :: FannPtr -> IO Float

-- | Reset the mean square error from the network.
--   
--   This function also resets the number of bits that fail.
resetMSE :: FannPtr -> IO ()

-- | Get the number of fail bits
--   
--   The number of fail bits means the number of output neurons which
--   differ more than the bit fail limit (see <a>getBitFailLimit</a>,
--   <a>setBitFailLimit</a>).
--   
--   This value is reset by <a>resetMSE</a> and updated by the same
--   functions which also updates the MSE value <a>testData</a>,
--   <a>trainEpoch</a>.
getBitFail :: FannPtr -> IO Int

-- | Read training data from file and run the given function on that data.
withTrainData :: String -> (TrainDataPtr -> IO a) -> IO a

-- | Reads training data from a file.
--   
--   The file must be formatted like:
--   
--   <pre>
--   num_records num_input num_output
--   inputdata separated by space
--   outputdata separated by space
--   
--   ...
--   ...
--   
--   inputdata separated by space
--   outputdata separated by space
--   </pre>
--   
--   See also: <a>trainOnData</a>, <tt>destroyTrain</tt>,
--   <tt>saveTrain</tt>
loadTrainData :: String -> IO TrainDataPtr

-- | Destroy training data
--   
--   Destroy training data and properly deallocates the memory.
--   
--   Be sure to use this function after finished using the training data
--   unless the training data is part of a <a>withTrainData</a> call.
destroyTrainData :: TrainDataPtr -> IO ()

-- | Shuffles training data, randomizing the order.
--   
--   This is recomended for incremental training, while it has no influence
--   during batch training
shuffleTrainData :: TrainDataPtr -> IO ()

-- | Scales the inputs in the training data to the specified range.
--   
--   See also: <tt>scaleOutputData</tt>, <a>scaleTrainData</a>
scaleInputTrainData :: TrainDataPtr -> FannType -> FannType -> IO ()

-- | Scales the output in the training data to the specified range.
--   
--   See also: <tt>scaleInputData</tt>, <a>scaleTrainData</a>
scaleOutputTrainData :: TrainDataPtr -> FannType -> FannType -> IO ()

-- | Scales the inputs and outputs in the training data to the specified
--   range.
--   
--   See also: <tt>scaleOutputData</tt>, <tt>scaleInputData</tt>
scaleTrainData :: TrainDataPtr -> FannType -> FannType -> IO ()

-- | Merges two training data sets into a new one.
mergeTrainData :: TrainDataPtr -> TrainDataPtr -> IO TrainDataPtr

-- | Returns an exact copy of a training data set.
duplicateTrainData :: TrainDataPtr -> IO TrainDataPtr

-- | Returns a copy of a subset of the training data, starting at the given
--   offset and taking the given count of elements.
--   
--   <pre>
--   len &lt;- trainDataLength tdata
--   newtdata &lt;- subsetTrainData tdata 0 len
--   </pre>
--   
--   Will do the same as <a>duplicateTrainData</a>
--   
--   See also: <a>trainDataLength</a>
subsetTrainData :: TrainDataPtr -> Int -> Int -> IO TrainDataPtr

-- | Returns the number of training patterns in the training data.
trainDataLength :: TrainDataPtr -> IO Int

-- | Returns the number of input nodes in the training data
getTrainDataInputNodesCount :: TrainDataPtr -> IO Int

-- | Returns the number of output nodes in the training data
getTrainDataOutputNodesCount :: TrainDataPtr -> IO Int

-- | Save the training structure to a file with the format as specified in
--   <a>loadTrainData</a>
--   
--   See also <a>loadTrainData</a>
saveTrainData :: TrainDataPtr -> String -> IO ()

-- | Return the training algorithm. This training algorithm is used by
--   <a>trainOnData</a> and associated functions.
--   
--   Note that this algorithm is also used during
--   <tt>cascadeTrainOnData</tt> although only fannTrainRPROP and
--   fannTrainQuickProp is allowed during cascade training.
--   
--   See also: <a>setTrainingAlgorithm</a>, <a>TrainAlgorithm</a>
getTrainingAlgorithm :: FannPtr -> IO TrainAlgorithm

-- | Set the training algorithm.
--   
--   See also: <a>getTrainingAlgorithm</a>, <tt>TrainingAlgorithm</tt>
setTrainingAlgorithm :: FannPtr -> TrainAlgorithm -> IO ()

-- | Return the learning rate.
--   
--   The learning rate is used to determine how aggressive the training
--   should be for some of the training algorithms
--   (<tt>fannTrainIncremental</tt>, <tt>fannTrainBatch</tt>,
--   <tt>fannTrainQuickProp</tt>).
--   
--   Note that it is not used in <tt>fannTrainRPROP</tt>.
--   
--   The default learning rate is 0.7.
--   
--   See also: <a>setLearningRate</a>, <a>setTrainingAlgorithm</a>
getLearningRate :: FannPtr -> IO Float

-- | Set the learning rate.
--   
--   See getLearningRate for more information about the learning rate.
--   
--   See also: <tt>getLearingRate</tt>
setLearningRate :: FannPtr -> Float -> IO ()

-- | Return the learning momentum.
--   
--   The learning momentum can be used to speed up the
--   <tt>fannTrainIncremental</tt> training algorithm.
--   
--   A too high momentum will however not benefit training. Setting
--   momentum to 0 will be the same as not using the momentum parameter.
--   The recommended value for this parameter is between 0.0 and 1.0.
--   
--   The default momentum is 0.
--   
--   See also: <a>setLearningMomentum</a>, <a>setTrainingAlgorithm</a>
getLearningMomentum :: FannPtr -> IO Float

-- | Set the learning momentum.
--   
--   More info available in <a>getLearningMomentum</a>.
setLearningMomentum :: FannPtr -> Float -> IO ()

-- | Set the activation function for the neuron specified in layer
--   specified, counting the input layer as layer 0.
--   
--   It is not possible to set activation functions for the neurons in the
--   input layer.
--   
--   When choosing an activation function it is important to note that the
--   activation function have different range. In <tt>fannSigmoid</tt> is
--   in the 0 .. 1 range while fannSigmoidSymmetric is in the -1 .. 1 range
--   and fannLinear is unbound.
--   
--   The default activation function is fannSigmoidStepwise.
--   
--   See also: <a>setActivationFunctionLayer</a>,
--   <a>setActivationFunctionHidden</a>,
--   <a>setActivationFunctionOutput</a>, <a>setActivationSteepness</a>
setActivationFunction :: FannPtr -> ActivationFunction -> Int -> Int -> IO ()

-- | Set the activation function for all neurons of a given layer, counting
--   the input layer as layer 0.
--   
--   It is not possible to set an activation function for the neurons in
--   the input layer.
--   
--   See also: <a>setActivationFunction</a>,
--   <a>setActivationFunctionHidden</a>,
--   <a>setActivationFunctionOutput</a>, <a>setActivationSteepnessLayer</a>
setActivationFunctionLayer :: FannPtr -> ActivationFunction -> Int -> IO ()

-- | Set the activation function for all the hidden layers.
--   
--   See also: <a>setActivationFunction</a>,
--   <a>setActivationFunctionLayer</a>, <a>setActivationFunctionOutput</a>
setActivationFunctionHidden :: FannPtr -> ActivationFunction -> IO ()

-- | Set the activation function for the output layer.
--   
--   See also: <a>setActivationFunction</a>,
--   <a>setActivationFunctionLayer</a>, <a>setActivationFunctionHidden</a>
setActivationFunctionOutput :: FannPtr -> ActivationFunction -> IO ()

-- | Set the activation steepness of the specified neuron in the specified
--   layer, counting the input layer as 0.
--   
--   It is not possible to set activation steepness for the neurons in the
--   input layer.
--   
--   The steepness of an activation function says something about how fast
--   the activation function goes from the minimum to the maximum. A high
--   value for the activation function will also give a more agressive
--   training.
--   
--   When training networks where the output values should be at the
--   extremes (usually 0 and 1, depending on the activation function), a
--   steep activation can be used (e.g. 1.0).
--   
--   The default activation steepness is 0.5
--   
--   See also: <a>setActivationSteepnessLayer</a>,
--   <a>setActivationSteepnessHidden</a>,
--   <a>setActivationSteepnessOutput</a>, <a>setActivationFunction</a>
setActivationSteepness :: FannPtr -> FannType -> Int -> Int -> IO ()

-- | Set the activation steepness for all of the neurons in the given
--   layer, counting the input layer as layer 0.
--   
--   It is not possible to set the activation steepness for the neurons in
--   the input layer.
--   
--   See also: <a>setActivationSteepness</a>,
--   <a>setActivationSteepnessHidden</a>,
--   <a>setActivationSteepnessOutput</a>, <a>setActivationFunction</a>.
setActivationSteepnessLayer :: FannPtr -> FannType -> Int -> IO ()

-- | Set the activation steepness of all the nodes in all hidden layers.
--   
--   See also: <a>setActivationSteepness</a>,
--   <a>setActivationSteepnessLayer</a>,
--   <a>setActivationSteepnessOutput</a>, <a>setActivationFunction</a>
setActivationSteepnessHidden :: FannPtr -> FannType -> IO ()

-- | Set the activation steepness of all the nodes in all output layer.
--   
--   See also: <a>setActivationSteepness</a>,
--   <a>setActivationSteepnessLayer</a>,
--   <a>setActivationSteepnessHidden</a>, <a>setActivationFunction</a>
setActivationSteepnessOutput :: FannPtr -> FannType -> IO ()

-- | Return the error function used during training.
--   
--   The error function is described in <a>ErrorFunction</a>
--   
--   The default error function is <tt>errorFunctionTanH</tt>
--   
--   See also: <a>setTrainErrorFunction</a>
getTrainErrorFunction :: FannPtr -> IO ErrorFunction

-- | Set the error function used during training.
--   
--   The error function is described in <a>ErrorFunction</a>
--   
--   See also: <a>getTrainErrorFunction</a>
setTrainErrorFunction :: FannPtr -> ErrorFunction -> IO ()

-- | Returns the stop function used during training.
--   
--   The stop function is described in <a>StopFunction</a>
--   
--   The default stop function is <tt>stopFunctionMSE</tt>
--   
--   See also: <a>setTrainStopFunction</a>, <a>setBitFailLimit</a>
getTrainStopFunction :: FannPtr -> IO StopFunction

-- | Set the stop function used during training.
--   
--   The stop function is described in <a>StopFunction</a>
--   
--   The default stop function is <tt>stopFunctionMSE</tt>
--   
--   See also: <a>getTrainStopFunction</a>, <a>getBitFailLimit</a>
setTrainStopFunction :: FannPtr -> StopFunction -> IO ()

-- | Returns the bit fail limit used during training.
--   
--   The bit fail limit is used during training where the
--   <a>StopFunction</a> is set <tt>stopFunctionBit</tt>.
--   
--   The limit is the maximum accepted difference between the desired
--   output and the actual output during training. Each output that
--   diverges more than this is counted as an error bit.
--   
--   This difference is divided by two when dealing with symmetric
--   activation functions, so that symmetric and not symmetric activation
--   functions can use the same limit.
--   
--   The default bit fail limit is 0.35.
--   
--   See also: <a>setBitFailLimit</a>
getBitFailLimit :: FannPtr -> IO FannType

-- | Set the bit fail limit used during training.
--   
--   See also: <a>getBitFailLimit</a>
setBitFailLimit :: FannPtr -> FannType -> IO ()

-- | Set the callback function to be used for reporting and to stop
--   training
--   
--   The callback function will be called based on the "Epoch between
--   reports" defined frequency.
--   
--   The type of the callback function is:
--   
--   <pre>
--   callback :: FannPtr      -- The ANN being trained
--            -&gt; TrainDataPtr -- The training data in use
--            -&gt; Int          -- Max number of epochs
--            -&gt; Int          -- Number of epochs between reports
--            -&gt; Float        -- Desired error
--            -&gt; Int          -- Current epoch
--            -&gt; Bool         -- True to terminate training, False to continue
--   </pre>
setCallback :: FannPtr -> CallbackType -> IO ()

-- | Returns the quickprop decay
--   
--   The decay is a small negative valued number which is the factor that
--   the weights should become smaller in each iteration during quickprop
--   training.
--   
--   This is used to make sure that the weights do not become too high
--   during training.
--   
--   The default decay is -0.0001
--   
--   See also: <a>setQuickPropDecay</a>
getQuickPropDecay :: FannPtr -> IO Float

-- | Sets the quickprop decay factor
--   
--   See also: <a>getQuickPropDecay</a>
setQuickPropDecay :: FannPtr -> Float -> IO ()

-- | Returns the quickprop mu factor
--   
--   The mu factor is used to increase and decrease the step-size during
--   quickprop training. The mu factor should always be above 1, since it
--   would otherwise decrease the step-size when it was supposed to
--   increase it.
--   
--   The default mu factor is 1.75
--   
--   See also: <a>setQuickPropMu</a>
getQuickPropMu :: FannPtr -> IO Float

-- | Sets the quickprop mu factor
--   
--   See also: <a>getQuickPropMu</a>
setQuickPropMu :: FannPtr -> Float -> IO ()

-- | Returns the RPROP increase factor
--   
--   The RPROP increase factor is a value larger than 1, which is used to
--   increase the step-size during RPROP training.
--   
--   The default increase factor is 1.2
--   
--   See also: <a>setRPROPIncreaseFactor</a>
getRPROPIncreaseFactor :: FannPtr -> IO Float

-- | Sets the RPROP increase factor
--   
--   See also: <a>getRPROPIncreaseFactor</a>
setRPROPIncreaseFactor :: FannPtr -> Float -> IO ()

-- | Returns the RPROP decrease factor
--   
--   The RPROP decrease factor is a value larger than 1, which is used to
--   decrease the step-size during RPROP training.
--   
--   The default decrease factor is 0.5
--   
--   See also: <a>setRPROPDecreaseFactor</a>
getRPROPDecreaseFactor :: FannPtr -> IO Float

-- | Sets the RPROP decrease factor
--   
--   See also: <a>getRPROPDecreaseFactor</a>
setRPROPDecreaseFactor :: FannPtr -> Float -> IO ()

-- | Returns the RPROP delta min factor
--   
--   The delta min factor is a small positive number determining how small
--   the minimum step-size may be.
--   
--   The default value delta min is 0.0
--   
--   See also: <a>setRPROPDeltaMin</a>
getRPROPDeltaMin :: FannPtr -> IO Float

-- | Sets the RPROP delta min
--   
--   See also: <a>getRPROPDeltaMin</a>
setRPROPDeltaMin :: FannPtr -> Float -> IO ()

-- | Returns the RPROP delta max factor
--   
--   The delta max factor is a positive number determining how large the
--   maximum step-size may be.
--   
--   The default value delta max is 50.0
--   
--   See also: <a>setRPROPDeltaMax</a>
getRPROPDeltaMax :: FannPtr -> IO Float

-- | Sets the RPROP delta max
--   
--   See also: <a>getRPROPDeltaMax</a>
setRPROPDeltaMax :: FannPtr -> Float -> IO ()


-- | The Fast Artificial Neural Network Library (FANN) is a free open
--   source neural network library written in C with support for both fully
--   connected and sparsely connected networks
--   (<a>http://leenissen.dk/fann/</a>).
--   
--   HFANN is a Haskell interface to this library.
--   
--   See below for examples.
module HFANN
