-- Hoogle documentation, generated by Haddock
-- See Hoogle, http://www.haskell.org/hoogle/


-- | Data Parallel Haskell segmented arrays. (production version)
--   
--   Production implementation of the flat parallel array API defined in
--   dph-prim-interface.
@package dph-prim-par
@version 0.7.0.1


-- | Subarrays of flat unlifted arrays.
module Data.Array.Parallel.Unlifted.Parallel.Subarrays

-- | Drop a the element at the provided index from a vector.
dropUP :: Unbox e => Int -> Vector e -> Vector e

module Data.Array.Parallel.Unlifted.Distributed.What

-- | What distributed computation we are doing.
data Comp
CGen :: Bool -> What -> Comp
CMap :: What -> Comp
CFold :: What -> Comp
CScan :: What -> Comp
CDist :: What -> Comp

-- | What sort of thing is being computed.
data What
What :: String -> What
WScalar :: What
WZip :: What
WSlice :: What
WLength :: What
WLengthIdx :: What
WBpermute :: What
WJoinCopy :: Int -> What
WFMapMap :: What -> What -> What
WFMapGen :: What -> What -> What
WFZipMap :: What -> What -> What
instance Eq What
instance Ord What
instance Read What
instance Show What
instance Eq Comp
instance Ord Comp
instance Read Comp
instance Show Comp


-- | Gang primitives.
module Data.Array.Parallel.Unlifted.Distributed.Primitive.Gang

-- | A <a>Gang</a> is a group of threads which execute arbitrary work
--   requests.
data Gang
data Workload

-- | Unknown workload. Just run it in parallel.
WorkUnknown :: Workload

-- | Memory bound copy-like workload, of the given number of bytes.
WorkCopy :: Int -> Workload

-- | A sequential gang has no threads.
seqGang :: Gang -> Gang

-- | Fork a <a>Gang</a> with the given number of threads (at least 1).
forkGang :: Int -> IO Gang

-- | O(1). Yield the number of threads in the <a>Gang</a>.
gangSize :: Gang -> Int

-- | Issue work requests for the <a>Gang</a> and wait until they have been
--   executed. If the gang is already busy then just run the action in the
--   requesting thread.
gangIO :: Gang -> String -> Workload -> (Int -> IO ()) -> IO ()

-- | Same as <a>gangIO</a> but in the <a>ST</a> monad.
gangST :: Gang -> String -> Workload -> (Int -> ST s ()) -> ST s ()
instance Eq Workload
instance Show Workload
instance Show Gang

module Data.Array.Parallel.Unlifted.Distributed.Primitive.DT

-- | Class of distributable types. Instances of <a>DT</a> can be
--   distributed across all workers of a <a>Gang</a>. All such types must
--   be hyperstrict as we do not want to pass thunks into distributed
--   computations.
class DT a where data family Dist a data family MDist a :: * -> * deepSeqD = seq measureD _ = "None"
indexD :: DT a => String -> Dist a -> Int -> a
newMD :: DT a => Gang -> ST s (MDist a s)
readMD :: DT a => MDist a s -> Int -> ST s a
writeMD :: DT a => MDist a s -> Int -> a -> ST s ()
unsafeFreezeMD :: DT a => MDist a s -> ST s (Dist a)
deepSeqD :: DT a => a -> b -> b
sizeD :: DT a => Dist a -> Int
sizeMD :: DT a => MDist a s -> Int
measureD :: DT a => a -> String

-- | Check that the sizes of the <a>Gang</a> and of the distributed value
--   match.
checkGangD :: DT a => String -> Gang -> Dist a -> b -> b

-- | Check that the sizes of the <a>Gang</a> and of the mutable distributed
--   value match.
checkGangMD :: DT a => String -> Gang -> MDist a s -> b -> b

-- | Given a computation that can write its result to a mutable distributed
--   value, run the computation to generate an immutable distributed value.
newD :: DT a => Gang -> (forall s. MDist a s -> ST s ()) -> Dist a

-- | Show all members of a distributed value.
debugD :: DT a => Dist a -> String
instance (Show a, DT a) => Show (Dist a)


-- | Distribution of Tuples
module Data.Array.Parallel.Unlifted.Distributed.Data.Tuple

-- | Pairing of distributed values. The two values must belong to the same
--   <tt>Gang</tt>.
zipD :: (DT a, DT b) => Dist a -> Dist b -> Dist (a, b)

-- | Unpairing of distributed values.
unzipD :: (DT a, DT b) => Dist (a, b) -> (Dist a, Dist b)

-- | Extract the first elements of a distributed pair.
fstD :: (DT a, DT b) => Dist (a, b) -> Dist a

-- | Extract the second elements of a distributed pair.
sndD :: (DT a, DT b) => Dist (a, b) -> Dist b

-- | Pairing of distributed values. <i>The two values must belong to the
--   same</i> <tt>Gang</tt>.
zip3D :: (DT a, DT b, DT c) => Dist a -> Dist b -> Dist c -> Dist (a, b, c)

-- | Unpairing of distributed values.
unzip3D :: (DT a, DT b, DT c) => Dist (a, b, c) -> (Dist a, Dist b, Dist c)
instance (DT a, DT b, DT c) => DT (a, b, c)
instance (PprPhysical (Dist a), PprPhysical (Dist b)) => PprPhysical (Dist (a, b))
instance (DT a, DT b) => DT (a, b)


-- | Distributed ST computations.
--   
--   Computations of type <a>DistST</a> are data-parallel computations
--   which are run on each thread of a gang. At the moment, they can only
--   access the element of a (possibly mutable) distributed value owned by
--   the current thread.
--   
--   <i>TODO:</i> Add facilities for implementing parallel scans etc.
--   
--   TODO:
module Data.Array.Parallel.Unlifted.Distributed.Primitive.DistST

-- | Data-parallel computations. When applied to a thread gang, the
--   computation implicitly knows the index of the thread it's working on.
--   Alternatively, if we know the thread index then we can make a regular
--   ST computation.
data DistST s a

-- | Lifts an <a>ST</a> computation into the <a>DistST</a> monad. The
--   lifted computation should be data parallel.
stToDistST :: ST s a -> DistST s a

-- | Execute a data-parallel computation on a <a>Gang</a>. The same DistST
--   comutation runs on each thread.
distST_ :: Comp -> Gang -> DistST s () -> ST s ()

-- | Execute a data-parallel computation, yielding the distributed result.
distST :: DT a => Comp -> Gang -> DistST s a -> ST s (Dist a)

-- | Run a data-parallel computation, yielding the distributed result.
runDistST :: DT a => Comp -> Gang -> (forall s. DistST s a) -> Dist a
runDistST_seq :: DT a => Gang -> (forall s. DistST s a) -> Dist a

-- | Yields the index of the current thread within its gang.
myIndex :: DistST s Int

-- | Yields the <a>Dist</a> element owned by the current thread.
myD :: DT a => Dist a -> DistST s a

-- | Yields the <a>MDist</a> element owned by the current thread.
readMyMD :: DT a => MDist a s -> DistST s a

-- | Writes the <a>MDist</a> element owned by the current thread.
writeMyMD :: DT a => MDist a s -> a -> DistST s ()
mapDST_ :: DT a => What -> Gang -> (a -> DistST s ()) -> Dist a -> ST s ()
mapDST :: (DT a, DT b) => What -> Gang -> (a -> DistST s b) -> Dist a -> ST s (Dist b)
zipWithDST_ :: (DT a, DT b) => What -> Gang -> (a -> b -> DistST s ()) -> Dist a -> Dist b -> ST s ()
zipWithDST :: (DT a, DT b, DT c) => What -> Gang -> (a -> b -> DistST s c) -> Dist a -> Dist b -> ST s (Dist c)
instance Monad (DistST s)


-- | Standard combinators for distributed types.
module Data.Array.Parallel.Unlifted.Distributed.Primitive.Operators

-- | Create a distributed value, given a function to create the instance
--   for each thread.
generateD :: DT a => What -> Gang -> (Int -> a) -> Dist a

-- | Create a distributed value, but do it sequentially.
--   
--   This function is used when we want to operate on a distributed value,
--   but there isn't much data involved. For example, if we want to
--   distribute a single integer to each thread, then there's no need to
--   fire up the gang for this.
generateD_cheap :: DT a => What -> Gang -> (Int -> a) -> Dist a

-- | Map a function across all elements of a distributed value. The worker
--   function also gets the current thread index.
imapD' :: (DT a, DT b) => What -> Gang -> (Int -> a -> b) -> Dist a -> Dist b

-- | Fold all the instances of a distributed value.
foldD :: DT a => What -> Gang -> (a -> a -> a) -> Dist a -> a

-- | Prefix sum of the instances of a distributed value.
scanD :: DT a => What -> Gang -> (a -> a -> a) -> a -> Dist a -> (Dist a, a)


-- | Standard combinators for distributed types.
module Data.Array.Parallel.Unlifted.Distributed.Primitive

-- | A <a>Gang</a> is a group of threads which execute arbitrary work
--   requests.
data Gang

-- | O(1). Yield the number of threads in the <a>Gang</a>.
gangSize :: Gang -> Int

-- | A sequential gang has no threads.
seqGang :: Gang -> Gang

-- | Fork a <a>Gang</a> with the given number of threads (at least 1).
forkGang :: Int -> IO Gang

-- | DPH programs use this single, shared gang of threads. The gang exists
--   at top level, and is initialised at program start.
--   
--   The vectoriser guarantees that the gang is only used by a single
--   computation at a time. This is true because the program produced by
--   the vector only uses flat parallelism, so parallel computations don't
--   invoke further parallel computations. If the vectorised program tries
--   to use nested parallelism then there is a bug in the vectoriser, and
--   the code will run sequentially.
theGang :: Gang

-- | Class of distributable types. Instances of <a>DT</a> can be
--   distributed across all workers of a <a>Gang</a>. All such types must
--   be hyperstrict as we do not want to pass thunks into distributed
--   computations.
class DT a where data family Dist a data family MDist a :: * -> * deepSeqD = seq measureD _ = "None"
indexD :: DT a => String -> Dist a -> Int -> a
newMD :: DT a => Gang -> ST s (MDist a s)
readMD :: DT a => MDist a s -> Int -> ST s a
writeMD :: DT a => MDist a s -> Int -> a -> ST s ()
unsafeFreezeMD :: DT a => MDist a s -> ST s (Dist a)
deepSeqD :: DT a => a -> b -> b
sizeD :: DT a => Dist a -> Int
sizeMD :: DT a => MDist a s -> Int
measureD :: DT a => a -> String

-- | Given a computation that can write its result to a mutable distributed
--   value, run the computation to generate an immutable distributed value.
newD :: DT a => Gang -> (forall s. MDist a s -> ST s ()) -> Dist a

-- | Show all members of a distributed value.
debugD :: DT a => Dist a -> String

-- | Check that the sizes of the <a>Gang</a> and of the distributed value
--   match.
checkGangD :: DT a => String -> Gang -> Dist a -> b -> b

-- | Create a distributed value, given a function to create the instance
--   for each thread.
generateD :: DT a => What -> Gang -> (Int -> a) -> Dist a

-- | Create a distributed value, but do it sequentially.
--   
--   This function is used when we want to operate on a distributed value,
--   but there isn't much data involved. For example, if we want to
--   distribute a single integer to each thread, then there's no need to
--   fire up the gang for this.
generateD_cheap :: DT a => What -> Gang -> (Int -> a) -> Dist a

-- | Map a function across all elements of a distributed value. The worker
--   function also gets the current thread index.
imapD' :: (DT a, DT b) => What -> Gang -> (Int -> a -> b) -> Dist a -> Dist b

-- | Fold all the instances of a distributed value.
foldD :: DT a => What -> Gang -> (a -> a -> a) -> Dist a -> a

-- | Prefix sum of the instances of a distributed value.
scanD :: DT a => What -> Gang -> (a -> a -> a) -> a -> Dist a -> (Dist a, a)


-- | Distribution of values of primitive types.
module Data.Array.Parallel.Unlifted.Distributed.Primitive.DPrim

-- | For distributed primitive values, we can just store all the members in
--   a vector. The vector has the same length as the number of threads in
--   the gang.
class Unbox e => DPrim e
mkDPrim :: DPrim e => Vector e -> Dist e
unDPrim :: DPrim e => Dist e -> Vector e
mkMDPrim :: DPrim e => STVector s e -> MDist e s
unMDPrim :: DPrim e => MDist e s -> STVector s e

-- | Get the member corresponding to a thread index.
primIndexD :: DPrim a => String -> Dist a -> Int -> a

-- | Create a new distributed value, having as many members as threads in
--   the given <a>Gang</a>.
primNewMD :: DPrim a => Gang -> ST s (MDist a s)

-- | Read the member of a distributed value corresponding to the given
--   thread index.
primReadMD :: DPrim a => MDist a s -> Int -> ST s a

-- | Write the member of a distributed value corresponding to the given
--   thread index.
primWriteMD :: DPrim a => MDist a s -> Int -> a -> ST s ()

-- | Freeze a mutable distributed value to an immutable one. You promise
--   not to update the mutable one any further.
primUnsafeFreezeMD :: DPrim a => MDist a s -> ST s (Dist a)

-- | Get the size of a distributed value, that is, the number of threads in
--   the gang that it was created for.
primSizeD :: DPrim a => Dist a -> Int

-- | Get the size of a distributed mutable value, that is, the number of
--   threads in the gang it was created for.
primSizeMD :: DPrim a => MDist a s -> Int


-- | <a>DPrim</a> and <a>DT</a> instances for scalar types.
module Data.Array.Parallel.Unlifted.Distributed.Data.Scalar.Base
instance DT Double
instance DPrim Double
instance DT Float
instance DPrim Float
instance DT Word8
instance DPrim Word8
instance DT Int
instance DPrim Int
instance DT Char
instance DPrim Char
instance DT Integer
instance DPrim Integer

module Data.Array.Parallel.Unlifted.Distributed.Data.Bool

-- | OR together all instances of a distributed <a>Bool</a>.
orD :: Gang -> Dist Bool -> Bool

-- | AND together all instances of a distributed <a>Bool</a>.
andD :: Gang -> Dist Bool -> Bool
instance DT Bool
instance DPrim Bool


-- | Distribution of Maybes.
module Data.Array.Parallel.Unlifted.Distributed.Data.Maybe
instance DT a => DT (Maybe a)


-- | Distribution of values of primitive types.
module Data.Array.Parallel.Unlifted.Distributed.Data.Ordering
instance DT Ordering
instance DPrim Ordering


-- | Distribution of unit values.
module Data.Array.Parallel.Unlifted.Distributed.Data.Unit

-- | Yield a distributed unit.
unitD :: Gang -> Dist ()
instance DT ()


-- | Standard combinators for distributed types.
module Data.Array.Parallel.Unlifted.Distributed.Combinators

-- | What sort of thing is being computed.
data What
What :: String -> What
WScalar :: What
WZip :: What
WSlice :: What
WLength :: What
WLengthIdx :: What
WBpermute :: What
WJoinCopy :: Int -> What
WFMapMap :: What -> What -> What
WFMapGen :: What -> What -> What
WFZipMap :: What -> What -> What

-- | Map a function across all elements of a distributed value. The worker
--   function also gets the current thread index. As opposed to
--   <a>imapD'</a> this version also deepSeqs each element before passing
--   it to the function.
imapD :: (DT a, DT b) => What -> Gang -> (Int -> a -> b) -> Dist a -> Dist b

-- | Map a function to every instance of a distributed value.
--   
--   This applies the function to every thread, but not every value held by
--   the thread. If you want that then use something like:
--   
--   <pre>
--   mapD theGang (V.map (+ 1)) :: Dist (Vector Int) -&gt; Dist (Vector Int)
--   </pre>
mapD :: (DT a, DT b) => What -> Gang -> (a -> b) -> Dist a -> Dist b

-- | Pairing of distributed values. The two values must belong to the same
--   <tt>Gang</tt>.
zipD :: (DT a, DT b) => Dist a -> Dist b -> Dist (a, b)

-- | Unpairing of distributed values.
unzipD :: (DT a, DT b) => Dist (a, b) -> (Dist a, Dist b)

-- | Extract the first elements of a distributed pair.
fstD :: (DT a, DT b) => Dist (a, b) -> Dist a

-- | Extract the second elements of a distributed pair.
sndD :: (DT a, DT b) => Dist (a, b) -> Dist b

-- | Combine two distributed values with the given function.
zipWithD :: (DT a, DT b, DT c) => What -> Gang -> (a -> b -> c) -> Dist a -> Dist b -> Dist c

-- | Combine two distributed values with the given function. The worker
--   function also gets the index of the current thread.
izipWithD :: (DT a, DT b, DT c) => What -> Gang -> (Int -> a -> b -> c) -> Dist a -> Dist b -> Dist c

-- | Fold all the instances of a distributed value.
foldD :: DT a => What -> Gang -> (a -> a -> a) -> Dist a -> a

-- | Prefix sum of the instances of a distributed value.
scanD :: DT a => What -> Gang -> (a -> a -> a) -> a -> Dist a -> (Dist a, a)

-- | Combination of map and fold.
mapAccumLD :: (DT a, DT b) => Gang -> (acc -> a -> (acc, b)) -> acc -> Dist a -> (acc, Dist b)


-- | Distribution of values of primitive types.
module Data.Array.Parallel.Unlifted.Distributed.Data.Scalar

-- | Class of distributable types. Instances of <a>DT</a> can be
--   distributed across all workers of a <a>Gang</a>. All such types must
--   be hyperstrict as we do not want to pass thunks into distributed
--   computations.
class DT a where data family Dist a data family MDist a :: * -> * deepSeqD = seq measureD _ = "None"
indexD :: DT a => String -> Dist a -> Int -> a
newMD :: DT a => Gang -> ST s (MDist a s)
readMD :: DT a => MDist a s -> Int -> ST s a
writeMD :: DT a => MDist a s -> Int -> a -> ST s ()
unsafeFreezeMD :: DT a => MDist a s -> ST s (Dist a)
deepSeqD :: DT a => a -> b -> b
sizeD :: DT a => Dist a -> Int
sizeMD :: DT a => MDist a s -> Int
measureD :: DT a => a -> String

-- | Distribute a scalar. Each thread gets its own copy of the same value.
--   Example: scalarD theGangN4 10 = [10, 10, 10, 10]
scalarD :: DT a => Gang -> a -> Dist a

-- | Sum all instances of a distributed number.
sumD :: (Num a, DT a) => Gang -> Dist a -> a
instance PprPhysical (Dist Int)


-- | Distribution of Vectors.
module Data.Array.Parallel.Unlifted.Distributed.Data.Vector

-- | Yield the distributed length of a distributed array.
lengthD :: Unbox a => Dist (Vector a) -> Dist Int
instance (Unbox a, Show a) => PprPhysical (Dist (Vector a))
instance Unbox a => DT (Vector a)


-- | Distribution of Segment Descriptors
module Data.Array.Parallel.Unlifted.Distributed.Data.USegd.DT
instance PprPhysical (Dist USegd)
instance DT USegd


-- | Distribution of Segment Descriptors
module Data.Array.Parallel.Unlifted.Distributed.Data.USegd.Base

-- | O(1). Construct a distributed segment descriptor
mkDUSegdD :: Dist (Vector Int) -> Dist (Vector Int) -> Dist Int -> Dist USegd

-- | O(1). Yield the overall number of segments.
lengthD :: Dist USegd -> Dist Int

-- | O(1). Yield the lengths of the individual segments.
takeLengthsD :: Dist USegd -> Dist (Vector Int)

-- | O(1). Yield the segment indices of a segment descriptor.
takeIndicesD :: Dist USegd -> Dist (Vector Int)

-- | O(1). Yield the number of data elements.
takeElementsD :: Dist USegd -> Dist Int


-- | Operations on distributed arrays.
module Data.Array.Parallel.Unlifted.Distributed.Arrays

-- | This is a phantom parameter used to record whether a distributed value
--   is balanced evenly among the threads. It's used to signal this
--   property between RULES, but the actual value is never used.
data Distribution
balanced :: Distribution
unbalanced :: Distribution

-- | Yield the distributed length of a distributed array.
lengthD :: Unbox a => Dist (Vector a) -> Dist Int

-- | O(threads). Distribute an array length over a <a>Gang</a>. Each thread
--   holds the number of elements it's reponsible for. If the array length
--   doesn't split evenly among the threads then the first threads get a
--   few more elements.
--   
--   <pre>
--   splitLenD theGangN4 511
--         = [128,128,128,127]
--   </pre>
splitLenD :: Gang -> Int -> Dist Int

-- | O(threads). Distribute an array length over a <a>Gang</a>. Each thread
--   holds the number of elements it's responsible for, and the index of
--   the start of its chunk.
--   
--   <pre>
--   splitLenIdxD theGangN4 511 
--         = [(128,0),(128,128),(128,256),(127,384)]
--   </pre>
splitLenIdxD :: Gang -> Int -> Dist (Int, Int)

-- | Distribute an array over a <a>Gang</a> such that each threads gets the
--   given number of elements.
--   
--   <pre>
--   splitAsD theGangN4 (splitLenD theGangN4 10) [1 2 3 4 5 6 7 8 9 0]
--         = [[1 2 3] [4 5 6] [7 8] [9 0]]
--   </pre>
splitAsD :: Unbox a => Gang -> Dist Int -> Vector a -> Dist (Vector a)

-- | Distribute an array over a <a>Gang</a>.
--   
--   NOTE: This is defined in terms of splitD_impl to avoid introducing
--   loops through RULES. Without it, splitJoinD would be a loop breaker.
splitD :: Unbox a => Gang -> Distribution -> Vector a -> Dist (Vector a)

-- | O(threads). Get the overall length of a distributed array. This is
--   implemented by reading the chunk length from each thread, and summing
--   them up.
joinLengthD :: Unbox a => Gang -> Dist (Vector a) -> Int

-- | Join a distributed array. Join sums up the array lengths of each
--   chunk, allocates a new result array, and copies each chunk into the
--   result.
--   
--   NOTE: This is defined in terms of joinD_impl to avoid introducing
--   loops through RULES. Without it, splitJoinD would be a loop breaker.
joinD :: Unbox a => Gang -> Distribution -> Dist (Vector a) -> Vector a

-- | Split a vector over a gang, run a distributed computation, then join
--   the pieces together again.
splitJoinD :: (Unbox a, Unbox b) => Gang -> (Dist (Vector a) -> Dist (Vector b)) -> Vector a -> Vector b

-- | Join a distributed array, yielding a mutable global array
joinDM :: Unbox a => Gang -> Dist (Vector a) -> ST s (MVector s a)

-- | Permute for distributed arrays.
permuteD :: Unbox a => Gang -> Dist (Vector a) -> Dist (Vector Int) -> Vector a
bpermuteD :: Unbox a => Gang -> Vector a -> Dist (Vector Int) -> Dist (Vector a)
atomicUpdateD :: Unbox a => Gang -> Dist (Vector a) -> Dist (Vector (Int, a)) -> Vector a

-- | Selectively combine the last elements of some chunks with the first
--   elements of others.
--   
--   NOTE: This runs sequentially and should only be used for testing
--   purposes.
--   
--   <pre>
--    pprp $ splitD theGang unbalanced $ fromList [80, 10, 20, 40, 50, 10 :: Int]
--    DVector lengths: [2,2,1,1]
--            chunks:  [[80,10],[20,40],[50],[10]]
--   
--   pprp $ fst 
--          $ carryD theGang (+) 0 
--             (mkDPrim $ fromList [True, False, True, False]) 
--             (splitD theGang unbalanced $ fromList [80, 10, 20, 40, 50, 10 :: Int])
--   
--   DVector lengths: [1,2,0,1]
--             chunks: [[80],[30,40],[],[60]]
--   </pre>
carryD :: (Unbox a, DT a) => Gang -> (a -> a -> a) -> a -> Dist Bool -> Dist (Vector a) -> (Dist (Vector a), a)


-- | Operations on Distributed Segment Descriptors
module Data.Array.Parallel.Unlifted.Distributed.Data.USegd.Split

-- | Split a segment descriptor across the gang, segment wise. Whole
--   segments are placed on each thread, and we try to balance out the
--   segments so each thread has the same number of array elements.
--   
--   We don't split segments across threads, as this would limit our
--   ability to perform intra-thread fusion of lifted operations. The down
--   side of this is that if we have few segments with an un-even size
--   distribution then large segments can cause the gang to become
--   unbalanced.
--   
--   In the following example the segment with size 100 dominates and
--   unbalances the gang. There is no reason to put any segments on the the
--   last thread because we need to wait for the first to finish anyway.
--   
--   <pre>
--    &gt; pprp $ splitSegdOnSegsD theGang
--               $ lengthsToUSegd $ fromList [100, 10, 20, 40, 50  :: Int]
--   
--   DUSegd lengths:   DVector lengths:  [ 1,    3,         1,  0]
--                                   chunks:  [[100],[10,20,40],[50],[]]
--   
--   indices:   DVector lengths:  [1,3,1,0]
--                                   chunks:  [[0],  [0,10,30], [0], []]
--   
--   elements:  DInt [100,70,50,0]
--   </pre>
--   
--   NOTE: This splitSegdOnSegsD function isn't currently used.
splitSegdOnSegsD :: Gang -> USegd -> Dist USegd

-- | Split a segment descriptor across the gang, element wise. We try to
--   put the same number of elements on each thread, which means that
--   segments are sometimes split across threads.
--   
--   Each thread gets a slice of segment descriptor, the segid of the first
--   slice, and the offset of the first slice in its segment.
--   
--   Example: In this picture each X represents 5 elements, and we have 5
--   segements in total.
--   
--   <pre>
--     segs:    ----------------------- --- ------- --------------- -------------------
--       elems:  |X X X X X X X X X|X X X X X X X X X|X X X X X X X X X|X X X X X X X X X|
--               |     thread1     |     thread2     |     thread3     |     thread4     |
--       segid:  0                 0                 3                 4
--       offset: 0                 45                0                 5
--   
--   pprp $ splitSegdOnElemsD theGang4
--             $ lengthsToUSegd $ fromList [60, 10, 20, 40, 50 :: Int]
--   
--   segd:    DUSegd lengths:  DVector lengths: [1,3,2,1]
--                                           chunks:  [[45],[15,10,20],[40,5],[45]]
--                        indices:  DVector lengths: [1,3,2,1]
--                                           chunks:  [[0], [0,15,25], [0,40],[0]]
--                       elements:  DInt [45,45,45,45]
--   
--   segids: DInt [0,0,3,4]     (segment id of first slice on thread)
--       offsets: DInt [0,45,0,5]    (offset of that slice in its segment)
--   </pre>
splitSegdOnElemsD :: Gang -> USegd -> Dist ((USegd, Int), Int)
splitSD :: Unbox a => Gang -> Dist USegd -> Vector a -> Dist (Vector a)

-- | time O(segs) Join a distributed segment descriptor into a global one.
--   This simply joins the distributed lengths and indices fields, but does
--   not reconstruct the original segment descriptor as it was before
--   splitting.
--   
--   <pre>
--    &gt; pprp $ joinSegdD theGang4 
--            $ fstD $ fstD $ splitSegdOnElemsD theGang
--            $ lengthsToUSegd $ fromList [60, 10, 20, 40, 50]
--   
--   USegd lengths:  [45,15,10,20,40,5,45]
--            indices:  [0,45,60,70,90,130,135]
--            elements: 180
--   </pre>
--   
--   TODO: sequential runtime is O(segs) due to application of
--   lengthsToUSegd
joinSegdD :: Gang -> Dist USegd -> USegd

-- | Glue a distributed segment descriptor back into the original global
--   one. Prop: glueSegdD gang $ splitSegdOnElems gang usegd = usegd
--   
--   NOTE: This is runs sequentially and should only be used for testing
--   purposes.
glueSegdD :: Gang -> Dist ((USegd, Int), Int) -> Dist USegd


-- | Distribution of Segment Descriptors
module Data.Array.Parallel.Unlifted.Distributed.Data.USegd

-- | O(1). Construct a distributed segment descriptor
mkDUSegdD :: Dist (Vector Int) -> Dist (Vector Int) -> Dist Int -> Dist USegd

-- | O(1). Yield the overall number of segments.
lengthD :: Dist USegd -> Dist Int

-- | O(1). Yield the lengths of the individual segments.
takeLengthsD :: Dist USegd -> Dist (Vector Int)

-- | O(1). Yield the segment indices of a segment descriptor.
takeIndicesD :: Dist USegd -> Dist (Vector Int)

-- | O(1). Yield the number of data elements.
takeElementsD :: Dist USegd -> Dist Int

-- | Split a segment descriptor across the gang, segment wise. Whole
--   segments are placed on each thread, and we try to balance out the
--   segments so each thread has the same number of array elements.
--   
--   We don't split segments across threads, as this would limit our
--   ability to perform intra-thread fusion of lifted operations. The down
--   side of this is that if we have few segments with an un-even size
--   distribution then large segments can cause the gang to become
--   unbalanced.
--   
--   In the following example the segment with size 100 dominates and
--   unbalances the gang. There is no reason to put any segments on the the
--   last thread because we need to wait for the first to finish anyway.
--   
--   <pre>
--    &gt; pprp $ splitSegdOnSegsD theGang
--               $ lengthsToUSegd $ fromList [100, 10, 20, 40, 50  :: Int]
--   
--   DUSegd lengths:   DVector lengths:  [ 1,    3,         1,  0]
--                                   chunks:  [[100],[10,20,40],[50],[]]
--   
--   indices:   DVector lengths:  [1,3,1,0]
--                                   chunks:  [[0],  [0,10,30], [0], []]
--   
--   elements:  DInt [100,70,50,0]
--   </pre>
--   
--   NOTE: This splitSegdOnSegsD function isn't currently used.
splitSegdOnSegsD :: Gang -> USegd -> Dist USegd

-- | Split a segment descriptor across the gang, element wise. We try to
--   put the same number of elements on each thread, which means that
--   segments are sometimes split across threads.
--   
--   Each thread gets a slice of segment descriptor, the segid of the first
--   slice, and the offset of the first slice in its segment.
--   
--   Example: In this picture each X represents 5 elements, and we have 5
--   segements in total.
--   
--   <pre>
--     segs:    ----------------------- --- ------- --------------- -------------------
--       elems:  |X X X X X X X X X|X X X X X X X X X|X X X X X X X X X|X X X X X X X X X|
--               |     thread1     |     thread2     |     thread3     |     thread4     |
--       segid:  0                 0                 3                 4
--       offset: 0                 45                0                 5
--   
--   pprp $ splitSegdOnElemsD theGang4
--             $ lengthsToUSegd $ fromList [60, 10, 20, 40, 50 :: Int]
--   
--   segd:    DUSegd lengths:  DVector lengths: [1,3,2,1]
--                                           chunks:  [[45],[15,10,20],[40,5],[45]]
--                        indices:  DVector lengths: [1,3,2,1]
--                                           chunks:  [[0], [0,15,25], [0,40],[0]]
--                       elements:  DInt [45,45,45,45]
--   
--   segids: DInt [0,0,3,4]     (segment id of first slice on thread)
--       offsets: DInt [0,45,0,5]    (offset of that slice in its segment)
--   </pre>
splitSegdOnElemsD :: Gang -> USegd -> Dist ((USegd, Int), Int)
splitSD :: Unbox a => Gang -> Dist USegd -> Vector a -> Dist (Vector a)

-- | time O(segs) Join a distributed segment descriptor into a global one.
--   This simply joins the distributed lengths and indices fields, but does
--   not reconstruct the original segment descriptor as it was before
--   splitting.
--   
--   <pre>
--    &gt; pprp $ joinSegdD theGang4 
--            $ fstD $ fstD $ splitSegdOnElemsD theGang
--            $ lengthsToUSegd $ fromList [60, 10, 20, 40, 50]
--   
--   USegd lengths:  [45,15,10,20,40,5,45]
--            indices:  [0,45,60,70,90,130,135]
--            elements: 180
--   </pre>
--   
--   TODO: sequential runtime is O(segs) due to application of
--   lengthsToUSegd
joinSegdD :: Gang -> Dist USegd -> USegd

-- | Glue a distributed segment descriptor back into the original global
--   one. Prop: glueSegdD gang $ splitSegdOnElems gang usegd = usegd
--   
--   NOTE: This is runs sequentially and should only be used for testing
--   purposes.
glueSegdD :: Gang -> Dist ((USegd, Int), Int) -> Dist USegd


-- | Distribution of Segment Descriptors
module Data.Array.Parallel.Unlifted.Distributed.Data.USSegd.DT
instance PprPhysical (Dist USSegd)
instance DT USSegd


-- | Distribution of Segment Descriptors
module Data.Array.Parallel.Unlifted.Distributed.Data.USSegd.Base

-- | O(1). Yield the overall number of segments.
lengthD :: Dist USSegd -> Dist Int

-- | O(1). Yield the lengths of the individual segments.
takeLengthsD :: Dist USSegd -> Dist (Vector Int)

-- | O(1). Yield the segment indices.
takeIndicesD :: Dist USSegd -> Dist (Vector Int)

-- | O(1). Yield the number of data elements.
takeElementsD :: Dist USSegd -> Dist Int

-- | O(1). Yield the starting indices.
takeStartsD :: Dist USSegd -> Dist (Vector Int)

-- | O(1). Yield the source ids
takeSourcesD :: Dist USSegd -> Dist (Vector Int)

-- | O(1). Yield the USegd
takeUSegdD :: Dist USSegd -> Dist USegd


-- | Operations on Distributed Segment Descriptors
module Data.Array.Parallel.Unlifted.Distributed.Data.USSegd.Split

-- | Split a segment descriptor across the gang, element wise. We try to
--   put the same number of elements on each thread, which means that
--   segments are sometimes split across threads.
--   
--   Each thread gets a slice of segment descriptor, the segid of the first
--   slice, and the offset of the first slice in its segment.
--   
--   Example: In this picture each X represents 5 elements, and we have 5
--   segements in total.
--   
--   <pre>
--      segs:    ----------------------- --- ------- --------------- -------------------
--       elems:  |X X X X X X X X X|X X X X X X X X X|X X X X X X X X X|X X X X X X X X X|
--               |     thread1     |     thread2     |     thread3     |     thread4     |
--       segid:  0                 0                 3                 4
--       offset: 0                 45                0                 5
--   
--   pprp $ splitSegdOnElemsD theGang 
--             $ lengthsToUSegd $ fromList [60, 10, 20, 40, 50 :: Int]
--   
--   segd:    DUSegd lengths:  DVector lengths: [1,3,2,1]
--                                           chunks:  [[45],[15,10,20],[40,5],[45]]
--                        indices:  DVector lengths: [1,3,2,1]
--                                           chunks:  [[0], [0,15,25], [0,40],[0]]
--                       elements:  DInt [45,45,45,45]
--   
--   segids: DInt [0,0,3,4]     (segment id of first slice on thread)
--       offsets: DInt [0,45,0,5]    (offset of that slice in its segment)
--   </pre>
splitSSegdOnElemsD :: Gang -> USSegd -> Dist ((USSegd, Int), Int)


-- | Distribution of Segment Descriptors
module Data.Array.Parallel.Unlifted.Distributed.Data.USSegd

-- | O(1). Yield the overall number of segments.
lengthD :: Dist USSegd -> Dist Int

-- | O(1). Yield the lengths of the individual segments.
takeLengthsD :: Dist USSegd -> Dist (Vector Int)

-- | O(1). Yield the segment indices.
takeIndicesD :: Dist USSegd -> Dist (Vector Int)

-- | O(1). Yield the number of data elements.
takeElementsD :: Dist USSegd -> Dist Int

-- | O(1). Yield the starting indices.
takeStartsD :: Dist USSegd -> Dist (Vector Int)

-- | O(1). Yield the source ids
takeSourcesD :: Dist USSegd -> Dist (Vector Int)

-- | O(1). Yield the USegd
takeUSegdD :: Dist USSegd -> Dist USegd

-- | Split a segment descriptor across the gang, element wise. We try to
--   put the same number of elements on each thread, which means that
--   segments are sometimes split across threads.
--   
--   Each thread gets a slice of segment descriptor, the segid of the first
--   slice, and the offset of the first slice in its segment.
--   
--   Example: In this picture each X represents 5 elements, and we have 5
--   segements in total.
--   
--   <pre>
--      segs:    ----------------------- --- ------- --------------- -------------------
--       elems:  |X X X X X X X X X|X X X X X X X X X|X X X X X X X X X|X X X X X X X X X|
--               |     thread1     |     thread2     |     thread3     |     thread4     |
--       segid:  0                 0                 3                 4
--       offset: 0                 45                0                 5
--   
--   pprp $ splitSegdOnElemsD theGang 
--             $ lengthsToUSegd $ fromList [60, 10, 20, 40, 50 :: Int]
--   
--   segd:    DUSegd lengths:  DVector lengths: [1,3,2,1]
--                                           chunks:  [[45],[15,10,20],[40,5],[45]]
--                        indices:  DVector lengths: [1,3,2,1]
--                                           chunks:  [[0], [0,15,25], [0,40],[0]]
--                       elements:  DInt [45,45,45,45]
--   
--   segids: DInt [0,0,3,4]     (segment id of first slice on thread)
--       offsets: DInt [0,45,0,5]    (offset of that slice in its segment)
--   </pre>
splitSSegdOnElemsD :: Gang -> USSegd -> Dist ((USSegd, Int), Int)


-- | Distribution of Virtual Segment Descriptors
module Data.Array.Parallel.Unlifted.Distributed.Data.UVSegd

-- | O(1). Yield the overall number of segments.
lengthD :: Dist UVSegd -> Dist Int

-- | O(1). Yield the lengths of the individual segments.
takeLengthsD :: Dist UVSegd -> Dist (Vector Int)

-- | O(1). Yield the segment indices.
takeIndicesD :: Dist UVSegd -> Dist (Vector Int)

-- | O(1). Yield the number of data elements.
takeElementsD :: Dist UVSegd -> Dist Int

-- | O(1). Yield the starting indices.
takeStartsD :: Dist UVSegd -> Dist (Vector Int)

-- | O(1). Yield the source ids
takeSourcesD :: Dist UVSegd -> Dist (Vector Int)

-- | O(1). Yield the vsegids
takeVSegidsD :: Dist UVSegd -> Dist (Vector Int)

-- | O(1). Yield the USSegd
takeUSSegdD :: Dist UVSegd -> Dist USSegd
instance PprPhysical (Dist UVSegd)
instance DT UVSegd


-- | Basic operations on distributed types.
module Data.Array.Parallel.Unlifted.Distributed.Basics

-- | Test whether to distributed values are equal. This requires a
--   <a>Gang</a> and hence can't be defined in terms of <a>Eq</a>.
eqD :: (Eq a, DT a) => Gang -> Dist a -> Dist a -> Bool

-- | Test whether to distributed values are not equal. This requires a
--   <a>Gang</a> and hence can't be defined in terms of <a>Eq</a>.
neqD :: (Eq a, DT a) => Gang -> Dist a -> Dist a -> Bool

-- | Generate a distributed value from the first <tt>p</tt> elements of a
--   list.
--   
--   <ul>
--   <li>For debugging only, don't use in production code.</li>
--   </ul>
toD :: DT a => Gang -> [a] -> Dist a

-- | Yield all elements of a distributed value.
--   
--   <ul>
--   <li>For debugging only, don't use in production code.</li>
--   </ul>
fromD :: DT a => Gang -> Dist a -> [a]


-- | Distributed types and operations.
--   
--   <ul>
--   <li>This is an internal API and shouldn't need to be used directly.
--   Client programs should use <a>Data.Array.Parallel.Unlifted</a></li>
--   </ul>
module Data.Array.Parallel.Unlifted.Distributed

-- | A <a>Gang</a> is a group of threads which execute arbitrary work
--   requests.
data Gang

-- | Fork a <a>Gang</a> with the given number of threads (at least 1).
forkGang :: Int -> IO Gang

-- | O(1). Yield the number of threads in the <a>Gang</a>.
gangSize :: Gang -> Int

-- | DPH programs use this single, shared gang of threads. The gang exists
--   at top level, and is initialised at program start.
--   
--   The vectoriser guarantees that the gang is only used by a single
--   computation at a time. This is true because the program produced by
--   the vector only uses flat parallelism, so parallel computations don't
--   invoke further parallel computations. If the vectorised program tries
--   to use nested parallelism then there is a bug in the vectoriser, and
--   the code will run sequentially.
theGang :: Gang

-- | Class of distributable types. Instances of <a>DT</a> can be
--   distributed across all workers of a <a>Gang</a>. All such types must
--   be hyperstrict as we do not want to pass thunks into distributed
--   computations.
class DT a where data family Dist a data family MDist a :: * -> * deepSeqD = seq measureD _ = "None"
indexD :: DT a => String -> Dist a -> Int -> a
newMD :: DT a => Gang -> ST s (MDist a s)
readMD :: DT a => MDist a s -> Int -> ST s a
writeMD :: DT a => MDist a s -> Int -> a -> ST s ()
unsafeFreezeMD :: DT a => MDist a s -> ST s (Dist a)
deepSeqD :: DT a => a -> b -> b
sizeD :: DT a => Dist a -> Int
sizeMD :: DT a => MDist a s -> Int
measureD :: DT a => a -> String

-- | Map a function to every instance of a distributed value.
--   
--   This applies the function to every thread, but not every value held by
--   the thread. If you want that then use something like:
--   
--   <pre>
--   mapD theGang (V.map (+ 1)) :: Dist (Vector Int) -&gt; Dist (Vector Int)
--   </pre>
mapD :: (DT a, DT b) => What -> Gang -> (a -> b) -> Dist a -> Dist b

-- | Combine two distributed values with the given function.
zipWithD :: (DT a, DT b, DT c) => What -> Gang -> (a -> b -> c) -> Dist a -> Dist b -> Dist c

-- | Fold all the instances of a distributed value.
foldD :: DT a => What -> Gang -> (a -> a -> a) -> Dist a -> a

-- | Prefix sum of the instances of a distributed value.
scanD :: DT a => What -> Gang -> (a -> a -> a) -> a -> Dist a -> (Dist a, a)

-- | Test whether to distributed values are equal. This requires a
--   <a>Gang</a> and hence can't be defined in terms of <a>Eq</a>.
eqD :: (Eq a, DT a) => Gang -> Dist a -> Dist a -> Bool

-- | Test whether to distributed values are not equal. This requires a
--   <a>Gang</a> and hence can't be defined in terms of <a>Eq</a>.
neqD :: (Eq a, DT a) => Gang -> Dist a -> Dist a -> Bool

-- | Distribute a scalar. Each thread gets its own copy of the same value.
--   Example: scalarD theGangN4 10 = [10, 10, 10, 10]
scalarD :: DT a => Gang -> a -> Dist a

-- | AND together all instances of a distributed <a>Bool</a>.
andD :: Gang -> Dist Bool -> Bool

-- | OR together all instances of a distributed <a>Bool</a>.
orD :: Gang -> Dist Bool -> Bool

-- | Sum all instances of a distributed number.
sumD :: (Num a, DT a) => Gang -> Dist a -> a

-- | Pairing of distributed values. The two values must belong to the same
--   <tt>Gang</tt>.
zipD :: (DT a, DT b) => Dist a -> Dist b -> Dist (a, b)

-- | Unpairing of distributed values.
unzipD :: (DT a, DT b) => Dist (a, b) -> (Dist a, Dist b)

-- | Extract the first elements of a distributed pair.
fstD :: (DT a, DT b) => Dist (a, b) -> Dist a

-- | Extract the second elements of a distributed pair.
sndD :: (DT a, DT b) => Dist (a, b) -> Dist b

-- | Yield the distributed length of a distributed array.
lengthD :: Unbox a => Dist (Vector a) -> Dist Int

-- | O(threads). Distribute an array length over a <a>Gang</a>. Each thread
--   holds the number of elements it's reponsible for. If the array length
--   doesn't split evenly among the threads then the first threads get a
--   few more elements.
--   
--   <pre>
--   splitLenD theGangN4 511
--         = [128,128,128,127]
--   </pre>
splitLenD :: Gang -> Int -> Dist Int

-- | O(threads). Distribute an array length over a <a>Gang</a>. Each thread
--   holds the number of elements it's responsible for, and the index of
--   the start of its chunk.
--   
--   <pre>
--   splitLenIdxD theGangN4 511 
--         = [(128,0),(128,128),(128,256),(127,384)]
--   </pre>
splitLenIdxD :: Gang -> Int -> Dist (Int, Int)

-- | Distribute an array over a <a>Gang</a>.
--   
--   NOTE: This is defined in terms of splitD_impl to avoid introducing
--   loops through RULES. Without it, splitJoinD would be a loop breaker.
splitD :: Unbox a => Gang -> Distribution -> Vector a -> Dist (Vector a)

-- | Distribute an array over a <a>Gang</a> such that each threads gets the
--   given number of elements.
--   
--   <pre>
--   splitAsD theGangN4 (splitLenD theGangN4 10) [1 2 3 4 5 6 7 8 9 0]
--         = [[1 2 3] [4 5 6] [7 8] [9 0]]
--   </pre>
splitAsD :: Unbox a => Gang -> Dist Int -> Vector a -> Dist (Vector a)

-- | O(threads). Get the overall length of a distributed array. This is
--   implemented by reading the chunk length from each thread, and summing
--   them up.
joinLengthD :: Unbox a => Gang -> Dist (Vector a) -> Int

-- | Join a distributed array. Join sums up the array lengths of each
--   chunk, allocates a new result array, and copies each chunk into the
--   result.
--   
--   NOTE: This is defined in terms of joinD_impl to avoid introducing
--   loops through RULES. Without it, splitJoinD would be a loop breaker.
joinD :: Unbox a => Gang -> Distribution -> Dist (Vector a) -> Vector a

-- | Split a vector over a gang, run a distributed computation, then join
--   the pieces together again.
splitJoinD :: (Unbox a, Unbox b) => Gang -> (Dist (Vector a) -> Dist (Vector b)) -> Vector a -> Vector b

-- | Join a distributed array, yielding a mutable global array
joinDM :: Unbox a => Gang -> Dist (Vector a) -> ST s (MVector s a)

-- | Selectively combine the last elements of some chunks with the first
--   elements of others.
--   
--   NOTE: This runs sequentially and should only be used for testing
--   purposes.
--   
--   <pre>
--    pprp $ splitD theGang unbalanced $ fromList [80, 10, 20, 40, 50, 10 :: Int]
--    DVector lengths: [2,2,1,1]
--            chunks:  [[80,10],[20,40],[50],[10]]
--   
--   pprp $ fst 
--          $ carryD theGang (+) 0 
--             (mkDPrim $ fromList [True, False, True, False]) 
--             (splitD theGang unbalanced $ fromList [80, 10, 20, 40, 50, 10 :: Int])
--   
--   DVector lengths: [1,2,0,1]
--             chunks: [[80],[30,40],[],[60]]
--   </pre>
carryD :: (Unbox a, DT a) => Gang -> (a -> a -> a) -> a -> Dist Bool -> Dist (Vector a) -> (Dist (Vector a), a)

-- | This is a phantom parameter used to record whether a distributed value
--   is balanced evenly among the threads. It's used to signal this
--   property between RULES, but the actual value is never used.
data Distribution
balanced :: Distribution
unbalanced :: Distribution

-- | Permute for distributed arrays.
permuteD :: Unbox a => Gang -> Dist (Vector a) -> Dist (Vector Int) -> Vector a
bpermuteD :: Unbox a => Gang -> Vector a -> Dist (Vector Int) -> Dist (Vector a)
atomicUpdateD :: Unbox a => Gang -> Dist (Vector a) -> Dist (Vector (Int, a)) -> Vector a

-- | Yield all elements of a distributed value.
--   
--   <ul>
--   <li>For debugging only, don't use in production code.</li>
--   </ul>
fromD :: DT a => Gang -> Dist a -> [a]

-- | Generate a distributed value from the first <tt>p</tt> elements of a
--   list.
--   
--   <ul>
--   <li>For debugging only, don't use in production code.</li>
--   </ul>
toD :: DT a => Gang -> [a] -> Dist a

-- | Show all members of a distributed value.
debugD :: DT a => Dist a -> String


-- | Parallel permutations for unlifted arrays
module Data.Array.Parallel.Unlifted.Parallel.Permute

-- | Backwards permutation.
bpermuteUP :: Unbox a => Vector a -> Vector Int -> Vector a

-- | Update elements in an array.
updateUP :: Unbox a => Vector a -> Vector (Int, a) -> Vector a


-- | Parallel selectors.
module Data.Array.Parallel.Unlifted.Parallel.UPSel

-- | Contains a selector <a>USel2</a>, as well as an <tt>USelRep2</tt>
--   which says how to distribute this selector across the PEs.
--   
--   See
--   <tt>dph-prim-seq:Data.Array.Parallel.Unlifted.Sequential.Segmented.USel</tt>
--   for more discussion of what selectors are for.
data UPSel2
type UPSelRep2 = Dist ((Int, Int), (Int, Int))

-- | O(1). Get the tags of a selector.
tagsUPSel2 :: UPSel2 -> Vector Tag

-- | O(1). Get the indices of a selector.
indicesUPSel2 :: UPSel2 -> Vector Int

-- | O(1). Get the number of elements that will be taken from the first
--   array.
elementsUPSel2_0 :: UPSel2 -> Int

-- | O(1). Get the number of elements that will be taken from the second
--   array.
elementsUPSel2_1 :: UPSel2 -> Int

-- | O(1). Take the sequential <a>USel2</a> from a <a>UPSel2</a>.
selUPSel2 :: UPSel2 -> USel2

-- | O(1). Take the <a>UPSelRep2</a> from a <a>UPSel2</a>.
repUPSel2 :: UPSel2 -> UPSelRep2

-- | O(1). Construct a selector. Wrapper for <a>UPSel2</a>.
mkUPSel2 :: Vector Tag -> Vector Int -> Int -> Int -> UPSelRep2 -> UPSel2

-- | Computes a <a>UPSelRep2</a> from an array of tags. This is used when
--   parallelising a <a>combine</a> operation. See the docs for
--   <a>UPSelRep2</a> for details.
mkUPSelRep2 :: Vector Tag -> UPSelRep2
indicesUPSelRep2 :: Vector Tag -> UPSelRep2 -> Vector Int

-- | O(n). Count the number of elements to take from the first array.
elementsUPSelRep2_0 :: Vector Tag -> UPSelRep2 -> Int

-- | O(n). Count the number of elements to take from the second array.
elementsUPSelRep2_1 :: Vector Tag -> UPSelRep2 -> Int


-- | Parallel combinators for unlifted arrays.
module Data.Array.Parallel.Unlifted.Parallel.Combinators

-- | Apply a worker to all elements of an array.
mapUP :: (Unbox a, Unbox b) => (a -> b) -> Vector a -> Vector b

-- | Keep elements that match the given predicate.
filterUP :: Unbox a => (a -> Bool) -> Vector a -> Vector a

-- | Take elements of an array where a flag value is true, and pack them
--   into the result.
--   
--   <ul>
--   <li>The souce and flag arrays must have the same length, but this is
--   not checked.</li>
--   </ul>
packUP :: Unbox e => Vector e -> Vector Bool -> Vector e

-- | Combine two vectors based on a selector. If the selector is true then
--   take the element from the first vector, otherwise take it from the
--   second.
--   
--   <ul>
--   <li>The data vectors must have enough elements to satisfy the flag
--   vector, but this is not checked.</li>
--   </ul>
combineUP :: Unbox a => Vector Bool -> Vector a -> Vector a -> Vector a

-- | Combine two vectors based on a selector.
--   
--   <ul>
--   <li>The data vectors must have enough elements to satisfy the
--   selector, but this is not checked.</li>
--   </ul>
combine2UP :: Unbox a => Vector Tag -> UPSelRep2 -> Vector a -> Vector a -> Vector a

-- | Apply a worker function to correponding elements of two arrays.
zipWithUP :: (Unbox a, Unbox b, Unbox c) => (a -> b -> c) -> Vector a -> Vector b -> Vector c

-- | Undirected fold. Note that this function has more constraints on its
--   parameters than the standard fold function from the Haskell Prelude.
--   
--   <ul>
--   <li>The worker function must be associative.</li>
--   <li>The provided starting element must be neutral with respect to the
--   worker. For example 0 is neutral wrt (+) and 1 is neutral wrt
--   (*).</li>
--   </ul>
--   
--   We need these constraints so that we can partition the fold across
--   several threads. Each thread folds a chunk of the input vector, then
--   we fold together all the results in the main thread.
foldUP :: (Unbox a, DT a) => (a -> a -> a) -> a -> Vector a -> a

-- | Left fold over an array.
--   
--   <ul>
--   <li>If the vector is empty then this returns the provided neural
--   element.</li>
--   <li>The worker function must be associative.</li>
--   <li>The provided starting element must be neutral with respect to the
--   worker, see <a>foldUP</a> for discussion.</li>
--   </ul>
foldlUP :: (DT a, Unbox a) => (a -> a -> a) -> a -> Vector a -> a

-- | Alias for <a>foldl1UP</a>
fold1UP :: (DT a, Unbox a) => (a -> a -> a) -> Vector a -> a

-- | Left fold over an array, using the first element of the vector as the
--   neural element.
--   
--   <ul>
--   <li>If the vector contains no elements then you'll get a bounds-check
--   error.</li>
--   <li>The worker function must be associative.</li>
--   <li>The provided starting element must be neutral with respect to the
--   worker, see <a>foldUP</a> for discussion.</li>
--   </ul>
foldl1UP :: (DT a, Unbox a) => (a -> a -> a) -> Vector a -> a

-- | Prefix scan. Similar to fold, but produce an array of the intermediate
--   states.
--   
--   <ul>
--   <li>The worker function must be associative.</li>
--   <li>The provided starting element must be neutral with respect to the
--   worker, see <a>foldUP</a> for discussion.</li>
--   </ul>
scanUP :: (DT a, Unbox a) => (a -> a -> a) -> a -> Vector a -> Vector a


-- | Enum-related parallel operations on unlifted arrays
module Data.Array.Parallel.Unlifted.Parallel.Enum
enumFromToUP :: (Unbox a, Enum a) => a -> a -> Vector a
enumFromThenToUP :: (Unbox a, Enum a) => a -> a -> a -> Vector a
enumFromStepLenUP :: Int -> Int -> Int -> Vector Int
enumFromStepLenEachUP :: Int -> Vector Int -> Vector Int -> Vector Int -> Vector Int


-- | Basic operations on parallel unlifted arrays.
module Data.Array.Parallel.Unlifted.Parallel.Basics

-- | O(1). Construct an empty array.
emptyUP :: Unbox e => Vector e

-- | Yield an array where all elements contain the same value
replicateUP :: Unbox e => Int -> e -> Vector e

-- | Repeat an array the given number of times.
repeatUP :: Unbox e => Int -> Vector e -> Vector e

-- | O(1). Take the length of an array.
lengthUP :: Unbox e => Vector e -> Int

-- | O(1). Test whether the given array is empty
nullUP :: Unbox e => Vector e -> Bool

-- | Interleave elements of two arrays
interleaveUP :: Unbox e => Vector e -> Vector e -> Vector e

-- | Associate each element of the array with its index
indexedUP :: (DT e, Unbox e) => Vector e -> Vector (Int, e)


-- | Parallel segment descriptors.
--   
--   See <a>Data.Array.Parallel.Unlifted</a> for how this works.
module Data.Array.Parallel.Unlifted.Parallel.UPSegd

-- | A parallel segment descriptor holds a global (undistributed) segment
--   desciptor, as well as a distributed version. The distributed version
--   describes how to split work on the segmented array over the gang.
data UPSegd
UPSegd :: !USegd -> Dist ((USegd, Int), Int) -> UPSegd

-- | Segment descriptor that describes the whole array.
upsegd_usegd :: UPSegd -> !USegd

-- | Segment descriptor for each chunk, along with segment id of first
--   slice in the chunk, and the offset of that slice in its segment. See
--   docs of <tt>splitSegdOfElemsD</tt> for an example.
upsegd_dsegd :: UPSegd -> Dist ((USegd, Int), Int)

-- | O(1). Check the internal consistency of a parallel segment descriptor.
valid :: UPSegd -> Bool

-- | O(1). Construct a new parallel segment descriptor.
mkUPSegd :: Vector Int -> Vector Int -> Int -> UPSegd

-- | Convert a global <a>USegd</a> to a parallel <a>UPSegd</a> by
--   distributing it across the gang.
fromUSegd :: USegd -> UPSegd

-- | O(1). Construct an empty segment descriptor, with no elements or
--   segments.
empty :: UPSegd

-- | O(1). Construct a singleton segment descriptor. The single segment
--   covers the given number of elements.
singleton :: Int -> UPSegd

-- | O(n). Convert an array of segment lengths into a parallel segment
--   descriptor.
--   
--   The array contains the length of each segment, and we compute the
--   indices from that. Runtime is O(n) in the number of segments.
fromLengths :: Vector Int -> UPSegd

-- | O(1). Yield the overall number of segments.
length :: UPSegd -> Int

-- | O(1). Yield the global <a>USegd</a> of a <a>UPSegd</a>.
takeUSegd :: UPSegd -> USegd

-- | O(1). Yield the distributed <a>USegd</a> of a <a>UPSegd</a>.
--   
--   We get a plain <a>USegd</a> for each chunk, the segment id of the
--   first slice in the chunk, and the starting offset of that slice in its
--   segment.
takeDistributed :: UPSegd -> Dist ((USegd, Int), Int)

-- | O(1). Yield the lengths of the individual segments.
takeLengths :: UPSegd -> Vector Int

-- | O(1). Yield the segment indices.
takeIndices :: UPSegd -> Vector Int

-- | O(1). Yield the total number of array elements.
--   
--   <pre>
--   takeElements upsegd = sum (takeLengths upsegd)
--   </pre>
takeElements :: UPSegd -> Int

-- | O(n). Yield a vector containing indicies that give the position of
--   each member of the flat array in its corresponding segment.
--   
--   <pre>
--   indicesP (fromLengths [5, 2, 3]) = [0,1,2,3,4,0,1,0,1,2]
--   </pre>
indicesP :: UPSegd -> Vector Int

-- | Copying segmented replication. Each element of the vector is
--   physically copied according to the length of each segment in the
--   segment descriptor.
--   
--   <pre>
--   replicateWith (fromLengths [3, 1, 2]) [5, 6, 7] = [5, 5, 5, 6, 7, 7]
--   </pre>
replicateWithP :: Unbox a => UPSegd -> Vector a -> Vector a

-- | Fold segments specified by a <a>UPSegd</a>.
foldWithP :: Unbox a => (a -> a -> a) -> a -> UPSegd -> Vector a -> Vector a

-- | Fold segments specified by a <a>UPSegd</a>, with a non-empty vector.
fold1WithP :: Unbox a => (a -> a -> a) -> UPSegd -> Vector a -> Vector a

-- | Sum up segments specified by a <a>UPSegd</a>.
sumWithP :: (Num e, Unbox e) => UPSegd -> Vector e -> Vector e

-- | Fold the segments specified by a <a>UPSegd</a>.
--   
--   This low level function takes a per-element worker and a per-segment
--   worker. It folds all the segments with the per-segment worker, then
--   uses the per-element worker to fixup the partial results when a
--   segment is split across multiple threads.
foldSegsWithP :: Unbox a => (a -> a -> a) -> (USegd -> Vector a -> Vector a) -> UPSegd -> Vector a -> Vector a
instance PprPhysical UPSegd


-- | Parallel Scattered Segment descriptors.
--   
--   See <a>Data.Array.Parallel.Unlifted</a> for how this works.
module Data.Array.Parallel.Unlifted.Parallel.UPSSegd

-- | Parallel Scattered Segment sescriptor
data UPSSegd

-- | O(1). Check the internal consistency of a scattered segment
--   descriptor.
valid :: UPSSegd -> Bool

-- | Construct a new segment descriptor.
mkUPSSegd :: Vector Int -> Vector Int -> UPSegd -> UPSSegd

-- | Promote a global <a>USSegd</a> to a parallel <a>UPSSegd</a> by
--   distributing it across the gang.
fromUSSegd :: USSegd -> UPSSegd

-- | Promote a plain <a>UPSegd</a> to a <a>UPSSegd</a>, by assuming that
--   all segments come from a single flat array with source id 0.
fromUPSegd :: UPSegd -> UPSSegd

-- | O(1). Yield an empty segment descriptor, with no elements or segments.
empty :: UPSSegd

-- | O(1). Yield a singleton segment descriptor. The single segment covers
--   the given number of elements.
singleton :: Int -> UPSSegd

-- | O(1). True when the starts are identical to the usegd indices field
--   and the sources are all 0's.
--   
--   In this case all the data elements are in one contiguous flat array,
--   and consumers can avoid looking at the real starts and sources fields.
isContiguous :: UPSSegd -> Bool

-- | O(1). Yield the overall number of segments.
length :: UPSSegd -> Int

-- | O(1). Yield the global <tt>USegd</tt> of a <a>UPSegd</a>
takeUSSegd :: UPSSegd -> USSegd

-- | O(1). Yield the distributed <tt>USegd</tt> of a <a>UPSegd</a>
takeDistributed :: UPSSegd -> Dist ((USSegd, Int), Int)

-- | O(1). Yield the lengths of the individual segments.
takeLengths :: UPSSegd -> Vector Int

-- | O(1). Yield the segment indices.
takeIndices :: UPSSegd -> Vector Int

-- | O(1). Yield the total number of data elements.
--   
--   <pre>
--   takeElements upssegd = sum (takeLengths upssegd)
--   </pre>
takeElements :: UPSSegd -> Int

-- | O(1). Yield the starting indices.
takeStarts :: UPSSegd -> Vector Int

-- | O(1). Yield the source ids.
takeSources :: UPSSegd -> Vector Int

-- | O(1). Get the length, segment index, starting index, and source id of
--   a segment.
getSeg :: UPSSegd -> Int -> (Int, Int, Int, Int)

-- | O(n) Produce a segment descriptor that describes the result of
--   appending two segmented arrays.
--   
--   Appending two nested arrays is an index space transformation. Because
--   a <a>UPSSegd</a> can contain segments from multiple flat data arrays,
--   we can represent the result of the append without copying elements
--   from the underlying flat data arrays.
appendWith :: UPSSegd -> Int -> UPSSegd -> Int -> UPSSegd

-- | Fold segments specified by a <a>UPSSegd</a>.
foldWithP :: (Unbox a, Unboxes a) => (a -> a -> a) -> a -> UPSSegd -> Vectors a -> Vector a

-- | Fold segments specified by a <a>UPSSegd</a>, with a non-empty vector.
fold1WithP :: (Unbox a, Unboxes a) => (a -> a -> a) -> UPSSegd -> Vectors a -> Vector a

-- | Sum up segments specified by a <a>UPSSegd</a>.
sumWithP :: (Num a, Unbox a, Unboxes a) => UPSSegd -> Vectors a -> Vector a

-- | Fold the segments specified by a <a>UPSSegd</a>.
--   
--   Low level function takes a per-element worker and a per-segment
--   worker. It folds all the segments with the per-segment worker, then
--   uses the per-element worker to fixup the partial results when a
--   segment is split across multiple threads.
foldSegsWithP :: (Unbox a, Unboxes a) => (a -> a -> a) -> (USSegd -> Vectors a -> Vector a) -> UPSSegd -> Vectors a -> Vector a
instance Show UPSSegd
instance PprPhysical UPSSegd


-- | Parallel virtual segment descriptors.
--   
--   See <a>Data.Array.Parallel.Unlifted</a> for how this works.
module Data.Array.Parallel.Unlifted.Parallel.UPVSegd

-- | Parallel Virtual Segment descriptor.
data UPVSegd

-- | O(1). Check the internal consistency of a virutal segmentation
--   descriptor.
valid :: UPVSegd -> Bool

-- | O(1). Construct a new virtual segment descriptor.
mkUPVSegd :: Vector Int -> UPSSegd -> UPVSegd

-- | O(segs). Promote a <a>UPSegd</a> to a <a>UPVSegd</a>. All segments are
--   assumed to come from a flat array with sourceid 0. The result contains
--   one virtual segment for every physical segment the provided
--   <a>UPSegd</a>.
fromUPSegd :: UPSegd -> UPVSegd

-- | O(segs). Promote a <a>UPSSegd</a> to a <a>UPVSegd</a>. The result
--   contains one virtual segment for every physical segment defined by the
--   <a>UPSSegd</a>.
fromUPSSegd :: UPSSegd -> UPVSegd

-- | O(1). Construct an empty segment descriptor, with no elements or
--   segments.
empty :: UPVSegd

-- | O(1). Construct a singleton segment descriptor. The single segment
--   covers the given number of elements in a flat array with sourceid 0.
singleton :: Int -> UPVSegd

-- | O(1). Construct a <a>UPVSegd</a> that describes an array created by
--   replicating a single segment several times.
replicated :: Int -> Int -> UPVSegd

-- | O(1). Checks whether all the segments are manifest (unshared /
--   non-virtual). If this is the case, then the vsegids field will be
--   [0..len-1].
--   
--   Consumers can check this field, avoid demanding the vsegids field.
--   This can avoid the need for it to be constructed in the first place,
--   due to lazy evaluation.
isManifest :: UPVSegd -> Bool

-- | O(1). True when the starts are identical to the usegd indices field
--   and the sources are all 0's.
--   
--   In this case all the data elements are in one contiguous flat array,
--   and consumers can avoid looking at the real starts and sources fields.
isContiguous :: UPVSegd -> Bool

-- | O(1). Yield the overall number of segments.
length :: UPVSegd -> Int

-- | O(1). Yield the virtual segment ids of <a>UPVSegd</a>.
takeVSegids :: UPVSegd -> Vector Int

-- | O(1). Take the vsegids of a <a>UPVSegd</a>, but don't require that
--   every physical segment is referenced by some virtual segment.
--   
--   If you're just performing indexing and don't need the invariant that
--   all physical segments are reachable from some virtual segment, then
--   use this version as it's faster. This sidesteps the code that
--   maintains the invariant.
--   
--   The stated O(1) complexity assumes that the array has already been
--   fully evalauted. If this is not the case then we can avoid demanding
--   the result of a prior computation on the vsegids, thus reducing the
--   cost attributed to that prior computation.
takeVSegidsRedundant :: UPVSegd -> Vector Int

-- | O(1). Yield the <a>UPSSegd</a> of <a>UPVSegd</a>.
takeUPSSegd :: UPVSegd -> UPSSegd

-- | O(1). Take the <a>UPSSegd</a> of a <a>UPVSegd</a>, but don't require
--   that every physical segment is referenced by some virtual segment.
--   
--   See the note in <a>takeVSegidsRedundant</a>.
takeUPSSegdRedundant :: UPVSegd -> UPSSegd

-- | O(1) or O(segs). Yield <a>USegd</a>s distributed over a logical view
--   of this <a>UPVSegd</a>. The complexity is only O(1) if this has
--   already been evaluated.
takeDistributed :: UPVSegd -> Dist ((USegd, Int), Int)

-- | O(segs). Yield the lengths of the segments described by a
--   <a>UPVSegd</a>.
takeLengths :: UPVSegd -> Vector Int

-- | O(1). Get the length, starting index, and source id of a segment.
getSeg :: UPVSegd -> Int -> (Int, Int, Int)

-- | O(segs). Yield a <a>UPSSegd</a> that describes each segment of a
--   <a>UPVSegd</a> individually.
--   
--   By doing this we lose information about which virtual segments
--   correspond to the same physical segments.
--   
--   <i>WARNING</i>: Trying to take the <a>UPSegd</a> of a nested array
--   that has been constructed with replication can cause index space
--   overflow. This is because the virtual size of the corresponding flat
--   data can be larger than physical memory. If this happens then indices
--   fields and element count in the result will be invalid.
unsafeDemoteToUPSSegd :: UPVSegd -> UPSSegd

-- | O(segs). Yield a <a>UPSegd</a> that describes each segment of a
--   <a>UPVSegd</a> individually, assuming all segments have been
--   concatenated to remove scattering.
--   
--   <ul>
--   <li>See the warning in <a>unsafeDemoteToUPSSegd</a>.</li>
--   </ul>
unsafeDemoteToUPSegd :: UPVSegd -> UPSegd

-- | Update the vsegids of a <a>UPVSegd</a>, and then cull the physical
--   segment descriptor so that all physical segments are reachable from
--   some virtual segment.
--   
--   This function lets you perform filtering operations on the virtual
--   segments, while maintaining the invariant that all physical segments
--   are referenced by some virtual segment.
updateVSegs :: (Vector Int -> Vector Int) -> UPVSegd -> UPVSegd

-- | Update the vsegids of <a>UPVSegd</a>, where the result is guaranteed
--   to cover all physical segments.
--   
--   Using this version saves performing the <tt>cull</tt> operation which
--   discards unreachable physical segments.
--   
--   <ul>
--   <li>The resulting vsegids must cover all physical segments. If they do
--   not then there will be physical segments that are not reachable from
--   some virtual segment, and subsequent operations like segmented fold
--   will have the wrong work complexity.</li>
--   </ul>
updateVSegsReachable :: (Vector Int -> Vector Int) -> UPVSegd -> UPVSegd

-- | Produce a segment descriptor that describes the result of appending
--   two arrays.
appendWith :: UPVSegd -> Int -> UPVSegd -> Int -> UPVSegd

-- | Combine two virtual segment descriptors.
combine2 :: UPSel2 -> UPVSegd -> Int -> UPVSegd -> Int -> UPVSegd
instance Show UPVSegd
instance PprPhysical UPVSegd


-- | Parallel combinators for segmented unboxed arrays
module Data.Array.Parallel.Unlifted.Parallel.Extracts

-- | Lookup elements from a <a>Vector</a>.
--   
--   TODO: make this parallel.
indexsFromVector :: Unbox a => Vector a -> Vector Int -> Vector a

-- | Lookup elements from some <a>Vectors</a> through a <a>UPVSegd</a>.
--   
--   TODO: make this parallel.
indexsFromVectorsUPVSegdP :: (Unbox a, Unboxes a) => Vectors a -> UPVSegd -> Vector (Int, Int) -> Vector a

-- | Lookup elements from some Vectors through a <a>UPVSegd</a>
indexsFromVectorsUPVSegd :: (Unbox a, Unboxes a) => Vectors a -> UPVSegd -> Vector (Int, Int) -> Vector a

-- | Copy segments from a nested vectors and concatenate them into a new
--   array.
extractsFromNestedUPSSegd :: Unbox a => UPSSegd -> Vector (Vector a) -> Vector a

-- | TODO: make this parallel.
extractsFromVectorsUPSSegd :: (Unbox a, Unboxes a) => UPSSegd -> Vectors a -> Vector a

-- | Parallel extracts from UPVSegd and Segmap TODO: This just distributes
--   the segmap over the gang, and will be unbalanced if there aren't many
--   segments, or they have varying sizes.
extractsFromVectorsUPVSegdP :: (Unbox a, Unboxes a) => UPVSegd -> Vectors a -> Vector a

-- | Sequential extracts from UPVSegd.
extractsFromVectorsUPVSegd :: (Unbox a, Unboxes a) => UPVSegd -> Vectors a -> Vector a

-- | Sequential extracts from USSegd and Segmap
extractsFromVectorsUPSSegdSegmap :: (Unbox a, Unboxes a) => UPSSegd -> Vectors a -> Vector Int -> Vector a


-- | Parallel combinators for segmented unboxed arrays
module Data.Array.Parallel.Unlifted.Parallel.Segmented

-- | Segmented replication. Each element in the vector is replicated the
--   given number of times.
--   
--   <pre>
--   replicateRSUP 2 [1, 2, 3, 4, 5] = [1, 1, 2, 2, 3, 3, 4, 4, 5, 5]
--   </pre>
replicateRSUP :: Unbox a => Int -> Vector a -> Vector a

-- | Segmented append.
appendSUP :: Unbox a => UPSegd -> UPSegd -> Vector a -> UPSegd -> Vector a -> Vector a

-- | Segmented append. -old
appendSUP_old :: Unbox a => UPSegd -> UPSegd -> Vector a -> UPSegd -> Vector a -> Vector a
appendSUPV :: (Unboxes a, Unbox a) => UPSegd -> UPVSegd -> Vectors a -> UPVSegd -> Vectors a -> Vector a

-- | Regular segmented fold.
foldRUP :: (Unbox a, Unbox b) => (b -> a -> b) -> b -> Int -> Vector a -> Vector b

-- | Regular segmented sum.
sumRUP :: (Num e, Unbox e) => Int -> Vector e -> Vector e


-- | Read/Show instances for segmented unlifted arrays.
module Data.Array.Parallel.Unlifted.Parallel.Text
instance Show UPSegd


-- | Sum-like parallel combinators for unlifted arrays
module Data.Array.Parallel.Unlifted.Parallel.Sums

-- | Compute the logical AND of all the elements in a array.
andUP :: Vector Bool -> Bool

-- | Compute the logical OR of all the elements in a array.
orUP :: Vector Bool -> Bool

-- | Check whether all the elements in a array meet the given predicate.
allUP :: Unbox e => (e -> Bool) -> Vector e -> Bool

-- | Check whether any of the elements in a array meet the given predicate.
anyUP :: Unbox e => (e -> Bool) -> Vector e -> Bool

-- | Compute the sum all the elements of a array.
sumUP :: (Unbox a, DT a, Num a) => Vector a -> a

-- | Compute the product of all the elements of an array.
productUP :: (DT e, Num e, Unbox e) => Vector e -> e

-- | Determine the maximum element in an array.
maximumUP :: (DT e, Ord e, Unbox e) => Vector e -> e

-- | Determine the maximum element in an array under the given ordering
maximumByUP :: (DT e, Unbox e) => (e -> e -> Ordering) -> Vector e -> e

-- | Determine the index of the maximum element in an array under the given
--   ordering
maximumIndexByUP :: (DT e, Unbox e) => (e -> e -> Ordering) -> Vector e -> Int


-- | Parallel operations on unlifted arrays
--   
--   <ul>
--   <li>This is an internal API and shouldn't need to be used directly.
--   Client programs should use <a>Data.Array.Parallel.Unlifted</a></li>
--   </ul>
module Data.Array.Parallel.Unlifted.Parallel

-- | O(1). Take the length of an array.
lengthUP :: Unbox e => Vector e -> Int

-- | O(1). Test whether the given array is empty
nullUP :: Unbox e => Vector e -> Bool

-- | O(1). Construct an empty array.
emptyUP :: Unbox e => Vector e

-- | Associate each element of the array with its index
indexedUP :: (DT e, Unbox e) => Vector e -> Vector (Int, e)

-- | Yield an array where all elements contain the same value
replicateUP :: Unbox e => Int -> e -> Vector e

-- | Repeat an array the given number of times.
repeatUP :: Unbox e => Int -> Vector e -> Vector e

-- | Interleave elements of two arrays
interleaveUP :: Unbox e => Vector e -> Vector e -> Vector e

-- | Apply a worker to all elements of an array.
mapUP :: (Unbox a, Unbox b) => (a -> b) -> Vector a -> Vector b

-- | Keep elements that match the given predicate.
filterUP :: Unbox a => (a -> Bool) -> Vector a -> Vector a

-- | Take elements of an array where a flag value is true, and pack them
--   into the result.
--   
--   <ul>
--   <li>The souce and flag arrays must have the same length, but this is
--   not checked.</li>
--   </ul>
packUP :: Unbox e => Vector e -> Vector Bool -> Vector e

-- | Combine two vectors based on a selector. If the selector is true then
--   take the element from the first vector, otherwise take it from the
--   second.
--   
--   <ul>
--   <li>The data vectors must have enough elements to satisfy the flag
--   vector, but this is not checked.</li>
--   </ul>
combineUP :: Unbox a => Vector Bool -> Vector a -> Vector a -> Vector a

-- | Combine two vectors based on a selector.
--   
--   <ul>
--   <li>The data vectors must have enough elements to satisfy the
--   selector, but this is not checked.</li>
--   </ul>
combine2UP :: Unbox a => Vector Tag -> UPSelRep2 -> Vector a -> Vector a -> Vector a

-- | Apply a worker function to correponding elements of two arrays.
zipWithUP :: (Unbox a, Unbox b, Unbox c) => (a -> b -> c) -> Vector a -> Vector b -> Vector c

-- | Undirected fold. Note that this function has more constraints on its
--   parameters than the standard fold function from the Haskell Prelude.
--   
--   <ul>
--   <li>The worker function must be associative.</li>
--   <li>The provided starting element must be neutral with respect to the
--   worker. For example 0 is neutral wrt (+) and 1 is neutral wrt
--   (*).</li>
--   </ul>
--   
--   We need these constraints so that we can partition the fold across
--   several threads. Each thread folds a chunk of the input vector, then
--   we fold together all the results in the main thread.
foldUP :: (Unbox a, DT a) => (a -> a -> a) -> a -> Vector a -> a

-- | Alias for <a>foldl1UP</a>
fold1UP :: (DT a, Unbox a) => (a -> a -> a) -> Vector a -> a

-- | Left fold over an array.
--   
--   <ul>
--   <li>If the vector is empty then this returns the provided neural
--   element.</li>
--   <li>The worker function must be associative.</li>
--   <li>The provided starting element must be neutral with respect to the
--   worker, see <a>foldUP</a> for discussion.</li>
--   </ul>
foldlUP :: (DT a, Unbox a) => (a -> a -> a) -> a -> Vector a -> a

-- | Left fold over an array, using the first element of the vector as the
--   neural element.
--   
--   <ul>
--   <li>If the vector contains no elements then you'll get a bounds-check
--   error.</li>
--   <li>The worker function must be associative.</li>
--   <li>The provided starting element must be neutral with respect to the
--   worker, see <a>foldUP</a> for discussion.</li>
--   </ul>
foldl1UP :: (DT a, Unbox a) => (a -> a -> a) -> Vector a -> a

-- | Prefix scan. Similar to fold, but produce an array of the intermediate
--   states.
--   
--   <ul>
--   <li>The worker function must be associative.</li>
--   <li>The provided starting element must be neutral with respect to the
--   worker, see <a>foldUP</a> for discussion.</li>
--   </ul>
scanUP :: (DT a, Unbox a) => (a -> a -> a) -> a -> Vector a -> Vector a
enumFromToUP :: (Unbox a, Enum a) => a -> a -> Vector a
enumFromThenToUP :: (Unbox a, Enum a) => a -> a -> a -> Vector a
enumFromStepLenUP :: Int -> Int -> Int -> Vector Int
enumFromStepLenEachUP :: Int -> Vector Int -> Vector Int -> Vector Int -> Vector Int

-- | Backwards permutation.
bpermuteUP :: Unbox a => Vector a -> Vector Int -> Vector a

-- | Update elements in an array.
updateUP :: Unbox a => Vector a -> Vector (Int, a) -> Vector a

-- | Segmented replication. Each element in the vector is replicated the
--   given number of times.
--   
--   <pre>
--   replicateRSUP 2 [1, 2, 3, 4, 5] = [1, 1, 2, 2, 3, 3, 4, 4, 5, 5]
--   </pre>
replicateRSUP :: Unbox a => Int -> Vector a -> Vector a

-- | Segmented append.
appendSUP :: Unbox a => UPSegd -> UPSegd -> Vector a -> UPSegd -> Vector a -> Vector a
appendSUPV :: (Unboxes a, Unbox a) => UPSegd -> UPVSegd -> Vectors a -> UPVSegd -> Vectors a -> Vector a

-- | Regular segmented fold.
foldRUP :: (Unbox a, Unbox b) => (b -> a -> b) -> b -> Int -> Vector a -> Vector b

-- | Regular segmented sum.
sumRUP :: (Num e, Unbox e) => Int -> Vector e -> Vector e

-- | Lookup elements from a <a>Vector</a>.
--   
--   TODO: make this parallel.
indexsFromVector :: Unbox a => Vector a -> Vector Int -> Vector a

-- | Lookup elements from some Vectors through a <a>UPVSegd</a>
indexsFromVectorsUPVSegd :: (Unbox a, Unboxes a) => Vectors a -> UPVSegd -> Vector (Int, Int) -> Vector a

-- | Lookup elements from some <a>Vectors</a> through a <a>UPVSegd</a>.
--   
--   TODO: make this parallel.
indexsFromVectorsUPVSegdP :: (Unbox a, Unboxes a) => Vectors a -> UPVSegd -> Vector (Int, Int) -> Vector a

-- | Copy segments from a nested vectors and concatenate them into a new
--   array.
extractsFromNestedUPSSegd :: Unbox a => UPSSegd -> Vector (Vector a) -> Vector a

-- | TODO: make this parallel.
extractsFromVectorsUPSSegd :: (Unbox a, Unboxes a) => UPSSegd -> Vectors a -> Vector a

-- | Sequential extracts from UPVSegd.
extractsFromVectorsUPVSegd :: (Unbox a, Unboxes a) => UPVSegd -> Vectors a -> Vector a

-- | Parallel extracts from UPVSegd and Segmap TODO: This just distributes
--   the segmap over the gang, and will be unbalanced if there aren't many
--   segments, or they have varying sizes.
extractsFromVectorsUPVSegdP :: (Unbox a, Unboxes a) => UPVSegd -> Vectors a -> Vector a

-- | Drop a the element at the provided index from a vector.
dropUP :: Unbox e => Int -> Vector e -> Vector e

-- | Compute the logical AND of all the elements in a array.
andUP :: Vector Bool -> Bool

-- | Compute the logical OR of all the elements in a array.
orUP :: Vector Bool -> Bool

-- | Check whether all the elements in a array meet the given predicate.
allUP :: Unbox e => (e -> Bool) -> Vector e -> Bool

-- | Check whether any of the elements in a array meet the given predicate.
anyUP :: Unbox e => (e -> Bool) -> Vector e -> Bool

-- | Compute the sum all the elements of a array.
sumUP :: (Unbox a, DT a, Num a) => Vector a -> a

-- | Compute the product of all the elements of an array.
productUP :: (DT e, Num e, Unbox e) => Vector e -> e

-- | Determine the maximum element in an array.
maximumUP :: (DT e, Ord e, Unbox e) => Vector e -> e

-- | Determine the maximum element in an array under the given ordering
maximumByUP :: (DT e, Unbox e) => (e -> e -> Ordering) -> Vector e -> e

-- | Determine the index of the maximum element in an array under the given
--   ordering
maximumIndexByUP :: (DT e, Unbox e) => (e -> e -> Ordering) -> Vector e -> Int


-- | Parallel implementation of the segmented array API defined in
--   <tt>dph-prim-interface</tt>.
--   
--   Some of them don't yet have parallel implementations, so we fall back
--   to the sequential ones from <tt>dph-prim-seq</tt>.
--   
--   <i>WARNING:</i> Although this library is intended to be used as a
--   target for the DPH vectoriser, it is also fine to use it directly from
--   non DPH programs. However, this library does not support nested
--   parallelism by itself. If you try to run further parallel computations
--   in the workers passed to <a>map</a>, <a>zipWith</a>, <a>fold</a> etc,
--   then they will just run sequentially.
module Data.Array.Parallel.Unlifted
class (Unbox a, DT a) => Elt a

-- | Arrays are stored as unboxed vectors. They have bulk-strict semantics,
--   so demanding one element demands them all.
type Array = Vector

-- | O(1). Construct an array with no elements.
empty :: Elt a => Array a

-- | Generate a new array given its length and a function to compute each
--   element.
generate :: Elt a => Int -> (Int -> a) -> Array a

-- | O(length result). Construct a new array by replicating a single
--   element the given number of times.
replicate :: Elt a => Int -> a -> Array a

-- | O(length result). Segmented replicate.
--   
--   Elements of the array are replicated according to the lengths of the
--   segments defined by the <a>Segd</a>.
replicate_s :: Elt a => Segd -> Array a -> Array a

-- | O(length result). Regular segmented replicate.
--   
--   Like <a>replicate_s</a>, but all segments are assumed to have the
--   given length.
replicate_rs :: Elt a => Int -> Array a -> Array a

-- | O(length result). Construct an array by copying a portion of another
--   array.
repeat :: Elt a => Int -> Int -> Array a -> Array a

-- | O(length result). Tag each element of an array with its index.
--   
--   <pre>
--   indexed [42, 93, 13] = [(0, 42), (1, 93), (2, 13)]
--   </pre>
indexed :: Elt a => Array a -> Array (Int, a)

-- | O(length result). Append two arrays.
(+:+) :: Elt a => Array a -> Array a -> Array a

-- | O(length result). Segmented append.
append_s :: Elt a => Segd -> Segd -> Array a -> Segd -> Array a -> Array a
append_vs :: (Elt a, Elts a) => Segd -> VSegd -> Arrays a -> VSegd -> Arrays a -> Array a

-- | O(length result). Segmented indices.
--   
--   Construct an array containing containing the segments defined by the
--   given <a>Segd</a>.
--   
--   Each segment will contain the elements <tt>[0..len-1]</tt> where
--   <tt>len</tt> is the length of that segment.
indices_s :: Segd -> Array Int
enumFromTo :: Int -> Int -> Array Int
enumFromThenTo :: Int -> Int -> Int -> Array Int
enumFromStepLen :: Int -> Int -> Int -> Array Int
enumFromStepLenEach :: Int -> Array Int -> Array Int -> Array Int -> Array Int

-- | O(1). Yield the number of elements in an array.
length :: Elt a => Array a -> Int

-- | O(1). Retrieve a numbered element from an array.
--   
--   The first argument gives a source-code location for out-of-bounds
--   errors.
index :: Elt a => String -> Array a -> Int -> a

-- | O(length result). Scattered indexing from a single <a>Array</a>.
--   
--   This is an alias for <a>bpermute</a>.
indexs :: Elt a => Array a -> Array Int -> Array a

-- | O(length result). Scattered indexing through a <a>VSegd</a>.
--   
--   The index array contains pairs of segment id and the index within that
--   segment.
--   
--   We use the <a>VSegd</a> to map the pairs to 2D indices within the
--   <a>Arrays</a>, and return an array of the resulting elements.
indexs_avs :: (Elt a, Elts a) => Arrays a -> VSegd -> Array (Int, Int) -> Array a

-- | O(length result). Extract a subrange of elements from an array.
--   
--   <pre>
--   extract [23, 42, 93, 50, 27] 1 3  = [42, 93, 50]
--   </pre>
extract :: Elt a => Array a -> Int -> Int -> Array a

-- | O(length result). Extract segments defined by a <a>SSegd</a> from a
--   vector of arrays.
--   
--   NOTE: This is a transitory interface, and will be removed in future
--   versions. Use <a>extracts_ass</a> instead.
extracts_nss :: Elt a => SSegd -> Vector (Array a) -> Array a

-- | O(length result). Extract segments defined by a <a>SSegd</a>.
--   
--   Extract all the segments defined by the <a>SSegd</a> from the
--   <a>Arrays</a>, returning them concatenated in a fresh <a>Array</a>.
extracts_ass :: (Elt a, Elts a) => SSegd -> Arrays a -> Array a

-- | O(length result). Extract segments defined by a <a>VSegd</a>.
--   
--   Extract all the segments defined by the <a>VSegd</a> from the
--   <a>Arrays</a>, returning them concatenated in a fresh <a>Array</a>.
extracts_avs :: (Elt a, Elts a) => VSegd -> Arrays a -> Array a

-- | O(length result). Drop elements from the front of an array, returning
--   the latter portion.
drop :: Elt a => Int -> Array a -> Array a

-- | O(length result). Copy the source array while replacing some elements
--   by new ones in the result.
update :: Elt a => Array a -> Array (Int, a) -> Array a

-- | O(length result). Forwards permutation of array elements.
permute :: Elt a => Array a -> Array Int -> Array a

-- | O(length result). Backwards permutation of array elements.
--   
--   <pre>
--   bpermute [50, 60, 20, 30] [0, 3, 2] = [50, 30, 20]
--   </pre>
bpermute :: Elt a => Array a -> Array Int -> Array a

-- | Combination of map and bpermute.
--   
--   The advantage of using this combined version is that we don't need to
--   apply the parameter function to source elements that don't appear in
--   the result.
mbpermute :: (Elt a, Elt b) => (a -> b) -> Array a -> Array Int -> Array b

-- | Default backwards permutation.
--   
--   The values of the index-value pairs are written into the position in
--   the result array that is indicated by the corresponding index.
--   
--   All positions not covered by the index-value pairs will have the value
--   determined by the initialiser function for that index position.
bpermuteDft :: Elt e => Int -> (Int -> e) -> Array (Int, e) -> Array e

-- | O(1). Zip two arrays into an array of pairs. If one array is short,
--   excess elements of the longer array are discarded.
zip :: (Elt a, Elt b) => Array a -> Array b -> Array (a, b)

-- | O(1). Zip three arrays into an array of triples. If one array is
--   short, excess elements of the longer arrays are discarded.
zip3 :: (Elt a, Elt b, Elt c) => Array a -> Array b -> Array c -> Array (a, b, c)

-- | O(1). Unzip an array of pairs into a pair of arrays.
unzip :: (Elt a, Elt b) => Array (a, b) -> (Array a, Array b)

-- | O(1). Unzip an array of triples into a triple of arrays.
unzip3 :: (Elt a, Elt b, Elt c) => Array (a, b, c) -> (Array a, Array b, Array c)

-- | O(1). Take the first elements of an array of pairs.
fsts :: (Elt a, Elt b) => Array (a, b) -> Array a

-- | O(1). Take the second elements of an array of pairs.
snds :: (Elt a, Elt b) => Array (a, b) -> Array b

-- | Apply a worker function to each element of an array, yielding a new
--   array.
map :: (Elt a, Elt b) => (a -> b) -> Array a -> Array b

-- | Apply a worker function to correponding elements of two arrays.
zipWith :: (Elt a, Elt b, Elt c) => (a -> b -> c) -> Array a -> Array b -> Array c

-- | Apply a worker function to corresponding elements of three arrays.
zipWith3 :: (Elt a, Elt b, Elt c, Elt d) => (a -> b -> c -> d) -> Array a -> Array b -> Array c -> Array d

-- | Apply a worker function to corresponding elements of four arrays.
zipWith4 :: (Elt a, Elt b, Elt c, Elt d, Elt e) => (a -> b -> c -> d -> e) -> Array a -> Array b -> Array c -> Array d -> Array e

-- | Apply a worker function to corresponding elements of five arrays.
zipWith5 :: (Elt a, Elt b, Elt c, Elt d, Elt e, Elt f) => (a -> b -> c -> d -> e -> f) -> Array a -> Array b -> Array c -> Array d -> Array e -> Array f

-- | Apply a worker function to corresponding elements of six arrays.
zipWith6 :: (Elt a, Elt b, Elt c, Elt d, Elt e, Elt f, Elt g) => (a -> b -> c -> d -> e -> f -> g) -> Array a -> Array b -> Array c -> Array d -> Array e -> Array f -> Array g

-- | Apply a worker function to corresponding elements of seven arrays.
zipWith7 :: (Elt a, Elt b, Elt c, Elt d, Elt e, Elt f, Elt g, Elt h) => (a -> b -> c -> d -> e -> f -> g -> h) -> Array a -> Array b -> Array c -> Array d -> Array e -> Array f -> Array g -> Array h

-- | Apply a worker function to corresponding elements of six arrays.
zipWith8 :: (Elt a, Elt b, Elt c, Elt d, Elt e, Elt f, Elt g, Elt h, Elt i) => (a -> b -> c -> d -> e -> f -> g -> h -> i) -> Array a -> Array b -> Array c -> Array d -> Array e -> Array f -> Array g -> Array h -> Array i

-- | Similar to <tt>foldl</tt> but return an array of the intermediate
--   states, including the final state that is computed by <tt>foldl</tt>.
scan :: Elt a => (a -> a -> a) -> a -> Array a -> Array a

-- | Undirected fold over an array.
--   
--   <ul>
--   <li>The worker function must be associative.</li>
--   <li>The provided starting element must be neutral with respect to the
--   worker. For example 0 is neutral wrt (+) and 1 is neutral wrt
--   (*).</li>
--   </ul>
fold :: Elt a => (a -> a -> a) -> a -> Array a -> a

-- | Undirected segmented fold.
--   
--   All segments are folded individually, and the result contains one
--   element for each segment.
--   
--   Same preconditions as <a>fold</a>.
fold_s :: Elt a => (a -> a -> a) -> a -> Segd -> Array a -> Array a

-- | Undirected scattered segmented fold.
--   
--   Like <a>fold_s</a>, but the segments can be scattered through an
--   <a>Arrays</a>.
--   
--   Same preconditions as <a>fold</a>.
fold_ss :: (Elts a, Elt a) => (a -> a -> a) -> a -> SSegd -> Arrays a -> Array a

-- | Undirected fold over virtual segments.
--   
--   The physical segments defined by the <a>VSegd</a> are folded
--   individually, and these results are replicated according to the
--   virtual segment id table of the <a>VSegd</a>. The result contains as
--   many elements as there virtual segments.
--   
--   Same preconditions as <a>fold</a>.
fold_vs :: (Elts a, Elt a) => (a -> a -> a) -> a -> VSegd -> Arrays a -> Array a

-- | Regular segmented fold.
--   
--   All segements have the given length.
--   
--   Same preconditions as <a>fold</a>.
fold_r :: Elt a => (a -> a -> a) -> a -> Int -> Array a -> Array a

-- | Undirected fold, using the first element to initialise the state.
--   
--   <ul>
--   <li>The worker function must be associative.</li>
--   <li>The provided starting element must be neutral with respect to the
--   worker. For example 0 is neutral wrt (+) and 1 is neutral wrt
--   (*).</li>
--   <li>If the array contains no elements then you'll get a bounds check
--   <tt>error</tt>.</li>
--   </ul>
fold1 :: Elt a => (a -> a -> a) -> Array a -> a

-- | Like <a>fold_s</a>, but using the first element of each segment to
--   initialise the state of that segment.
--   
--   Same preconditions as <a>fold1</a>.
fold1_s :: Elt a => (a -> a -> a) -> Segd -> Array a -> Array a

-- | Like <a>fold_ss</a>, but using the first element of each segment to
--   intialise the state of that segment.
--   
--   Same preconditions as <a>fold1</a>.
fold1_ss :: (Elts a, Elt a) => (a -> a -> a) -> SSegd -> Arrays a -> Array a

-- | Like <a>fold_vs</a>, but using the first element of each segment to
--   initialise the state of that segment.
--   
--   Same preconditions as <a>fold1</a>.
fold1_vs :: (Elts a, Elt a) => (a -> a -> a) -> VSegd -> Arrays a -> Array a

-- | Same as <tt>fold (+) 0</tt>
sum :: (Num a, Elt a) => Array a -> a

-- | Same as <tt>fold_s (+) 0</tt>
sum_s :: (Num a, Elt a) => Segd -> Array a -> Array a

-- | Same as <tt>fold_ss (+) 0</tt>
sum_ss :: (Num a, Elts a, Elt a) => SSegd -> Arrays a -> Array a

-- | Same as <tt>fold_r (+) 0</tt>
sum_r :: (Num a, Elt a) => Int -> Array a -> Array a

-- | Count the number of elements in array that are equal to the given
--   value.
count :: (Elt a, Eq a) => Array a -> a -> Int

-- | Segmented count.
count_s :: (Elt a, Eq a) => Segd -> Array a -> a -> Array Int

-- | Scattered segmented count.
--   
--   NOTE: This is a transitory interface, and will be removed in future
--   versions.
count_ss :: (Elt a, Eq a) => SSegd -> Vector (Array a) -> a -> Array Int

-- | O(length source). Compute the conjunction of all elements in a boolean
--   array.
and :: Array Bool -> Bool

-- | O(length result). Extract elements of an array where the associated
--   flag is true.
pack :: Elt a => Array a -> Array Bool -> Array a

-- | O(length result). Select the elements of an array that have a
--   corresponding tag.
--   
--   <pre>
--   packByTag [12, 24, 42, 93] [1, 0, 0, 1] 0 = [24, 42]
--   </pre>
packByTag :: Elt a => Array a -> Array Tag -> Tag -> Array a

-- | Extract the elements from an array that match the given predicate.
filter :: Elt a => (a -> Bool) -> Array a -> Array a

-- | Compute an array of flags indicating which elements match a given
--   value.
--   
--   <pre>
--   pick [4, 5, 3, 6, 5, 2, 5] 5 = [F, T, F, F, T, F, T]
--   </pre>
pick :: (Elt a, Eq a) => Array a -> a -> Array Bool

-- | Combine two arrays, using a flags array to tell us where to get each
--   element from.
--   
--   <pre>
--   combine [T, F, F, T, T, F] [1, 2, 3] [4, 5, 6] = [1, 4, 5, 2, 3, 6]
--   </pre>
combine :: Elt a => Array Bool -> Array a -> Array a -> Array a

-- | Like <a>combine</a>, but use a precomputed selector to speed up the
--   process.
--   
--   See the description of <a>mkSel2</a> for how this works.
combine2 :: Elt a => Array Tag -> SelRep2 -> Array a -> Array a -> Array a

-- | Interleave the elements of two arrays.
--   
--   <pre>
--   interleave [1, 2, 3] [4, 5, 6] = [1, 4, 2, 5, 3, 6]
--   </pre>
interleave :: Elt a => Array a -> Array a -> Array a
type Sel2 = UPSel2

-- | O(1). Construct a selector.
--   
--   A selector is a description of how to perform a <a>combine</a>
--   operation.
--   
--   Suppose we are evaluating the following expression:
--   
--   <pre>
--   combine [F,F,T,F,T,T] [1,2,3] [4,5,6] = [4,5,1,6,2,3]
--   </pre>
--   
--   This is difficult to parallelise. For each element in the result, the
--   source array we get this element from depends on the tag values
--   associated with all previous elements.
--   
--   However, if we going to apply <a>combine</a> several times with the
--   same flags array, we can precompute a selector that tells us where to
--   get each element. The selector contains the original flags, as well as
--   the source index telling us where to get each element for the result
--   array.
--   
--   For example:
--   
--   <pre>
--   tagsToIndices2 [F,F,T,F,T,T]   -- tags
--                = [0,1,0,2,1,2]   -- indices
--   </pre>
--   
--   This says get the first element from index 0 in the second array, then
--   from index 1 in the second array, then index 0 in the first array ...
--   
--   The selector then consists of both the <tt>tag</tt> and
--   <tt>indices</tt> arrays.
mkSel2 :: Array Tag -> Array Int -> Int -> Int -> SelRep2 -> Sel2

-- | O(1). Yield the tags array of a selector.
tagsSel2 :: Sel2 -> Array Tag

-- | O(1). Yield the indices array of a selector.
indicesSel2 :: Sel2 -> Array Int

-- | O(1). Yield the number of elements that will be taken from the first
--   array.
elementsSel2_0 :: Sel2 -> Int

-- | O(1). Yield the number of elements that will be taken from the second
--   array.
elementsSel2_1 :: Sel2 -> Int

-- | O(1). Yield the parallel representation of a selector.
repSel2 :: Sel2 -> SelRep2

-- | O(n). Compute a selector from a tags array.
tagsToSel2 :: Array Tag -> Sel2
type SelRep2 = UPSelRep2

-- | O(n). Construct a parallel selector representation.
--   
--   A <a>SelRep2</a> describes how to distribute the two data vectors
--   corresponding to a <a>Sel2</a> across several PEs.
--   
--   Suppose we want to perform the following <a>combine</a> operation:
--   
--   <pre>
--   combine [F,F,T,T,F,T,F,F,T] [A0,A1,A2,A3,A4] [B0,B1,B2,B3] 
--     = [A0,A1,B0,B1,A2,B2,A3,A4,B3]
--   </pre>
--   
--   The first array is the flags array, that says which of the data arrays
--   to get each successive element from. As <a>combine</a> is difficult to
--   compute in parallel, if we are going to perform several combines with
--   the same flags array, we can precompute a selector that tells us where
--   to get each element. The selector contains the original flags, as well
--   as the source index telling us where to get each element for the
--   result array.
--   
--   <pre>
--   flags:   [F,F,T,T,F,T,F,F,T]
--   indices: [0,1,0,1,2,2,3,4,3]
--   </pre>
--   
--   Suppose we want to distribute the combine operation across 3 PEs. It's
--   easy to split the selector like so:
--   
--   <pre>
--              PE0                PE1               PE2
--   flags:   [F,F,T]            [T,F,T]           [F,F,T] 
--   indices: [0,1,0]            [1,2,2]           [3,4,3]
--   </pre>
--   
--   We now need to split the two data arrays. Each PE needs slices of the
--   data arrays that correspond to the parts of the selector that were
--   given to it. For the current example we get:
--   
--   <pre>
--              PE0                PE1               PE2
--   data_A:   [A0,A1]            [A2]              [A3,A4]
--   data_B:   [B0]               [B1,B2]           [B3]
--   </pre>
--   
--   The <a>SelRep2</a> contains the starting index and length of each of
--   of these slices:
--   
--   <pre>
--         PE0                PE1               PE2
--   ((0, 0), (2, 1))   ((2, 1), (1, 2))  ((3, 3), (2, 1))
--    indices   lens      indices  lens    indices  lens
--   </pre>
mkSelRep2 :: Array Tag -> SelRep2

-- | O(1). Take the <tt>indices</tt> field from a <a>SelRep2</a>.
indicesSelRep2 :: Array Tag -> SelRep2 -> Array Int

-- | O(1). Yield the number of elements to take from the first array.
elementsSelRep2_0 :: Array Tag -> SelRep2 -> Int

-- | O(1). Yield the number of elements to take from the second array.
elementsSelRep2_1 :: Array Tag -> SelRep2 -> Int
type Segd = UPSegd

-- | O(max(segs, threads) . log segs). Construct a segment descriptor.
--   
--   A segment desciptor defines an irregular 2D array based on a flat, 1D
--   array of elements. The defined array is a nested array of segments,
--   where every segment covers some of the elements from the flat array.
--   
--   <ul>
--   <li>The starting indices must be equal to <tt>init (scanl (+) 0
--   lengths)</tt></li>
--   <li>If you don't want to cover all the elements from the flat arrary
--   then use a <a>SSegd</a> instead.</li>
--   </ul>
--   
--   Example:
--   
--   <pre>
--   flat array data: [1 2 3 4 5 6 7 8]
--     (segmentation)  --- ----- - ---
--     segd  lengths: [2, 3, 1, 2]
--           indices: [0, 2, 5, 6]
--          elements: 8 
--   </pre>
mkSegd :: Array Int -> Array Int -> Int -> Segd

-- | Check whether a <a>Segd</a> is well formed.
validSegd :: Segd -> Bool

-- | O(1). Construct an empty <a>Segd</a>.
emptySegd :: Segd

-- | O(1). Construct a <a>Segd</a> containing a single segment of the given
--   length.
singletonSegd :: Int -> Segd

-- | O(max(segs, threads) . log segs). Construct a <a>Segd</a> from an
--   array of segment lengths.
lengthsToSegd :: Array Int -> Segd

-- | O(1). Yield the length of a <a>Segd</a>.
lengthSegd :: Segd -> Int

-- | O(1). Yield the segment lengths of a <a>Segd</a>.
lengthsSegd :: Segd -> Array Int

-- | O(1). Yield the segment starting indices of a <a>Segd</a>.
indicesSegd :: Segd -> Array Int

-- | O(1). Yield the total number of elements defined by a <a>Segd</a>.
elementsSegd :: Segd -> Int

-- | O(max(segs, threads) . log segs). Add the lengths of corresponding
--   segments in two descriptors.
--   
--   <pre>
--   plusSegd [lens: 2 3 1] [lens: 3 1 1] = [lens: 5 4 2]
--   </pre>
plusSegd :: Segd -> Segd -> Segd
type SSegd = UPSSegd

-- | Construct a Scattered Segment Descriptor.
--   
--   A <a>SSegd</a> is an extension of a <a>Segd</a> that that allows the
--   segments to be scattered through multiple flat arrays.
--   
--   Each segment is associated with a source id that indicates what flat
--   array it is in, along with the starting index in that flat array.
--   
--   <ul>
--   <li>The segments need not cover the entire flat array.</li>
--   <li>Different segments may point to the same elements.</li>
--   </ul>
mkSSegd :: Array Int -> Array Int -> Segd -> SSegd

-- | Check whether a <a>Segd</a> is well formed.
validSSegd :: SSegd -> Bool

-- | O(1). Construct an empty <a>SSegd</a>.
emptySSegd :: SSegd

-- | O(1). Construct a <a>Segd</a> containing a single segment of the given
--   length.
singletonSSegd :: Int -> SSegd

-- | O(segs). Promote a <a>Segd</a> to a <a>SSegd</a>, assuming all
--   segments are contiguous and come from a single array.
promoteSegdToSSegd :: Segd -> SSegd

-- | O(1). True when a <a>SSegd</a> has been constructed by promoting a
--   <a>SSegd</a>.
--   
--   In this case all the data elements are in one contiguous flat array,
--   and consumers can avoid looking at the real starts and sources fields.
isContiguousSSegd :: SSegd -> Bool

-- | O(1). Yield the length of a <a>SSegd</a>.
lengthOfSSegd :: SSegd -> Int

-- | O(1). Yield the segment lengths of a <a>SSegd</a>.
lengthsOfSSegd :: SSegd -> Array Int

-- | O(1). Yield the indices field of a <a>SSegd</a>.
indicesOfSSegd :: SSegd -> Array Int

-- | O(1). Yield the starts field of a <a>SSegd</a>.
startsOfSSegd :: SSegd -> Array Int

-- | O(1). Yield the sources field of a <a>SSegd</a>.
sourcesOfSSegd :: SSegd -> Array Int

-- | O(1). Get the length, segment index, starting index, and source id of
--   a segment.
getSegOfSSegd :: SSegd -> Int -> (Int, Int, Int, Int)

-- | Produce a segment descriptor that describes the result of appending
--   two segmented arrays.
appendSSegd :: SSegd -> Int -> SSegd -> Int -> SSegd
type VSegd = UPVSegd

-- | Construct a Virtual Segment Descriptor.
--   
--   A <a>VSegd</a> is an extension of a <a>SSegd</a> that allows data from
--   the underlying flat array to be shared between segments. For example,
--   you can define an array of 10 virtual segments that all have the same
--   length and elements as a single physical segment.
--   
--   <ul>
--   <li>Internally we maintain the invariant that all physical segments
--   must be reachable by some virtual segment. This is needed to ensure
--   that operations such as <a>fold_ss</a> segmented fold have the right
--   complexity.</li>
--   <li>If you don't need the invariant then you can sidestep the code
--   that maintains it by using the redundant versions of the following
--   operators, and sometimes get faster code.</li>
--   </ul>
mkVSegd :: Array Int -> SSegd -> VSegd

-- | Check whether a <a>Segd</a> is well formed.
validVSegd :: VSegd -> Bool

-- | O(1). Construct an empty <a>SSegd</a>.
emptyVSegd :: VSegd

-- | O(1). Construct a <a>VSegd</a> containing a single segment of the
--   given length.
singletonVSegd :: Int -> VSegd

-- | O(len). Construct a <a>VSegd</a> that describes an array where all
--   virtual segments point to the same physical segment.
replicatedVSegd :: Int -> Int -> VSegd

-- | O(segs). Promote a plain <a>Segd</a> to a <a>VSegd</a>.
--   
--   The result contains one virtual segment for every physical segment the
--   provided <a>Segd</a>.
promoteSegdToVSegd :: Segd -> VSegd

-- | O(segs). Promote a plain <a>SSegd</a> to a <a>VSegd</a>.
--   
--   The result contains one virtual segment for every physical segment the
--   provided <a>SSegd</a>.
promoteSSegdToVSegd :: SSegd -> VSegd

-- | O(1). If true then the segments are all unshared, and the
--   <tt>vsegids</tt> field be just <tt>[0..len-1]</tt>.
--   
--   Consumers can check this field to avoid demanding the <tt>vsegids</tt>
--   field. This can avoid the need for it to be constructed in the first
--   place, due to lazy evaluation.
isManifestVSegd :: VSegd -> Bool

-- | O(1). If true then the <tt>starts</tt> field is identical to the
--   <tt>indices</tt> field and the sourceids are all 0s.
--   
--   In this case all the data elements are in one contiguous flat array,
--   and consumers can avoid looking at the real starts and sources fields.
isContiguousVSegd :: VSegd -> Bool

-- | O(1). Yield the length of a <a>VSegd</a>.
lengthOfVSegd :: VSegd -> Int

-- | O(1). Yield the vsegids of a <a>VSegd</a>.
takeVSegidsOfVSegd :: VSegd -> Array Int

-- | O(1). Yield the vsegids of a <a>VSegd</a>, but don't require that
--   every physical segment is referenced by some virtual segment.
--   
--   If you're just performing indexing and don't need the invariant that
--   all physical segments are reachable from some virtual segment, then
--   use this version as it's faster. This sidesteps the code that
--   maintains the invariant.
--   
--   The stated O(1) complexity assumes that the array has already been
--   fully evalauted. If this is not the case then we can avoid demanding
--   the result of a prior computation on the <tt>vsegids</tt>, thus
--   reducing the cost attributed to that prior computation.
takeVSegidsRedundantOfVSegd :: VSegd -> Array Int

-- | O(1). Yield the <a>SSegd</a> of a <a>VSegd</a>.
takeSSegdOfVSegd :: VSegd -> SSegd

-- | O(1). Yield the <a>SSegd</a> of a <a>VSegd</a>, but don't require that
--   every physical segment is referenced by some virtual segment.
--   
--   See the note in <a>takeVSegidsRedundantOfVSegd</a>.
takeSSegdRedundantOfVSegd :: VSegd -> SSegd

-- | O(1). Yield the segment lengths of a <a>VSegd</a>.
takeLengthsOfVSegd :: VSegd -> Array Int

-- | O(1). Get the length, starting index, and source id of a segment.
getSegOfVSegd :: VSegd -> Int -> (Int, Int, Int)

-- | O(segs). Yield a <a>SSegd</a> that describes each segment of a
--   <a>VSegd</a> individually.
--   
--   By doing this we lose information about which virtual segments
--   correspond to the same physical segments.
--   
--   <i>WARNING</i>: Trying to take the <a>SSegd</a> of a nested array that
--   has been constructed with replication can cause index space overflow.
--   This is because the virtual size of the corresponding flat data can be
--   larger than physical memory. If this happens then indices fields and
--   element count in the result will be invalid.
unsafeDemoteToSSegdOfVSegd :: VSegd -> SSegd

-- | O(segs). Yield a <a>Segd</a> that describes each segment of a
--   <a>VSegd</a> individually.
--   
--   By doing this we lose information about which virtual segments
--   correspond to the same physical segments.
--   
--   See the warning in <a>unsafeDemoteToSSegdOfVSegd</a>.
unsafeDemoteToSegdOfVSegd :: VSegd -> Segd

-- | Update the <tt>vsegids</tt> of a <a>VSegd</a>, and then cull the
--   physical segment descriptor so that all physical segments are
--   reachable from some virtual segment.
updateVSegsOfVSegd :: (Array Int -> Array Int) -> VSegd -> VSegd

-- | Update the <tt>vsegids</tt> of <a>VSegd</a>, where the result is
--   guaranteed to cover all physical segments.
--   
--   Using this version avoids performing the <tt>cull</tt> operation which
--   discards unreachable physical segments.
--   
--   <ul>
--   <li>The resulting vsegids must cover all physical segments. If they do
--   not then there will be physical segments that are not reachable from
--   some virtual segment, and subsequent operations like <tt>fold_ss</tt>
--   will have the wrong work complexity.</li>
--   </ul>
updateVSegsReachableOfVSegd :: (Array Int -> Array Int) -> VSegd -> VSegd

-- | Produce a virtual segment descriptor that describes the result of
--   appending two segmented arrays.
appendVSegd :: VSegd -> Int -> VSegd -> Int -> VSegd

-- | Combine two virtual segment descriptors.
combine2VSegd :: Sel2 -> VSegd -> Int -> VSegd -> Int -> VSegd
class (Unboxes a, DT a) => Elts a
type Arrays = Vectors

-- | O(1). Construct an empty <a>Arrays</a> with no elements.
emptys :: Arrays a

-- | O(1). Construct an <a>Arrays</a> consisting of a single <a>Array</a>.
singletons :: (Elt a, Elts a) => Array a -> Arrays a

-- | O(1). Yield the number of <a>Array</a> in an <a>Arrays</a>.
lengths :: Elts a => Arrays a -> Int

-- | O(1). Take one of the outer <a>Array</a> from an <a>Arrays</a>.
unsafeIndexs :: (Elt a, Elts a) => Arrays a -> Int -> Array a

-- | O(1). Retrieve a single element from an <a>Arrays</a>, given the outer
--   and inner indices.
unsafeIndex2s :: (Elt a, Elts a) => Arrays a -> Int -> Int -> a

-- | O(n). Append two <a>Arrays</a>, using work proportional to the length
--   of the outer array.
appends :: (Elt a, Elts a) => Arrays a -> Arrays a -> Arrays a

-- | O(number of inner arrays). Convert a boxed vector of <a>Array</a> to
--   an <a>Arrays</a>.
fromVectors :: (Elt a, Elts a) => Vector (Array a) -> Arrays a

-- | O(number of inner arrays). Convert an <a>Arrays</a> to a boxed vector
--   of <a>Array</a>.
toVectors :: (Elt a, Elts a) => Arrays a -> Vector (Array a)

-- | Generate an array of the given length full of random data. Good for
--   testing.
randoms :: (Elt a, Random a, RandomGen g) => Int -> g -> Array a

-- | Generate an array of the given length full of random data. Good for
--   testing.
randomRs :: (Elt a, Random a, RandomGen g) => Int -> (a, a) -> g -> Array a
class UIO a => IOElt a

-- | Read an array from a file.
hGet :: IOElt a => Handle -> IO (Array a)

-- | Write an array to a file.
hPut :: IOElt a => Handle -> Array a -> IO ()

-- | Convert an array to a list of elements.
toList :: Elt a => Array a -> [a]

-- | Convert a list of elements to an array.
fromList :: Elt a => [a] -> Array a
instance (IOElt a, IOElt b) => IOElt (a, b)
instance IOElt Double
instance IOElt Int
instance Elts Double
instance Elts Float
instance Elts Word8
instance Elts Int
instance (Elt a, Elt b) => Elt (a, b)
instance Elt Double
instance Elt Float
instance Elt Bool
instance Elt Word8
instance Elt Int
